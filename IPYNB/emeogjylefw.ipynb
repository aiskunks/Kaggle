{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb77ed1c",
   "metadata": {},
   "source": [
    "### Heart Disease indicator Dataset\n",
    "#### Abstract\n",
    "#### AutoML:\n",
    "\n",
    "Auto ml selects the best model for our dataset by evaluating many models for us.\n",
    "\n",
    "Here below we are going to use AUTOML to predict the gender of person using other variables such as BMI, smoking,Alcohol drinking, Stroke etc (ie: multiple classification will be done here).\n",
    "\n",
    "By performing automl we will get the imp variables and the most effective model for our dataset as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "982d5a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h2o in /Users/nikhilbindal/opt/anaconda3/lib/python3.9/site-packages (3.38.0.2)\n",
      "Requirement already satisfied: tabulate in /Users/nikhilbindal/opt/anaconda3/lib/python3.9/site-packages (from h2o) (0.8.9)\n",
      "Requirement already satisfied: requests in /Users/nikhilbindal/opt/anaconda3/lib/python3.9/site-packages (from h2o) (2.27.1)\n",
      "Requirement already satisfied: future in /Users/nikhilbindal/opt/anaconda3/lib/python3.9/site-packages (from h2o) (0.18.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/nikhilbindal/opt/anaconda3/lib/python3.9/site-packages (from requests->h2o) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nikhilbindal/opt/anaconda3/lib/python3.9/site-packages (from requests->h2o) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/nikhilbindal/opt/anaconda3/lib/python3.9/site-packages (from requests->h2o) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nikhilbindal/opt/anaconda3/lib/python3.9/site-packages (from requests->h2o) (3.3)\n"
     ]
    }
   ],
   "source": [
    "#Installing H20\n",
    "!pip install h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fb155c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the library\n",
    "# importing H20 automl \n",
    "#It can do data prepossesing it self like categorical encoding coversion etc. \n",
    "#So there is no need to create duplicates and can take care of missing value imputation and other data cleaning activities.\n",
    "#mine\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "976d72b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 . connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>4 hours 11 mins</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>America/New_York</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.38.0.2</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>12 days </td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_nikhilbindal_6t9qnj</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>1.968 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.9.12 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -----------------------------------\n",
       "H2O_cluster_uptime:         4 hours 11 mins\n",
       "H2O_cluster_timezone:       America/New_York\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.38.0.2\n",
       "H2O_cluster_version_age:    12 days\n",
       "H2O_cluster_name:           H2O_from_python_nikhilbindal_6t9qnj\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    1.968 Gb\n",
       "H2O_cluster_total_cores:    4\n",
       "H2O_cluster_allowed_cores:  4\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.9.12 final\n",
       "--------------------------  -----------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init()\n",
    "#It starts the H2o clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "423a7756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HeartDisease</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>AlcoholDrinking</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>PhysicalHealth</th>\n",
       "      <th>MentalHealth</th>\n",
       "      <th>DiffWalking</th>\n",
       "      <th>Sex</th>\n",
       "      <th>AgeCategory</th>\n",
       "      <th>Race</th>\n",
       "      <th>Diabetic</th>\n",
       "      <th>PhysicalActivity</th>\n",
       "      <th>GenHealth</th>\n",
       "      <th>SleepTime</th>\n",
       "      <th>Asthma</th>\n",
       "      <th>KidneyDisease</th>\n",
       "      <th>SkinCancer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>16.60</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Female</td>\n",
       "      <td>55-59</td>\n",
       "      <td>White</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Very good</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No</td>\n",
       "      <td>20.34</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Female</td>\n",
       "      <td>80 or older</td>\n",
       "      <td>White</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Very good</td>\n",
       "      <td>7.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No</td>\n",
       "      <td>26.58</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>65-69</td>\n",
       "      <td>White</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Fair</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No</td>\n",
       "      <td>24.21</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Female</td>\n",
       "      <td>75-79</td>\n",
       "      <td>White</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Good</td>\n",
       "      <td>6.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No</td>\n",
       "      <td>23.71</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Female</td>\n",
       "      <td>40-44</td>\n",
       "      <td>White</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Very good</td>\n",
       "      <td>8.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  HeartDisease    BMI Smoking AlcoholDrinking Stroke  PhysicalHealth  \\\n",
       "0           No  16.60     Yes              No     No             3.0   \n",
       "1           No  20.34      No              No    Yes             0.0   \n",
       "2           No  26.58     Yes              No     No            20.0   \n",
       "3           No  24.21      No              No     No             0.0   \n",
       "4           No  23.71      No              No     No            28.0   \n",
       "\n",
       "   MentalHealth DiffWalking     Sex  AgeCategory   Race Diabetic  \\\n",
       "0          30.0          No  Female        55-59  White      Yes   \n",
       "1           0.0          No  Female  80 or older  White       No   \n",
       "2          30.0          No    Male        65-69  White      Yes   \n",
       "3           0.0          No  Female        75-79  White       No   \n",
       "4           0.0         Yes  Female        40-44  White       No   \n",
       "\n",
       "  PhysicalActivity  GenHealth  SleepTime Asthma KidneyDisease SkinCancer  \n",
       "0              Yes  Very good        5.0    Yes            No        Yes  \n",
       "1              Yes  Very good        7.0     No            No         No  \n",
       "2              Yes       Fair        8.0    Yes            No         No  \n",
       "3               No       Good        6.0     No            No        Yes  \n",
       "4              Yes  Very good        8.0     No            No         No  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading the Dataset and Displaying the head of it.\n",
    "data=pd.read_csv(\"./heart_2020_cleaned.csv\", sep = \",\")\n",
    "data.name = \"data\"\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75574f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "city_development_index  target                   -0.341665\n",
       "enrollee_id             city_development_index   -0.040455\n",
       "training_hours          target                   -0.021577\n",
       "enrollee_id             training_hours            0.000998\n",
       "city_development_index  training_hours            0.001920\n",
       "enrollee_id             target                    0.049475\n",
       "                        enrollee_id               1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking correlation between variables\n",
    "data.corr().unstack().sort_values().drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8152e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "#Importing our dataset with H2O.\n",
    "df = h2o.import_file('./heart_2020_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e20f7c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HeartDisease': 'enum',\n",
       " 'BMI': 'real',\n",
       " 'Smoking': 'enum',\n",
       " 'AlcoholDrinking': 'enum',\n",
       " 'Stroke': 'enum',\n",
       " 'PhysicalHealth': 'int',\n",
       " 'MentalHealth': 'int',\n",
       " 'DiffWalking': 'enum',\n",
       " 'Sex': 'enum',\n",
       " 'AgeCategory': 'enum',\n",
       " 'Race': 'enum',\n",
       " 'Diabetic': 'enum',\n",
       " 'PhysicalActivity': 'enum',\n",
       " 'GenHealth': 'enum',\n",
       " 'SleepTime': 'int',\n",
       " 'Asthma': 'enum',\n",
       " 'KidneyDisease': 'enum',\n",
       " 'SkinCancer': 'enum'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f84b0b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>Rows:319795\n",
       "Cols:18\n",
       "</pre>"
      ],
      "text/plain": [
       "Rows:319795\n",
       "Cols:18\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class='dataframe'>\n",
       "<thead>\n",
       "<tr><th>       </th><th>HeartDisease  </th><th>BMI               </th><th>Smoking  </th><th>AlcoholDrinking  </th><th>Stroke  </th><th>PhysicalHealth   </th><th>MentalHealth     </th><th>DiffWalking  </th><th>Sex   </th><th>AgeCategory  </th><th>Race  </th><th>Diabetic               </th><th>PhysicalActivity  </th><th>GenHealth  </th><th>SleepTime         </th><th>Asthma  </th><th>KidneyDisease  </th><th>SkinCancer  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>type   </td><td>enum          </td><td>real              </td><td>enum     </td><td>enum             </td><td>enum    </td><td>int              </td><td>int              </td><td>enum         </td><td>enum  </td><td>enum         </td><td>enum  </td><td>enum                   </td><td>enum              </td><td>enum       </td><td>int               </td><td>enum    </td><td>enum           </td><td>enum        </td></tr>\n",
       "<tr><td>mins   </td><td>              </td><td>12.02             </td><td>         </td><td>                 </td><td>        </td><td>0.0              </td><td>0.0              </td><td>             </td><td>      </td><td>             </td><td>      </td><td>                       </td><td>                  </td><td>           </td><td>1.0               </td><td>        </td><td>               </td><td>            </td></tr>\n",
       "<tr><td>mean   </td><td>              </td><td>28.325398520927457</td><td>         </td><td>                 </td><td>        </td><td>3.371710001719859</td><td>3.898366140808957</td><td>             </td><td>      </td><td>             </td><td>      </td><td>                       </td><td>                  </td><td>           </td><td>7.097074688472298 </td><td>        </td><td>               </td><td>            </td></tr>\n",
       "<tr><td>maxs   </td><td>              </td><td>94.85             </td><td>         </td><td>                 </td><td>        </td><td>30.0             </td><td>30.0             </td><td>             </td><td>      </td><td>             </td><td>      </td><td>                       </td><td>                  </td><td>           </td><td>24.0              </td><td>        </td><td>               </td><td>            </td></tr>\n",
       "<tr><td>sigma  </td><td>              </td><td>6.356100200470744 </td><td>         </td><td>                 </td><td>        </td><td>7.950850182571366</td><td>7.95523521894361 </td><td>             </td><td>      </td><td>             </td><td>      </td><td>                       </td><td>                  </td><td>           </td><td>1.4360070609642848</td><td>        </td><td>               </td><td>            </td></tr>\n",
       "<tr><td>zeros  </td><td>              </td><td>0                 </td><td>         </td><td>                 </td><td>        </td><td>226589           </td><td>205401           </td><td>             </td><td>      </td><td>             </td><td>      </td><td>                       </td><td>                  </td><td>           </td><td>0                 </td><td>        </td><td>               </td><td>            </td></tr>\n",
       "<tr><td>missing</td><td>0             </td><td>0                 </td><td>0        </td><td>0                </td><td>0       </td><td>0                </td><td>0                </td><td>0            </td><td>0     </td><td>0            </td><td>0     </td><td>0                      </td><td>0                 </td><td>0          </td><td>0                 </td><td>0       </td><td>0              </td><td>0           </td></tr>\n",
       "<tr><td>0      </td><td>No            </td><td>16.6              </td><td>Yes      </td><td>No               </td><td>No      </td><td>3.0              </td><td>30.0             </td><td>No           </td><td>Female</td><td>55-59        </td><td>White </td><td>Yes                    </td><td>Yes               </td><td>Very good  </td><td>5.0               </td><td>Yes     </td><td>No             </td><td>Yes         </td></tr>\n",
       "<tr><td>1      </td><td>No            </td><td>20.34             </td><td>No       </td><td>No               </td><td>Yes     </td><td>0.0              </td><td>0.0              </td><td>No           </td><td>Female</td><td>80 or older  </td><td>White </td><td>No                     </td><td>Yes               </td><td>Very good  </td><td>7.0               </td><td>No      </td><td>No             </td><td>No          </td></tr>\n",
       "<tr><td>2      </td><td>No            </td><td>26.58             </td><td>Yes      </td><td>No               </td><td>No      </td><td>20.0             </td><td>30.0             </td><td>No           </td><td>Male  </td><td>65-69        </td><td>White </td><td>Yes                    </td><td>Yes               </td><td>Fair       </td><td>8.0               </td><td>Yes     </td><td>No             </td><td>No          </td></tr>\n",
       "<tr><td>3      </td><td>No            </td><td>24.21             </td><td>No       </td><td>No               </td><td>No      </td><td>0.0              </td><td>0.0              </td><td>No           </td><td>Female</td><td>75-79        </td><td>White </td><td>No                     </td><td>No                </td><td>Good       </td><td>6.0               </td><td>No      </td><td>No             </td><td>Yes         </td></tr>\n",
       "<tr><td>4      </td><td>No            </td><td>23.71             </td><td>No       </td><td>No               </td><td>No      </td><td>28.0             </td><td>0.0              </td><td>Yes          </td><td>Female</td><td>40-44        </td><td>White </td><td>No                     </td><td>Yes               </td><td>Very good  </td><td>8.0               </td><td>No      </td><td>No             </td><td>No          </td></tr>\n",
       "<tr><td>5      </td><td>Yes           </td><td>28.87             </td><td>Yes      </td><td>No               </td><td>No      </td><td>6.0              </td><td>0.0              </td><td>Yes          </td><td>Female</td><td>75-79        </td><td>Black </td><td>No                     </td><td>No                </td><td>Fair       </td><td>12.0              </td><td>No      </td><td>No             </td><td>No          </td></tr>\n",
       "<tr><td>6      </td><td>No            </td><td>21.63             </td><td>No       </td><td>No               </td><td>No      </td><td>15.0             </td><td>0.0              </td><td>No           </td><td>Female</td><td>70-74        </td><td>White </td><td>No                     </td><td>Yes               </td><td>Fair       </td><td>4.0               </td><td>Yes     </td><td>No             </td><td>Yes         </td></tr>\n",
       "<tr><td>7      </td><td>No            </td><td>31.64             </td><td>Yes      </td><td>No               </td><td>No      </td><td>5.0              </td><td>0.0              </td><td>Yes          </td><td>Female</td><td>80 or older  </td><td>White </td><td>Yes                    </td><td>No                </td><td>Good       </td><td>9.0               </td><td>Yes     </td><td>No             </td><td>No          </td></tr>\n",
       "<tr><td>8      </td><td>No            </td><td>26.45             </td><td>No       </td><td>No               </td><td>No      </td><td>0.0              </td><td>0.0              </td><td>No           </td><td>Female</td><td>80 or older  </td><td>White </td><td>No, borderline diabetes</td><td>No                </td><td>Fair       </td><td>5.0               </td><td>No      </td><td>Yes            </td><td>No          </td></tr>\n",
       "<tr><td>9      </td><td>No            </td><td>40.69             </td><td>No       </td><td>No               </td><td>No      </td><td>0.0              </td><td>0.0              </td><td>Yes          </td><td>Male  </td><td>65-69        </td><td>White </td><td>No                     </td><td>Yes               </td><td>Good       </td><td>10.0              </td><td>No      </td><td>No             </td><td>No          </td></tr>\n",
       "</tbody>\n",
       "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[319795 rows x 18 columns]</pre>"
      ],
      "text/plain": [
       "         HeartDisease    BMI                 Smoking    AlcoholDrinking    Stroke    PhysicalHealth     MentalHealth       DiffWalking    Sex     AgeCategory    Race    Diabetic                 PhysicalActivity    GenHealth    SleepTime           Asthma    KidneyDisease    SkinCancer\n",
       "-------  --------------  ------------------  ---------  -----------------  --------  -----------------  -----------------  -------------  ------  -------------  ------  -----------------------  ------------------  -----------  ------------------  --------  ---------------  ------------\n",
       "type     enum            real                enum       enum               enum      int                int                enum           enum    enum           enum    enum                     enum                enum         int                 enum      enum             enum\n",
       "mins                     12.02                                                       0.0                0.0                                                                                                                        1.0\n",
       "mean                     28.325398520927457                                          3.371710001719859  3.898366140808957                                                                                                          7.097074688472298\n",
       "maxs                     94.85                                                       30.0               30.0                                                                                                                       24.0\n",
       "sigma                    6.356100200470744                                           7.950850182571366  7.95523521894361                                                                                                           1.4360070609642848\n",
       "zeros                    0                                                           226589             205401                                                                                                                     0\n",
       "missing  0               0                   0          0                  0         0                  0                  0              0       0              0       0                        0                   0            0                   0         0                0\n",
       "0        No              16.6                Yes        No                 No        3.0                30.0               No             Female  55-59          White   Yes                      Yes                 Very good    5.0                 Yes       No               Yes\n",
       "1        No              20.34               No         No                 Yes       0.0                0.0                No             Female  80 or older    White   No                       Yes                 Very good    7.0                 No        No               No\n",
       "2        No              26.58               Yes        No                 No        20.0               30.0               No             Male    65-69          White   Yes                      Yes                 Fair         8.0                 Yes       No               No\n",
       "3        No              24.21               No         No                 No        0.0                0.0                No             Female  75-79          White   No                       No                  Good         6.0                 No        No               Yes\n",
       "4        No              23.71               No         No                 No        28.0               0.0                Yes            Female  40-44          White   No                       Yes                 Very good    8.0                 No        No               No\n",
       "5        Yes             28.87               Yes        No                 No        6.0                0.0                Yes            Female  75-79          Black   No                       No                  Fair         12.0                No        No               No\n",
       "6        No              21.63               No         No                 No        15.0               0.0                No             Female  70-74          White   No                       Yes                 Fair         4.0                 Yes       No               Yes\n",
       "7        No              31.64               Yes        No                 No        5.0                0.0                Yes            Female  80 or older    White   Yes                      No                  Good         9.0                 Yes       No               No\n",
       "8        No              26.45               No         No                 No        0.0                0.0                No             Female  80 or older    White   No, borderline diabetes  No                  Fair         5.0                 No        Yes              No\n",
       "9        No              40.69               No         No                 No        0.0                0.0                Yes            Male    65-69          White   No                       Yes                 Good         10.0                No        No               No\n",
       "[319795 rows x 18 columns]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c6af1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting our dataset into 3 datasets, one for training, other for testing and last one for validation purposes. (0.7,0.15,0.15 split)\n",
    "df_train,df_test,df_valid = df.split_frame(ratios=[.7, .15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d04f88b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class='dataframe'>\n",
       "<thead>\n",
       "<tr><th>HeartDisease  </th><th style=\"text-align: right;\">  BMI</th><th>Smoking  </th><th>AlcoholDrinking  </th><th>Stroke  </th><th style=\"text-align: right;\">  PhysicalHealth</th><th style=\"text-align: right;\">  MentalHealth</th><th>DiffWalking  </th><th>Sex   </th><th>AgeCategory  </th><th>Race  </th><th>Diabetic               </th><th>PhysicalActivity  </th><th>GenHealth  </th><th style=\"text-align: right;\">  SleepTime</th><th>Asthma  </th><th>KidneyDisease  </th><th>SkinCancer  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>No            </td><td style=\"text-align: right;\">16.6 </td><td>Yes      </td><td>No               </td><td>No      </td><td style=\"text-align: right;\">               3</td><td style=\"text-align: right;\">            30</td><td>No           </td><td>Female</td><td>55-59        </td><td>White </td><td>Yes                    </td><td>Yes               </td><td>Very good  </td><td style=\"text-align: right;\">          5</td><td>Yes     </td><td>No             </td><td>Yes         </td></tr>\n",
       "<tr><td>No            </td><td style=\"text-align: right;\">20.34</td><td>No       </td><td>No               </td><td>Yes     </td><td style=\"text-align: right;\">               0</td><td style=\"text-align: right;\">             0</td><td>No           </td><td>Female</td><td>80 or older  </td><td>White </td><td>No                     </td><td>Yes               </td><td>Very good  </td><td style=\"text-align: right;\">          7</td><td>No      </td><td>No             </td><td>No          </td></tr>\n",
       "<tr><td>Yes           </td><td style=\"text-align: right;\">28.87</td><td>Yes      </td><td>No               </td><td>No      </td><td style=\"text-align: right;\">               6</td><td style=\"text-align: right;\">             0</td><td>Yes          </td><td>Female</td><td>75-79        </td><td>Black </td><td>No                     </td><td>No                </td><td>Fair       </td><td style=\"text-align: right;\">         12</td><td>No      </td><td>No             </td><td>No          </td></tr>\n",
       "<tr><td>No            </td><td style=\"text-align: right;\">21.63</td><td>No       </td><td>No               </td><td>No      </td><td style=\"text-align: right;\">              15</td><td style=\"text-align: right;\">             0</td><td>No           </td><td>Female</td><td>70-74        </td><td>White </td><td>No                     </td><td>Yes               </td><td>Fair       </td><td style=\"text-align: right;\">          4</td><td>Yes     </td><td>No             </td><td>Yes         </td></tr>\n",
       "<tr><td>No            </td><td style=\"text-align: right;\">31.64</td><td>Yes      </td><td>No               </td><td>No      </td><td style=\"text-align: right;\">               5</td><td style=\"text-align: right;\">             0</td><td>Yes          </td><td>Female</td><td>80 or older  </td><td>White </td><td>Yes                    </td><td>No                </td><td>Good       </td><td style=\"text-align: right;\">          9</td><td>Yes     </td><td>No             </td><td>No          </td></tr>\n",
       "<tr><td>No            </td><td style=\"text-align: right;\">26.45</td><td>No       </td><td>No               </td><td>No      </td><td style=\"text-align: right;\">               0</td><td style=\"text-align: right;\">             0</td><td>No           </td><td>Female</td><td>80 or older  </td><td>White </td><td>No, borderline diabetes</td><td>No                </td><td>Fair       </td><td style=\"text-align: right;\">          5</td><td>No      </td><td>Yes            </td><td>No          </td></tr>\n",
       "<tr><td>No            </td><td style=\"text-align: right;\">40.69</td><td>No       </td><td>No               </td><td>No      </td><td style=\"text-align: right;\">               0</td><td style=\"text-align: right;\">             0</td><td>Yes          </td><td>Male  </td><td>65-69        </td><td>White </td><td>No                     </td><td>Yes               </td><td>Good       </td><td style=\"text-align: right;\">         10</td><td>No      </td><td>No             </td><td>No          </td></tr>\n",
       "<tr><td>Yes           </td><td style=\"text-align: right;\">34.3 </td><td>Yes      </td><td>No               </td><td>No      </td><td style=\"text-align: right;\">              30</td><td style=\"text-align: right;\">             0</td><td>Yes          </td><td>Male  </td><td>60-64        </td><td>White </td><td>Yes                    </td><td>No                </td><td>Poor       </td><td style=\"text-align: right;\">         15</td><td>Yes     </td><td>No             </td><td>No          </td></tr>\n",
       "<tr><td>No            </td><td style=\"text-align: right;\">28.71</td><td>Yes      </td><td>No               </td><td>No      </td><td style=\"text-align: right;\">               0</td><td style=\"text-align: right;\">             0</td><td>No           </td><td>Female</td><td>55-59        </td><td>White </td><td>No                     </td><td>Yes               </td><td>Very good  </td><td style=\"text-align: right;\">          5</td><td>No      </td><td>No             </td><td>No          </td></tr>\n",
       "<tr><td>No            </td><td style=\"text-align: right;\">28.37</td><td>Yes      </td><td>No               </td><td>No      </td><td style=\"text-align: right;\">               0</td><td style=\"text-align: right;\">             0</td><td>Yes          </td><td>Male  </td><td>75-79        </td><td>White </td><td>Yes                    </td><td>Yes               </td><td>Very good  </td><td style=\"text-align: right;\">          8</td><td>No      </td><td>No             </td><td>No          </td></tr>\n",
       "</tbody>\n",
       "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[223898 rows x 18 columns]</pre>"
      ],
      "text/plain": [
       "HeartDisease      BMI  Smoking    AlcoholDrinking    Stroke      PhysicalHealth    MentalHealth  DiffWalking    Sex     AgeCategory    Race    Diabetic                 PhysicalActivity    GenHealth      SleepTime  Asthma    KidneyDisease    SkinCancer\n",
       "--------------  -----  ---------  -----------------  --------  ----------------  --------------  -------------  ------  -------------  ------  -----------------------  ------------------  -----------  -----------  --------  ---------------  ------------\n",
       "No              16.6   Yes        No                 No                       3              30  No             Female  55-59          White   Yes                      Yes                 Very good              5  Yes       No               Yes\n",
       "No              20.34  No         No                 Yes                      0               0  No             Female  80 or older    White   No                       Yes                 Very good              7  No        No               No\n",
       "Yes             28.87  Yes        No                 No                       6               0  Yes            Female  75-79          Black   No                       No                  Fair                  12  No        No               No\n",
       "No              21.63  No         No                 No                      15               0  No             Female  70-74          White   No                       Yes                 Fair                   4  Yes       No               Yes\n",
       "No              31.64  Yes        No                 No                       5               0  Yes            Female  80 or older    White   Yes                      No                  Good                   9  Yes       No               No\n",
       "No              26.45  No         No                 No                       0               0  No             Female  80 or older    White   No, borderline diabetes  No                  Fair                   5  No        Yes              No\n",
       "No              40.69  No         No                 No                       0               0  Yes            Male    65-69          White   No                       Yes                 Good                  10  No        No               No\n",
       "Yes             34.3   Yes        No                 No                      30               0  Yes            Male    60-64          White   Yes                      No                  Poor                  15  Yes       No               No\n",
       "No              28.71  Yes        No                 No                       0               0  No             Female  55-59          White   No                       Yes                 Very good              5  No        No               No\n",
       "No              28.37  Yes        No                 No                       0               0  Yes            Male    75-79          White   Yes                      Yes                 Very good              8  No        No               No\n",
       "[223898 rows x 18 columns]\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47804af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing target variable from dataset. to create input varaibles and output (or) target variable.\n",
    "y = \"HeartDisease\"\n",
    "x = df.columns\n",
    "x.remove(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13081f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using H2O automl\n",
    "#Setting models thresold to \"10\", more models we use it takes more time to come up with the best model and hyperparameters. \n",
    "#To create a simpler model we are excluding \"StackedEnsemble\" and \"DeepLearning\", tho they are really good. \n",
    "aml = H2OAutoML(max_models = 10, seed = 10, exclude_algos = [\"StackedEnsemble\", \"DeepLearning\"], verbosity=\"info\", nfolds=0)\n",
    "#taken from references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87dbb252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |\n",
      "21:28:40.63: Project: AutoML_3_20221108_212840\n",
      "21:28:40.64: Cross-validation disabled by user: no fold column nor nfolds > 1.\n",
      "21:28:40.64: Setting stopping tolerance adaptively based on the training frame: 0.0021133668599572068\n",
      "21:28:40.64: Build control seed: 10\n",
      "21:28:40.64: training frame: Frame key: AutoML_3_20221108_212840_training_py_10_sid_b108    cols: 18    rows: 223898  chunks: 16    size: 2454836  checksum: 5119352645841490734\n",
      "21:28:40.65: validation frame: Frame key: py_12_sid_b108    cols: 18    rows: 47867  chunks: 16    size: 643537  checksum: 7923063591121785633\n",
      "21:28:40.65: leaderboard frame: Frame key: py_12_sid_b108    cols: 18    rows: 47867  chunks: 16    size: 643537  checksum: 7923063591121785633\n",
      "21:28:40.65: blending frame: NULL\n",
      "21:28:40.65: response column: HeartDisease\n",
      "21:28:40.65: fold column: null\n",
      "21:28:40.65: weights column: null\n",
      "21:28:40.80: Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (7g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (7g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (6g, 60w)]}, {StackedEnsemble : [monotonic (9g, 10w), best_of_family_xglm (10g, 10w), all_xglm (10g, 10w)]}]\n",
      "21:28:40.81: Disabling Algo: DeepLearning as requested by the user.\n",
      "21:28:40.81: Disabling Algo: StackedEnsemble as requested by the user.\n",
      "21:28:40.82: AutoML job created: 2022.11.08 21:28:40.59\n",
      "21:28:40.94: AutoML build started: 2022.11.08 21:28:40.93\n",
      "21:28:40.123: AutoML: starting XGBoost_1_AutoML_3_20221108_212840 model training\n",
      "\n",
      "██\n",
      "21:30:12.676: New leader: XGBoost_1_AutoML_3_20221108_212840, auc: 0.8295863651690569\n",
      "21:30:12.678: AutoML: starting GLM_1_AutoML_3_20221108_212840 model training\n",
      "\n",
      "██\n",
      "21:30:27.219: New leader: GLM_1_AutoML_3_20221108_212840, auc: 0.8403453470842085\n",
      "21:30:27.232: AutoML: starting GBM_1_AutoML_3_20221108_212840 model training\n",
      "\n",
      "██\n",
      "21:30:46.104: AutoML: starting XGBoost_2_AutoML_3_20221108_212840 model training\n",
      "\n",
      "██████████\n",
      "21:31:48.950: AutoML: starting DRF_1_AutoML_3_20221108_212840 model training\n",
      "\n",
      "███\n",
      "21:32:26.285: AutoML: starting GBM_2_AutoML_3_20221108_212840 model training\n",
      "21:32:38.526: New leader: GBM_2_AutoML_3_20221108_212840, auc: 0.8445896056068984\n",
      "21:32:38.535: AutoML: starting GBM_3_AutoML_3_20221108_212840 model training\n",
      "\n",
      "██\n",
      "21:32:52.54: AutoML: starting GBM_4_AutoML_3_20221108_212840 model training\n",
      "\n",
      "█\n",
      "21:33:05.417: AutoML: starting XGBoost_3_AutoML_3_20221108_212840 model training\n",
      "\n",
      "██████\n",
      "21:33:49.361: AutoML: starting XRT_1_AutoML_3_20221108_212840 model training\n",
      "\n",
      "██\n",
      "21:34:21.190: Skipping StackedEnsemble 'monotonic' due to the exclude_algos option or it is already trained.\n",
      "21:34:21.190: Skipping StackedEnsemble 'best_of_family_xglm' due to the exclude_algos option or it is already trained.\n",
      "21:34:21.191: Skipping StackedEnsemble 'all_xglm' due to the exclude_algos option or it is already trained.\n",
      "21:34:21.191: Actual modeling steps: [{XGBoost : [def_2 (1g, 10w)]}, {GLM : [def_1 (1g, 10w)]}, {GBM : [def_5 (1g, 10w)]}, {XGBoost : [def_1 (2g, 10w)]}, {DRF : [def_1 (2g, 10w)]}, {GBM : [def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w)]}, {XGBoost : [def_3 (3g, 10w)]}, {DRF : [XRT (3g, 10w)]}]\n",
      "21:34:21.191: AutoML build stopped: 2022.11.08 21:34:21.191\n",
      "21:34:21.191: AutoML build done: built 10 models\n",
      "21:34:21.191: AutoML duration:  5 min 41.098 sec\n",
      "\n",
      "█████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
       "=============\n",
       "H2OGradientBoostingEstimator : Gradient Boosting Machine\n",
       "Model Key: GBM_2_AutoML_3_20221108_212840\n",
       "</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-2.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-2 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-2 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-2 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table th,\n",
       "#h2o-table-2 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-2 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-2\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Model Summary: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>number_of_trees</th>\n",
       "<th>number_of_internal_trees</th>\n",
       "<th>model_size_in_bytes</th>\n",
       "<th>min_depth</th>\n",
       "<th>max_depth</th>\n",
       "<th>mean_depth</th>\n",
       "<th>min_leaves</th>\n",
       "<th>max_leaves</th>\n",
       "<th>mean_leaves</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>60.0</td>\n",
       "<td>60.0</td>\n",
       "<td>82587.0</td>\n",
       "<td>7.0</td>\n",
       "<td>7.0</td>\n",
       "<td>6.883333</td>\n",
       "<td>1.0</td>\n",
       "<td>126.0</td>\n",
       "<td>104.98333</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: gbm\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.06235065757957192\n",
       "RMSE: 0.24970113652038495\n",
       "LogLoss: 0.2162922799323176\n",
       "Mean Per-Class Error: 0.2818640244158738\n",
       "AUC: 0.8576394651442227\n",
       "AUCPR: 0.42026254210495456\n",
       "Gini: 0.7152789302884455</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-3.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-3 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-3 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-3 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-3 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-3 .h2o-table th,\n",
       "#h2o-table-3 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-3 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-3\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.21090732948169086</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>No</th>\n",
       "<th>Yes</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>No</td>\n",
       "<td>187394.0</td>\n",
       "<td>17312.0</td>\n",
       "<td>0.0846</td>\n",
       "<td> (17312.0/204706.0)</td></tr>\n",
       "<tr><td>Yes</td>\n",
       "<td>9196.0</td>\n",
       "<td>9996.0</td>\n",
       "<td>0.4792</td>\n",
       "<td> (9196.0/19192.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>196590.0</td>\n",
       "<td>27308.0</td>\n",
       "<td>0.1184</td>\n",
       "<td> (26508.0/223898.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-4.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-4 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-4 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-4 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-4 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-4 .h2o-table th,\n",
       "#h2o-table-4 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-4 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-4\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.2109073</td>\n",
       "<td>0.4299355</td>\n",
       "<td>201.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1090870</td>\n",
       "<td>0.5413970</td>\n",
       "<td>275.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.3542844</td>\n",
       "<td>0.4466645</td>\n",
       "<td>128.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4626136</td>\n",
       "<td>0.9204325</td>\n",
       "<td>85.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9372221</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0047356</td>\n",
       "<td>1.0</td>\n",
       "<td>398.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9372221</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.2109073</td>\n",
       "<td>0.3732132</td>\n",
       "<td>201.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.1019551</td>\n",
       "<td>0.7752924</td>\n",
       "<td>281.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.0859754</td>\n",
       "<td>0.7770224</td>\n",
       "<td>294.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9372221</td>\n",
       "<td>204706.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9372221</td>\n",
       "<td>19189.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0042138</td>\n",
       "<td>204706.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0047356</td>\n",
       "<td>19192.0</td>\n",
       "<td>398.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9372221</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9372221</td>\n",
       "<td>0.9998437</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0042138</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0047356</td>\n",
       "<td>1.0</td>\n",
       "<td>398.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-5.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-5 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-5 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-5 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-5 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-5 .h2o-table th,\n",
       "#h2o-table-5 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-5 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-5\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate:  8.57 %, avg score:  8.58 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0100001</td>\n",
       "<td>0.5445738</td>\n",
       "<td>8.7848319</td>\n",
       "<td>8.7848319</td>\n",
       "<td>0.7530147</td>\n",
       "<td>0.6335674</td>\n",
       "<td>0.7530147</td>\n",
       "<td>0.6335674</td>\n",
       "<td>0.0878491</td>\n",
       "<td>0.0878491</td>\n",
       "<td>778.4831908</td>\n",
       "<td>778.4831908</td>\n",
       "<td>0.0851477</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0200002</td>\n",
       "<td>0.4626759</td>\n",
       "<td>6.4661782</td>\n",
       "<td>7.6255050</td>\n",
       "<td>0.5542653</td>\n",
       "<td>0.4991629</td>\n",
       "<td>0.6536400</td>\n",
       "<td>0.5663651</td>\n",
       "<td>0.0646624</td>\n",
       "<td>0.1525115</td>\n",
       "<td>546.6178172</td>\n",
       "<td>662.5505040</td>\n",
       "<td>0.1449347</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0300003</td>\n",
       "<td>0.4105801</td>\n",
       "<td>5.4970330</td>\n",
       "<td>6.9160144</td>\n",
       "<td>0.4711925</td>\n",
       "<td>0.4346842</td>\n",
       "<td>0.5928242</td>\n",
       "<td>0.5224715</td>\n",
       "<td>0.0549708</td>\n",
       "<td>0.2074823</td>\n",
       "<td>449.7033015</td>\n",
       "<td>591.6014365</td>\n",
       "<td>0.1941217</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0400004</td>\n",
       "<td>0.3732927</td>\n",
       "<td>4.6320970</td>\n",
       "<td>6.3450350</td>\n",
       "<td>0.3970523</td>\n",
       "<td>0.3908190</td>\n",
       "<td>0.5438812</td>\n",
       "<td>0.4895584</td>\n",
       "<td>0.0463214</td>\n",
       "<td>0.2538037</td>\n",
       "<td>363.2097014</td>\n",
       "<td>534.5035027</td>\n",
       "<td>0.2338482</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0500004</td>\n",
       "<td>0.3407455</td>\n",
       "<td>4.3038382</td>\n",
       "<td>5.9367957</td>\n",
       "<td>0.3689147</td>\n",
       "<td>0.3567826</td>\n",
       "<td>0.5088879</td>\n",
       "<td>0.4630032</td>\n",
       "<td>0.0430388</td>\n",
       "<td>0.2968424</td>\n",
       "<td>330.3838171</td>\n",
       "<td>493.6795656</td>\n",
       "<td>0.2699844</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1000009</td>\n",
       "<td>0.2406339</td>\n",
       "<td>3.3232300</td>\n",
       "<td>4.6300128</td>\n",
       "<td>0.2848593</td>\n",
       "<td>0.2858955</td>\n",
       "<td>0.3968736</td>\n",
       "<td>0.3744493</td>\n",
       "<td>0.1661630</td>\n",
       "<td>0.4630054</td>\n",
       "<td>232.3230006</td>\n",
       "<td>363.0012831</td>\n",
       "<td>0.3970376</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1500013</td>\n",
       "<td>0.1791957</td>\n",
       "<td>2.3759688</td>\n",
       "<td>3.8786648</td>\n",
       "<td>0.2036623</td>\n",
       "<td>0.2078666</td>\n",
       "<td>0.3324699</td>\n",
       "<td>0.3189218</td>\n",
       "<td>0.1187995</td>\n",
       "<td>0.5818049</td>\n",
       "<td>137.5968772</td>\n",
       "<td>287.8664811</td>\n",
       "<td>0.4722869</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2000018</td>\n",
       "<td>0.1416549</td>\n",
       "<td>1.8674281</td>\n",
       "<td>3.3758556</td>\n",
       "<td>0.1600715</td>\n",
       "<td>0.1604630</td>\n",
       "<td>0.2893703</td>\n",
       "<td>0.2793071</td>\n",
       "<td>0.0933722</td>\n",
       "<td>0.6751772</td>\n",
       "<td>86.7428088</td>\n",
       "<td>237.5855630</td>\n",
       "<td>0.5197249</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3000027</td>\n",
       "<td>0.0882667</td>\n",
       "<td>1.3020934</td>\n",
       "<td>2.6846016</td>\n",
       "<td>0.1116123</td>\n",
       "<td>0.1133023</td>\n",
       "<td>0.2301176</td>\n",
       "<td>0.2239721</td>\n",
       "<td>0.1302105</td>\n",
       "<td>0.8053877</td>\n",
       "<td>30.2093413</td>\n",
       "<td>168.4601558</td>\n",
       "<td>0.5527668</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.3999991</td>\n",
       "<td>0.0556348</td>\n",
       "<td>0.8024463</td>\n",
       "<td>2.2140785</td>\n",
       "<td>0.0687838</td>\n",
       "<td>0.0705778</td>\n",
       "<td>0.1897855</td>\n",
       "<td>0.1856248</td>\n",
       "<td>0.0802418</td>\n",
       "<td>0.8856294</td>\n",
       "<td>-19.7553654</td>\n",
       "<td>121.4078517</td>\n",
       "<td>0.5311601</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5000536</td>\n",
       "<td>0.0345582</td>\n",
       "<td>0.4962906</td>\n",
       "<td>1.8703706</td>\n",
       "<td>0.0425408</td>\n",
       "<td>0.0447486</td>\n",
       "<td>0.1603237</td>\n",
       "<td>0.1574373</td>\n",
       "<td>0.0496561</td>\n",
       "<td>0.9352855</td>\n",
       "<td>-50.3709357</td>\n",
       "<td>87.0370583</td>\n",
       "<td>0.4760367</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6000009</td>\n",
       "<td>0.0216793</td>\n",
       "<td>0.3008046</td>\n",
       "<td>1.6089145</td>\n",
       "<td>0.0257843</td>\n",
       "<td>0.0275263</td>\n",
       "<td>0.1379123</td>\n",
       "<td>0.1357969</td>\n",
       "<td>0.0300646</td>\n",
       "<td>0.9653501</td>\n",
       "<td>-69.9195366</td>\n",
       "<td>60.8914515</td>\n",
       "<td>0.3996022</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.6999973</td>\n",
       "<td>0.0142479</td>\n",
       "<td>0.1630946</td>\n",
       "<td>1.4023754</td>\n",
       "<td>0.0139801</td>\n",
       "<td>0.0176377</td>\n",
       "<td>0.1202083</td>\n",
       "<td>0.1189175</td>\n",
       "<td>0.0163089</td>\n",
       "<td>0.9816590</td>\n",
       "<td>-83.6905386</td>\n",
       "<td>40.2375404</td>\n",
       "<td>0.3080686</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.8000027</td>\n",
       "<td>0.0098226</td>\n",
       "<td>0.0932630</td>\n",
       "<td>1.2387281</td>\n",
       "<td>0.0079943</td>\n",
       "<td>0.0119307</td>\n",
       "<td>0.1061808</td>\n",
       "<td>0.1055435</td>\n",
       "<td>0.0093268</td>\n",
       "<td>0.9909858</td>\n",
       "<td>-90.6736970</td>\n",
       "<td>23.8728135</td>\n",
       "<td>0.2088886</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8999991</td>\n",
       "<td>0.0067844</td>\n",
       "<td>0.0583597</td>\n",
       "<td>1.1075806</td>\n",
       "<td>0.0050025</td>\n",
       "<td>0.0082757</td>\n",
       "<td>0.0949392</td>\n",
       "<td>0.0947363</td>\n",
       "<td>0.0058358</td>\n",
       "<td>0.9968216</td>\n",
       "<td>-94.1640266</td>\n",
       "<td>10.7580646</td>\n",
       "<td>0.1059000</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0037749</td>\n",
       "<td>0.0317838</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0027244</td>\n",
       "<td>0.0055917</td>\n",
       "<td>0.0857176</td>\n",
       "<td>0.0858218</td>\n",
       "<td>0.0031784</td>\n",
       "<td>1.0</td>\n",
       "<td>-96.8216207</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: gbm\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.06627360066228435\n",
       "RMSE: 0.25743659542163844\n",
       "LogLoss: 0.22727388362363\n",
       "Mean Per-Class Error: 0.2675555572976968\n",
       "AUC: 0.8445896056068984\n",
       "AUCPR: 0.344396693762911\n",
       "Gini: 0.6891792112137969</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-6.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-6 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-6 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-6 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-6 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-6 .h2o-table th,\n",
       "#h2o-table-6 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-6 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-6\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.16511319188107634</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>No</th>\n",
       "<th>Yes</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>No</td>\n",
       "<td>38121.0</td>\n",
       "<td>5597.0</td>\n",
       "<td>0.128</td>\n",
       "<td> (5597.0/43718.0)</td></tr>\n",
       "<tr><td>Yes</td>\n",
       "<td>1689.0</td>\n",
       "<td>2460.0</td>\n",
       "<td>0.4071</td>\n",
       "<td> (1689.0/4149.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>39810.0</td>\n",
       "<td>8057.0</td>\n",
       "<td>0.1522</td>\n",
       "<td> (7286.0/47867.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-7.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-7 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-7 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-7 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-7 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-7 .h2o-table th,\n",
       "#h2o-table-7 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-7 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-7\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.1651132</td>\n",
       "<td>0.4030805</td>\n",
       "<td>226.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0980888</td>\n",
       "<td>0.5305332</td>\n",
       "<td>280.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.3334623</td>\n",
       "<td>0.3803156</td>\n",
       "<td>128.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4841676</td>\n",
       "<td>0.9150563</td>\n",
       "<td>68.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.8903495</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0046663</td>\n",
       "<td>1.0</td>\n",
       "<td>398.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.8903495</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.1651132</td>\n",
       "<td>0.3495974</td>\n",
       "<td>226.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.0980888</td>\n",
       "<td>0.7659677</td>\n",
       "<td>280.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.0783484</td>\n",
       "<td>0.7699481</td>\n",
       "<td>298.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.8903495</td>\n",
       "<td>43718.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.8903495</td>\n",
       "<td>4148.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0041809</td>\n",
       "<td>43718.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0046663</td>\n",
       "<td>4149.0</td>\n",
       "<td>398.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.8903495</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.8903495</td>\n",
       "<td>0.9997590</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0041809</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0046663</td>\n",
       "<td>1.0</td>\n",
       "<td>398.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-8.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-8 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-8 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-8 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-8 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-8 .h2o-table th,\n",
       "#h2o-table-8 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-8 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-8\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate:  8.67 %, avg score:  8.55 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0100069</td>\n",
       "<td>0.5382749</td>\n",
       "<td>6.4790233</td>\n",
       "<td>6.4790233</td>\n",
       "<td>0.5615866</td>\n",
       "<td>0.6256722</td>\n",
       "<td>0.5615866</td>\n",
       "<td>0.6256722</td>\n",
       "<td>0.0648349</td>\n",
       "<td>0.0648349</td>\n",
       "<td>547.9023293</td>\n",
       "<td>547.9023293</td>\n",
       "<td>0.0600314</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0200138</td>\n",
       "<td>0.4616204</td>\n",
       "<td>5.9009692</td>\n",
       "<td>6.1899962</td>\n",
       "<td>0.5114823</td>\n",
       "<td>0.4965781</td>\n",
       "<td>0.5365344</td>\n",
       "<td>0.5611251</td>\n",
       "<td>0.0590504</td>\n",
       "<td>0.1238853</td>\n",
       "<td>490.0969170</td>\n",
       "<td>518.9996231</td>\n",
       "<td>0.1137293</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0299998</td>\n",
       "<td>0.4088819</td>\n",
       "<td>4.4651557</td>\n",
       "<td>5.6158501</td>\n",
       "<td>0.3870293</td>\n",
       "<td>0.4341375</td>\n",
       "<td>0.4867688</td>\n",
       "<td>0.5188549</td>\n",
       "<td>0.0445891</td>\n",
       "<td>0.1684743</td>\n",
       "<td>346.5155691</td>\n",
       "<td>461.5850146</td>\n",
       "<td>0.1516163</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0400067</td>\n",
       "<td>0.3698618</td>\n",
       "<td>4.4076627</td>\n",
       "<td>5.3136456</td>\n",
       "<td>0.3820459</td>\n",
       "<td>0.3878727</td>\n",
       "<td>0.4605744</td>\n",
       "<td>0.4860922</td>\n",
       "<td>0.0441070</td>\n",
       "<td>0.2125813</td>\n",
       "<td>340.7662686</td>\n",
       "<td>431.3645554</td>\n",
       "<td>0.1889526</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0500136</td>\n",
       "<td>0.3372058</td>\n",
       "<td>3.7814374</td>\n",
       "<td>5.0070759</td>\n",
       "<td>0.3277662</td>\n",
       "<td>0.3539796</td>\n",
       "<td>0.4340017</td>\n",
       "<td>0.4596587</td>\n",
       "<td>0.0378404</td>\n",
       "<td>0.2504218</td>\n",
       "<td>278.1437386</td>\n",
       "<td>400.7075917</td>\n",
       "<td>0.2194277</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1000063</td>\n",
       "<td>0.2396934</td>\n",
       "<td>3.3024834</td>\n",
       "<td>4.1549577</td>\n",
       "<td>0.2862516</td>\n",
       "<td>0.2839509</td>\n",
       "<td>0.3601421</td>\n",
       "<td>0.3718232</td>\n",
       "<td>0.1651000</td>\n",
       "<td>0.4155218</td>\n",
       "<td>230.2483432</td>\n",
       "<td>315.4957718</td>\n",
       "<td>0.3454591</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1500407</td>\n",
       "<td>0.1775183</td>\n",
       "<td>2.5771580</td>\n",
       "<td>3.6288048</td>\n",
       "<td>0.2233820</td>\n",
       "<td>0.2065748</td>\n",
       "<td>0.3145363</td>\n",
       "<td>0.3167174</td>\n",
       "<td>0.1289467</td>\n",
       "<td>0.5444685</td>\n",
       "<td>157.7157964</td>\n",
       "<td>262.8804779</td>\n",
       "<td>0.4318605</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2000334</td>\n",
       "<td>0.1414024</td>\n",
       "<td>2.0634495</td>\n",
       "<td>3.2375886</td>\n",
       "<td>0.1788550</td>\n",
       "<td>0.1595248</td>\n",
       "<td>0.2806266</td>\n",
       "<td>0.2774315</td>\n",
       "<td>0.1031574</td>\n",
       "<td>0.6476259</td>\n",
       "<td>106.3449502</td>\n",
       "<td>223.7588572</td>\n",
       "<td>0.4900707</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.2999979</td>\n",
       "<td>0.0883530</td>\n",
       "<td>1.4225346</td>\n",
       "<td>2.6327812</td>\n",
       "<td>0.1233020</td>\n",
       "<td>0.1131431</td>\n",
       "<td>0.2282033</td>\n",
       "<td>0.2226878</td>\n",
       "<td>0.1422029</td>\n",
       "<td>0.7898289</td>\n",
       "<td>42.2534619</td>\n",
       "<td>163.2781249</td>\n",
       "<td>0.5363177</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4000251</td>\n",
       "<td>0.0555852</td>\n",
       "<td>0.8602147</td>\n",
       "<td>2.1895470</td>\n",
       "<td>0.0745614</td>\n",
       "<td>0.0701890</td>\n",
       "<td>0.1897848</td>\n",
       "<td>0.1845551</td>\n",
       "<td>0.0860448</td>\n",
       "<td>0.8758737</td>\n",
       "<td>-13.9785321</td>\n",
       "<td>118.9547034</td>\n",
       "<td>0.5210084</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5000313</td>\n",
       "<td>0.0349450</td>\n",
       "<td>0.5735963</td>\n",
       "<td>1.8663569</td>\n",
       "<td>0.0497180</td>\n",
       "<td>0.0450287</td>\n",
       "<td>0.1617715</td>\n",
       "<td>0.1566498</td>\n",
       "<td>0.0573632</td>\n",
       "<td>0.9332369</td>\n",
       "<td>-42.6403749</td>\n",
       "<td>86.6356878</td>\n",
       "<td>0.4743184</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6000376</td>\n",
       "<td>0.0217499</td>\n",
       "<td>0.2940283</td>\n",
       "<td>1.6043021</td>\n",
       "<td>0.0254857</td>\n",
       "<td>0.0277017</td>\n",
       "<td>0.1390572</td>\n",
       "<td>0.1351585</td>\n",
       "<td>0.0294047</td>\n",
       "<td>0.9626416</td>\n",
       "<td>-70.5971670</td>\n",
       "<td>60.4302120</td>\n",
       "<td>0.3970165</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.7000021</td>\n",
       "<td>0.0142890</td>\n",
       "<td>0.1663642</td>\n",
       "<td>1.3989560</td>\n",
       "<td>0.0144201</td>\n",
       "<td>0.0176854</td>\n",
       "<td>0.1212582</td>\n",
       "<td>0.1183826</td>\n",
       "<td>0.0166305</td>\n",
       "<td>0.9792721</td>\n",
       "<td>-83.3635782</td>\n",
       "<td>39.8955987</td>\n",
       "<td>0.3057738</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.8000292</td>\n",
       "<td>0.0098844</td>\n",
       "<td>0.1180687</td>\n",
       "<td>1.2388074</td>\n",
       "<td>0.0102339</td>\n",
       "<td>0.0119730</td>\n",
       "<td>0.1073769</td>\n",
       "<td>0.1050783</td>\n",
       "<td>0.0118101</td>\n",
       "<td>0.9910822</td>\n",
       "<td>-88.1931319</td>\n",
       "<td>23.8807445</td>\n",
       "<td>0.2091846</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8999937</td>\n",
       "<td>0.0067875</td>\n",
       "<td>0.0554547</td>\n",
       "<td>1.1073696</td>\n",
       "<td>0.0048067</td>\n",
       "<td>0.0083120</td>\n",
       "<td>0.0959842</td>\n",
       "<td>0.0943302</td>\n",
       "<td>0.0055435</td>\n",
       "<td>0.9966257</td>\n",
       "<td>-94.4545261</td>\n",
       "<td>10.7369592</td>\n",
       "<td>0.1058027</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0035774</td>\n",
       "<td>0.0337410</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0029246</td>\n",
       "<td>0.0055841</td>\n",
       "<td>0.0866777</td>\n",
       "<td>0.0854551</td>\n",
       "<td>0.0033743</td>\n",
       "<td>1.0</td>\n",
       "<td>-96.6259044</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-9.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-9 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-9 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-9 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-9 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-9 .h2o-table th,\n",
       "#h2o-table-9 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-9 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-9\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Scoring History: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>timestamp</th>\n",
       "<th>duration</th>\n",
       "<th>number_of_trees</th>\n",
       "<th>training_rmse</th>\n",
       "<th>training_logloss</th>\n",
       "<th>training_auc</th>\n",
       "<th>training_pr_auc</th>\n",
       "<th>training_lift</th>\n",
       "<th>training_classification_error</th>\n",
       "<th>validation_rmse</th>\n",
       "<th>validation_logloss</th>\n",
       "<th>validation_auc</th>\n",
       "<th>validation_pr_auc</th>\n",
       "<th>validation_lift</th>\n",
       "<th>validation_classification_error</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>2022-11-08 21:32:26</td>\n",
       "<td> 0.009 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>0.2799466</td>\n",
       "<td>0.2925163</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0857176</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9142824</td>\n",
       "<td>0.2813638</td>\n",
       "<td>0.2947889</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0866777</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9133223</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2022-11-08 21:32:27</td>\n",
       "<td> 0.877 sec</td>\n",
       "<td>5.0</td>\n",
       "<td>0.2658376</td>\n",
       "<td>0.2546183</td>\n",
       "<td>0.8363275</td>\n",
       "<td>0.3599911</td>\n",
       "<td>7.4755399</td>\n",
       "<td>0.1224218</td>\n",
       "<td>0.2681675</td>\n",
       "<td>0.2583809</td>\n",
       "<td>0.8334614</td>\n",
       "<td>0.3321727</td>\n",
       "<td>6.5857024</td>\n",
       "<td>0.1517747</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2022-11-08 21:32:28</td>\n",
       "<td> 1.890 sec</td>\n",
       "<td>10.0</td>\n",
       "<td>0.2594292</td>\n",
       "<td>0.2402577</td>\n",
       "<td>0.8399221</td>\n",
       "<td>0.3714404</td>\n",
       "<td>7.7740031</td>\n",
       "<td>0.1143735</td>\n",
       "<td>0.2626026</td>\n",
       "<td>0.2447966</td>\n",
       "<td>0.8370798</td>\n",
       "<td>0.3361224</td>\n",
       "<td>6.5753656</td>\n",
       "<td>0.1431466</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2022-11-08 21:32:29</td>\n",
       "<td> 2.983 sec</td>\n",
       "<td>15.0</td>\n",
       "<td>0.2559473</td>\n",
       "<td>0.2316768</td>\n",
       "<td>0.8448092</td>\n",
       "<td>0.3802619</td>\n",
       "<td>7.9840660</td>\n",
       "<td>0.1191569</td>\n",
       "<td>0.2597315</td>\n",
       "<td>0.2368575</td>\n",
       "<td>0.8407413</td>\n",
       "<td>0.3411091</td>\n",
       "<td>6.6235368</td>\n",
       "<td>0.1569557</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2022-11-08 21:32:30</td>\n",
       "<td> 3.940 sec</td>\n",
       "<td>20.0</td>\n",
       "<td>0.2540282</td>\n",
       "<td>0.2264226</td>\n",
       "<td>0.8481993</td>\n",
       "<td>0.3872783</td>\n",
       "<td>8.1038530</td>\n",
       "<td>0.1199743</td>\n",
       "<td>0.2583671</td>\n",
       "<td>0.2322946</td>\n",
       "<td>0.8428656</td>\n",
       "<td>0.3436049</td>\n",
       "<td>6.6476224</td>\n",
       "<td>0.1464892</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2022-11-08 21:32:31</td>\n",
       "<td> 4.924 sec</td>\n",
       "<td>25.0</td>\n",
       "<td>0.2528989</td>\n",
       "<td>0.2233516</td>\n",
       "<td>0.8505143</td>\n",
       "<td>0.3930873</td>\n",
       "<td>8.2221025</td>\n",
       "<td>0.1232258</td>\n",
       "<td>0.2577834</td>\n",
       "<td>0.2300011</td>\n",
       "<td>0.8438623</td>\n",
       "<td>0.3443956</td>\n",
       "<td>6.5994512</td>\n",
       "<td>0.1497900</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2022-11-08 21:32:32</td>\n",
       "<td> 5.941 sec</td>\n",
       "<td>30.0</td>\n",
       "<td>0.2522093</td>\n",
       "<td>0.2215122</td>\n",
       "<td>0.8517722</td>\n",
       "<td>0.3972680</td>\n",
       "<td>8.3211012</td>\n",
       "<td>0.1234982</td>\n",
       "<td>0.2575651</td>\n",
       "<td>0.2288354</td>\n",
       "<td>0.8442298</td>\n",
       "<td>0.3446230</td>\n",
       "<td>6.5512801</td>\n",
       "<td>0.1431884</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2022-11-08 21:32:33</td>\n",
       "<td> 6.879 sec</td>\n",
       "<td>35.0</td>\n",
       "<td>0.2516312</td>\n",
       "<td>0.2201344</td>\n",
       "<td>0.8527761</td>\n",
       "<td>0.4019793</td>\n",
       "<td>8.4148894</td>\n",
       "<td>0.1197733</td>\n",
       "<td>0.2574547</td>\n",
       "<td>0.2280901</td>\n",
       "<td>0.8444687</td>\n",
       "<td>0.3448317</td>\n",
       "<td>6.4549377</td>\n",
       "<td>0.1395742</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2022-11-08 21:32:34</td>\n",
       "<td> 7.853 sec</td>\n",
       "<td>40.0</td>\n",
       "<td>0.2511534</td>\n",
       "<td>0.2190832</td>\n",
       "<td>0.8539359</td>\n",
       "<td>0.4060557</td>\n",
       "<td>8.4513626</td>\n",
       "<td>0.1195723</td>\n",
       "<td>0.2573935</td>\n",
       "<td>0.2276656</td>\n",
       "<td>0.8446942</td>\n",
       "<td>0.3447744</td>\n",
       "<td>6.6717080</td>\n",
       "<td>0.1376314</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2022-11-08 21:32:35</td>\n",
       "<td> 8.830 sec</td>\n",
       "<td>45.0</td>\n",
       "<td>0.2507598</td>\n",
       "<td>0.2182248</td>\n",
       "<td>0.8549616</td>\n",
       "<td>0.4097193</td>\n",
       "<td>8.5399404</td>\n",
       "<td>0.1133775</td>\n",
       "<td>0.2573839</td>\n",
       "<td>0.2274303</td>\n",
       "<td>0.8446926</td>\n",
       "<td>0.3445531</td>\n",
       "<td>6.6717080</td>\n",
       "<td>0.1501243</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2022-11-08 21:32:36</td>\n",
       "<td> 9.742 sec</td>\n",
       "<td>50.0</td>\n",
       "<td>0.2504282</td>\n",
       "<td>0.2175424</td>\n",
       "<td>0.8559820</td>\n",
       "<td>0.4128287</td>\n",
       "<td>8.6233077</td>\n",
       "<td>0.1208095</td>\n",
       "<td>0.2574263</td>\n",
       "<td>0.2273937</td>\n",
       "<td>0.8445852</td>\n",
       "<td>0.3441534</td>\n",
       "<td>6.6476224</td>\n",
       "<td>0.1544070</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2022-11-08 21:32:37</td>\n",
       "<td>10.749 sec</td>\n",
       "<td>55.0</td>\n",
       "<td>0.2500195</td>\n",
       "<td>0.2168282</td>\n",
       "<td>0.8569342</td>\n",
       "<td>0.4170367</td>\n",
       "<td>8.7535692</td>\n",
       "<td>0.1193267</td>\n",
       "<td>0.2574419</td>\n",
       "<td>0.2273305</td>\n",
       "<td>0.8445800</td>\n",
       "<td>0.3442528</td>\n",
       "<td>6.4549377</td>\n",
       "<td>0.1525686</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2022-11-08 21:32:38</td>\n",
       "<td>11.732 sec</td>\n",
       "<td>60.0</td>\n",
       "<td>0.2497011</td>\n",
       "<td>0.2162923</td>\n",
       "<td>0.8576395</td>\n",
       "<td>0.4202625</td>\n",
       "<td>8.7848319</td>\n",
       "<td>0.1183932</td>\n",
       "<td>0.2574366</td>\n",
       "<td>0.2272739</td>\n",
       "<td>0.8445896</td>\n",
       "<td>0.3443967</td>\n",
       "<td>6.4790233</td>\n",
       "<td>0.1522134</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-10.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-10 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-10 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-10 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-10 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-10 .h2o-table th,\n",
       "#h2o-table-10 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-10 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-10\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Variable Importances: </caption>\n",
       "    <thead><tr><th>variable</th>\n",
       "<th>relative_importance</th>\n",
       "<th>scaled_importance</th>\n",
       "<th>percentage</th></tr></thead>\n",
       "    <tbody><tr><td>GenHealth</td>\n",
       "<td>3887.2387695</td>\n",
       "<td>1.0</td>\n",
       "<td>0.2503293</td></tr>\n",
       "<tr><td>AgeCategory</td>\n",
       "<td>3791.9187012</td>\n",
       "<td>0.9754787</td>\n",
       "<td>0.2441909</td></tr>\n",
       "<tr><td>Stroke</td>\n",
       "<td>1866.4750977</td>\n",
       "<td>0.4801545</td>\n",
       "<td>0.1201967</td></tr>\n",
       "<tr><td>Diabetic</td>\n",
       "<td>859.2261353</td>\n",
       "<td>0.2210377</td>\n",
       "<td>0.0553322</td></tr>\n",
       "<tr><td>Sex</td>\n",
       "<td>833.8864746</td>\n",
       "<td>0.2145190</td>\n",
       "<td>0.0537004</td></tr>\n",
       "<tr><td>DiffWalking</td>\n",
       "<td>615.5896606</td>\n",
       "<td>0.1583617</td>\n",
       "<td>0.0396426</td></tr>\n",
       "<tr><td>PhysicalHealth</td>\n",
       "<td>611.5654907</td>\n",
       "<td>0.1573265</td>\n",
       "<td>0.0393834</td></tr>\n",
       "<tr><td>BMI</td>\n",
       "<td>551.5499268</td>\n",
       "<td>0.1418873</td>\n",
       "<td>0.0355186</td></tr>\n",
       "<tr><td>Race</td>\n",
       "<td>496.2322388</td>\n",
       "<td>0.1276567</td>\n",
       "<td>0.0319562</td></tr>\n",
       "<tr><td>KidneyDisease</td>\n",
       "<td>457.0770569</td>\n",
       "<td>0.1175840</td>\n",
       "<td>0.0294347</td></tr>\n",
       "<tr><td>SleepTime</td>\n",
       "<td>415.6210022</td>\n",
       "<td>0.1069193</td>\n",
       "<td>0.0267650</td></tr>\n",
       "<tr><td>Smoking</td>\n",
       "<td>340.5538025</td>\n",
       "<td>0.0876082</td>\n",
       "<td>0.0219309</td></tr>\n",
       "<tr><td>MentalHealth</td>\n",
       "<td>302.5711975</td>\n",
       "<td>0.0778370</td>\n",
       "<td>0.0194849</td></tr>\n",
       "<tr><td>SkinCancer</td>\n",
       "<td>241.5182953</td>\n",
       "<td>0.0621311</td>\n",
       "<td>0.0155532</td></tr>\n",
       "<tr><td>Asthma</td>\n",
       "<td>121.8171692</td>\n",
       "<td>0.0313377</td>\n",
       "<td>0.0078447</td></tr>\n",
       "<tr><td>PhysicalActivity</td>\n",
       "<td>79.5061951</td>\n",
       "<td>0.0204531</td>\n",
       "<td>0.0051200</td></tr>\n",
       "<tr><td>AlcoholDrinking</td>\n",
       "<td>56.1543579</td>\n",
       "<td>0.0144458</td>\n",
       "<td>0.0036162</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
      ],
      "text/plain": [
       "Model Details\n",
       "=============\n",
       "H2OGradientBoostingEstimator : Gradient Boosting Machine\n",
       "Model Key: GBM_2_AutoML_3_20221108_212840\n",
       "\n",
       "\n",
       "Model Summary: \n",
       "    number_of_trees    number_of_internal_trees    model_size_in_bytes    min_depth    max_depth    mean_depth    min_leaves    max_leaves    mean_leaves\n",
       "--  -----------------  --------------------------  ---------------------  -----------  -----------  ------------  ------------  ------------  -------------\n",
       "    60                 60                          82587                  7            7            6.88333       1             126           104.983\n",
       "\n",
       "ModelMetricsBinomial: gbm\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.06235065757957192\n",
       "RMSE: 0.24970113652038495\n",
       "LogLoss: 0.2162922799323176\n",
       "Mean Per-Class Error: 0.2818640244158738\n",
       "AUC: 0.8576394651442227\n",
       "AUCPR: 0.42026254210495456\n",
       "Gini: 0.7152789302884455\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.21090732948169086\n",
       "       No      Yes    Error    Rate\n",
       "-----  ------  -----  -------  ------------------\n",
       "No     187394  17312  0.0846   (17312.0/204706.0)\n",
       "Yes    9196    9996   0.4792   (9196.0/19192.0)\n",
       "Total  196590  27308  0.1184   (26508.0/223898.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.210907     0.429935  201\n",
       "max f2                       0.109087     0.541397  275\n",
       "max f0point5                 0.354284     0.446664  128\n",
       "max accuracy                 0.462614     0.920433  85\n",
       "max precision                0.937222     1         0\n",
       "max recall                   0.00473561   1         398\n",
       "max specificity              0.937222     1         0\n",
       "max absolute_mcc             0.210907     0.373213  201\n",
       "max min_per_class_accuracy   0.101955     0.775292  281\n",
       "max mean_per_class_accuracy  0.0859754    0.777022  294\n",
       "max tns                      0.937222     204706    0\n",
       "max fns                      0.937222     19189     0\n",
       "max fps                      0.00421379   204706    399\n",
       "max tps                      0.00473561   19192     398\n",
       "max tnr                      0.937222     1         0\n",
       "max fnr                      0.937222     0.999844  0\n",
       "max fpr                      0.00421379   1         399\n",
       "max tpr                      0.00473561   1         398\n",
       "\n",
       "Gains/Lift Table: Avg response rate:  8.57 %, avg score:  8.58 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0100001                   0.544574           8.78483    8.78483            0.753015         0.633567    0.753015                    0.633567            0.0878491       0.0878491                  778.483   778.483            0.0851477\n",
       "2        0.0200002                   0.462676           6.46618    7.62551            0.554265         0.499163    0.65364                     0.566365            0.0646624       0.152511                   546.618   662.551            0.144935\n",
       "3        0.0300003                   0.41058            5.49703    6.91601            0.471192         0.434684    0.592824                    0.522472            0.0549708       0.207482                   449.703   591.601            0.194122\n",
       "4        0.0400004                   0.373293           4.6321     6.34504            0.397052         0.390819    0.543881                    0.489558            0.0463214       0.253804                   363.21    534.504            0.233848\n",
       "5        0.0500004                   0.340745           4.30384    5.9368             0.368915         0.356783    0.508888                    0.463003            0.0430388       0.296842                   330.384   493.68             0.269984\n",
       "6        0.100001                    0.240634           3.32323    4.63001            0.284859         0.285895    0.396874                    0.374449            0.166163        0.463005                   232.323   363.001            0.397038\n",
       "7        0.150001                    0.179196           2.37597    3.87866            0.203662         0.207867    0.33247                     0.318922            0.118799        0.581805                   137.597   287.866            0.472287\n",
       "8        0.200002                    0.141655           1.86743    3.37586            0.160071         0.160463    0.28937                     0.279307            0.0933722       0.675177                   86.7428   237.586            0.519725\n",
       "9        0.300003                    0.0882667          1.30209    2.6846             0.111612         0.113302    0.230118                    0.223972            0.130211        0.805388                   30.2093   168.46             0.552767\n",
       "10       0.399999                    0.0556348          0.802446   2.21408            0.0687838        0.0705778   0.189786                    0.185625            0.0802418       0.885629                   -19.7554  121.408            0.53116\n",
       "11       0.500054                    0.0345582          0.496291   1.87037            0.0425408        0.0447486   0.160324                    0.157437            0.0496561       0.935286                   -50.3709  87.0371            0.476037\n",
       "12       0.600001                    0.0216793          0.300805   1.60891            0.0257843        0.0275263   0.137912                    0.135797            0.0300646       0.96535                    -69.9195  60.8915            0.399602\n",
       "13       0.699997                    0.0142479          0.163095   1.40238            0.0139801        0.0176377   0.120208                    0.118918            0.0163089       0.981659                   -83.6905  40.2375            0.308069\n",
       "14       0.800003                    0.0098226          0.093263   1.23873            0.00799428       0.0119307   0.106181                    0.105544            0.0093268       0.990986                   -90.6737  23.8728            0.208889\n",
       "15       0.899999                    0.00678441         0.0583597  1.10758            0.00500246       0.00827573  0.0949392                   0.0947363           0.00583576      0.996822                   -94.164   10.7581            0.1059\n",
       "16       1                           0.00377486         0.0317838  1                  0.00272443       0.00559175  0.0857176                   0.0858218           0.00317841      1                          -96.8216  0                  0\n",
       "\n",
       "ModelMetricsBinomial: gbm\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.06627360066228435\n",
       "RMSE: 0.25743659542163844\n",
       "LogLoss: 0.22727388362363\n",
       "Mean Per-Class Error: 0.2675555572976968\n",
       "AUC: 0.8445896056068984\n",
       "AUCPR: 0.344396693762911\n",
       "Gini: 0.6891792112137969\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.16511319188107634\n",
       "       No     Yes    Error    Rate\n",
       "-----  -----  -----  -------  ----------------\n",
       "No     38121  5597   0.128    (5597.0/43718.0)\n",
       "Yes    1689   2460   0.4071   (1689.0/4149.0)\n",
       "Total  39810  8057   0.1522   (7286.0/47867.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.165113     0.40308   226\n",
       "max f2                       0.0980888    0.530533  280\n",
       "max f0point5                 0.333462     0.380316  128\n",
       "max accuracy                 0.484168     0.915056  68\n",
       "max precision                0.890349     1         0\n",
       "max recall                   0.00466634   1         398\n",
       "max specificity              0.890349     1         0\n",
       "max absolute_mcc             0.165113     0.349597  226\n",
       "max min_per_class_accuracy   0.0980888    0.765968  280\n",
       "max mean_per_class_accuracy  0.0783484    0.769948  298\n",
       "max tns                      0.890349     43718     0\n",
       "max fns                      0.890349     4148      0\n",
       "max fps                      0.00418094   43718     399\n",
       "max tps                      0.00466634   4149      398\n",
       "max tnr                      0.890349     1         0\n",
       "max fnr                      0.890349     0.999759  0\n",
       "max fpr                      0.00418094   1         399\n",
       "max tpr                      0.00466634   1         398\n",
       "\n",
       "Gains/Lift Table: Avg response rate:  8.67 %, avg score:  8.55 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0100069                   0.538275           6.47902    6.47902            0.561587         0.625672    0.561587                    0.625672            0.0648349       0.0648349                  547.902   547.902            0.0600314\n",
       "2        0.0200138                   0.46162            5.90097    6.19               0.511482         0.496578    0.536534                    0.561125            0.0590504       0.123885                   490.097   519                0.113729\n",
       "3        0.0299998                   0.408882           4.46516    5.61585            0.387029         0.434138    0.486769                    0.518855            0.0445891       0.168474                   346.516   461.585            0.151616\n",
       "4        0.0400067                   0.369862           4.40766    5.31365            0.382046         0.387873    0.460574                    0.486092            0.044107        0.212581                   340.766   431.365            0.188953\n",
       "5        0.0500136                   0.337206           3.78144    5.00708            0.327766         0.35398     0.434002                    0.459659            0.0378404       0.250422                   278.144   400.708            0.219428\n",
       "6        0.100006                    0.239693           3.30248    4.15496            0.286252         0.283951    0.360142                    0.371823            0.1651          0.415522                   230.248   315.496            0.345459\n",
       "7        0.150041                    0.177518           2.57716    3.6288             0.223382         0.206575    0.314536                    0.316717            0.128947        0.544469                   157.716   262.88             0.43186\n",
       "8        0.200033                    0.141402           2.06345    3.23759            0.178855         0.159525    0.280627                    0.277432            0.103157        0.647626                   106.345   223.759            0.490071\n",
       "9        0.299998                    0.088353           1.42253    2.63278            0.123302         0.113143    0.228203                    0.222688            0.142203        0.789829                   42.2535   163.278            0.536318\n",
       "10       0.400025                    0.0555852          0.860215   2.18955            0.0745614        0.070189    0.189785                    0.184555            0.0860448       0.875874                   -13.9785  118.955            0.521008\n",
       "11       0.500031                    0.034945           0.573596   1.86636            0.049718         0.0450287   0.161771                    0.15665             0.0573632       0.933237                   -42.6404  86.6357            0.474318\n",
       "12       0.600038                    0.0217499          0.294028   1.6043             0.0254857        0.0277017   0.139057                    0.135158            0.0294047       0.962642                   -70.5972  60.4302            0.397016\n",
       "13       0.700002                    0.014289           0.166364   1.39896            0.0144201        0.0176854   0.121258                    0.118383            0.0166305       0.979272                   -83.3636  39.8956            0.305774\n",
       "14       0.800029                    0.0098844          0.118069   1.23881            0.0102339        0.011973    0.107377                    0.105078            0.0118101       0.991082                   -88.1931  23.8807            0.209185\n",
       "15       0.899994                    0.00678752         0.0554547  1.10737            0.00480669       0.00831197  0.0959842                   0.0943302           0.0055435       0.996626                   -94.4545  10.737             0.105803\n",
       "16       1                           0.00357741         0.033741   1                  0.00292459       0.00558406  0.0866777                   0.0854551           0.00337431      1                          -96.6259  0                  0\n",
       "\n",
       "Scoring History: \n",
       "    timestamp            duration    number_of_trees    training_rmse    training_logloss    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_auc    validation_pr_auc    validation_lift    validation_classification_error\n",
       "--  -------------------  ----------  -----------------  ---------------  ------------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ----------------  -------------------  -----------------  ---------------------------------\n",
       "    2022-11-08 21:32:26  0.009 sec   0                  0.279947         0.292516            0.5             0.0857176          1                0.914282                         0.281364           0.294789              0.5               0.0866777            1                  0.913322\n",
       "    2022-11-08 21:32:27  0.877 sec   5                  0.265838         0.254618            0.836327        0.359991           7.47554          0.122422                         0.268168           0.258381              0.833461          0.332173             6.5857             0.151775\n",
       "    2022-11-08 21:32:28  1.890 sec   10                 0.259429         0.240258            0.839922        0.37144            7.774            0.114374                         0.262603           0.244797              0.83708           0.336122             6.57537            0.143147\n",
       "    2022-11-08 21:32:29  2.983 sec   15                 0.255947         0.231677            0.844809        0.380262           7.98407          0.119157                         0.259731           0.236857              0.840741          0.341109             6.62354            0.156956\n",
       "    2022-11-08 21:32:30  3.940 sec   20                 0.254028         0.226423            0.848199        0.387278           8.10385          0.119974                         0.258367           0.232295              0.842866          0.343605             6.64762            0.146489\n",
       "    2022-11-08 21:32:31  4.924 sec   25                 0.252899         0.223352            0.850514        0.393087           8.2221           0.123226                         0.257783           0.230001              0.843862          0.344396             6.59945            0.14979\n",
       "    2022-11-08 21:32:32  5.941 sec   30                 0.252209         0.221512            0.851772        0.397268           8.3211           0.123498                         0.257565           0.228835              0.84423           0.344623             6.55128            0.143188\n",
       "    2022-11-08 21:32:33  6.879 sec   35                 0.251631         0.220134            0.852776        0.401979           8.41489          0.119773                         0.257455           0.22809               0.844469          0.344832             6.45494            0.139574\n",
       "    2022-11-08 21:32:34  7.853 sec   40                 0.251153         0.219083            0.853936        0.406056           8.45136          0.119572                         0.257393           0.227666              0.844694          0.344774             6.67171            0.137631\n",
       "    2022-11-08 21:32:35  8.830 sec   45                 0.25076          0.218225            0.854962        0.409719           8.53994          0.113378                         0.257384           0.22743               0.844693          0.344553             6.67171            0.150124\n",
       "    2022-11-08 21:32:36  9.742 sec   50                 0.250428         0.217542            0.855982        0.412829           8.62331          0.120809                         0.257426           0.227394              0.844585          0.344153             6.64762            0.154407\n",
       "    2022-11-08 21:32:37  10.749 sec  55                 0.250019         0.216828            0.856934        0.417037           8.75357          0.119327                         0.257442           0.22733               0.84458           0.344253             6.45494            0.152569\n",
       "    2022-11-08 21:32:38  11.732 sec  60                 0.249701         0.216292            0.857639        0.420263           8.78483          0.118393                         0.257437           0.227274              0.84459           0.344397             6.47902            0.152213\n",
       "\n",
       "Variable Importances: \n",
       "variable          relative_importance    scaled_importance    percentage\n",
       "----------------  ---------------------  -------------------  ------------\n",
       "GenHealth         3887.24                1                    0.250329\n",
       "AgeCategory       3791.92                0.975479             0.244191\n",
       "Stroke            1866.48                0.480154             0.120197\n",
       "Diabetic          859.226                0.221038             0.0553322\n",
       "Sex               833.886                0.214519             0.0537004\n",
       "DiffWalking       615.59                 0.158362             0.0396426\n",
       "PhysicalHealth    611.565                0.157326             0.0393834\n",
       "BMI               551.55                 0.141887             0.0355186\n",
       "Race              496.232                0.127657             0.0319562\n",
       "KidneyDisease     457.077                0.117584             0.0294347\n",
       "SleepTime         415.621                0.106919             0.026765\n",
       "Smoking           340.554                0.0876082            0.0219309\n",
       "MentalHealth      302.571                0.077837             0.0194849\n",
       "SkinCancer        241.518                0.0621311            0.0155532\n",
       "Asthma            121.817                0.0313377            0.00784475\n",
       "PhysicalActivity  79.5062                0.0204531            0.00512002\n",
       "AlcoholDrinking   56.1544                0.0144458            0.00361621\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#starting the automl process\n",
    "#It will test all the 10 models and update the leading model according to performance.\n",
    "#We can see for the variable importance at the end as well. Gives us rough Idea of which \n",
    "#variable will it be using for the prediction purposes. \n",
    "aml.train(x = x, y = y, training_frame = df_train, validation_frame=df_valid)\n",
    "#taken from references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b215014",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates the leader Board for all out models, ranking them by their performance(default: mean_per_class_error\t)\n",
    "#We can also observe that as we go below the leaderboard the logloss, rmse and mse are increasing as well. \n",
    "#Here from the leaderboard we have \"GBM_5_AutoML_1_20221107_231030\t\" as the leader(best performing) model .\n",
    "\n",
    "lb = aml.leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df23b406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class='dataframe'>\n",
       "<thead>\n",
       "<tr><th>model_id                          </th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">   aucpr</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">      mse</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>GBM_2_AutoML_3_20221108_212840    </td><td style=\"text-align: right;\">0.84459 </td><td style=\"text-align: right;\"> 0.227274</td><td style=\"text-align: right;\">0.344397</td><td style=\"text-align: right;\">              0.267556</td><td style=\"text-align: right;\">0.257437</td><td style=\"text-align: right;\">0.0662736</td></tr>\n",
       "<tr><td>GBM_3_AutoML_3_20221108_212840    </td><td style=\"text-align: right;\">0.843878</td><td style=\"text-align: right;\"> 0.227919</td><td style=\"text-align: right;\">0.338493</td><td style=\"text-align: right;\">              0.272468</td><td style=\"text-align: right;\">0.257979</td><td style=\"text-align: right;\">0.0665531</td></tr>\n",
       "<tr><td>XGBoost_3_AutoML_3_20221108_212840</td><td style=\"text-align: right;\">0.843579</td><td style=\"text-align: right;\"> 0.227628</td><td style=\"text-align: right;\">0.343459</td><td style=\"text-align: right;\">              0.276189</td><td style=\"text-align: right;\">0.257627</td><td style=\"text-align: right;\">0.0663719</td></tr>\n",
       "<tr><td>GBM_4_AutoML_3_20221108_212840    </td><td style=\"text-align: right;\">0.841016</td><td style=\"text-align: right;\"> 0.229327</td><td style=\"text-align: right;\">0.338145</td><td style=\"text-align: right;\">              0.289268</td><td style=\"text-align: right;\">0.258507</td><td style=\"text-align: right;\">0.0668257</td></tr>\n",
       "<tr><td>GLM_1_AutoML_3_20221108_212840    </td><td style=\"text-align: right;\">0.840345</td><td style=\"text-align: right;\"> 0.229809</td><td style=\"text-align: right;\">0.340574</td><td style=\"text-align: right;\">              0.278193</td><td style=\"text-align: right;\">0.258375</td><td style=\"text-align: right;\">0.0667578</td></tr>\n",
       "<tr><td>GBM_1_AutoML_3_20221108_212840    </td><td style=\"text-align: right;\">0.839758</td><td style=\"text-align: right;\"> 0.2295  </td><td style=\"text-align: right;\">0.336907</td><td style=\"text-align: right;\">              0.285513</td><td style=\"text-align: right;\">0.25845 </td><td style=\"text-align: right;\">0.0667963</td></tr>\n",
       "<tr><td>XGBoost_2_AutoML_3_20221108_212840</td><td style=\"text-align: right;\">0.83703 </td><td style=\"text-align: right;\"> 0.231889</td><td style=\"text-align: right;\">0.325112</td><td style=\"text-align: right;\">              0.28651 </td><td style=\"text-align: right;\">0.26002 </td><td style=\"text-align: right;\">0.0676105</td></tr>\n",
       "<tr><td>XRT_1_AutoML_3_20221108_212840    </td><td style=\"text-align: right;\">0.834391</td><td style=\"text-align: right;\"> 0.235813</td><td style=\"text-align: right;\">0.32865 </td><td style=\"text-align: right;\">              0.279346</td><td style=\"text-align: right;\">0.260424</td><td style=\"text-align: right;\">0.0678206</td></tr>\n",
       "<tr><td>XGBoost_1_AutoML_3_20221108_212840</td><td style=\"text-align: right;\">0.829586</td><td style=\"text-align: right;\"> 0.236668</td><td style=\"text-align: right;\">0.311399</td><td style=\"text-align: right;\">              0.280775</td><td style=\"text-align: right;\">0.262507</td><td style=\"text-align: right;\">0.0689097</td></tr>\n",
       "<tr><td>DRF_1_AutoML_3_20221108_212840    </td><td style=\"text-align: right;\">0.826372</td><td style=\"text-align: right;\"> 0.237241</td><td style=\"text-align: right;\">0.311899</td><td style=\"text-align: right;\">              0.295128</td><td style=\"text-align: right;\">0.261893</td><td style=\"text-align: right;\">0.0685882</td></tr>\n",
       "</tbody>\n",
       "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[10 rows x 7 columns]</pre>"
      ],
      "text/plain": [
       "model_id                                 auc    logloss     aucpr    mean_per_class_error      rmse        mse\n",
       "----------------------------------  --------  ---------  --------  ----------------------  --------  ---------\n",
       "GBM_2_AutoML_3_20221108_212840      0.84459    0.227274  0.344397                0.267556  0.257437  0.0662736\n",
       "GBM_3_AutoML_3_20221108_212840      0.843878   0.227919  0.338493                0.272468  0.257979  0.0665531\n",
       "XGBoost_3_AutoML_3_20221108_212840  0.843579   0.227628  0.343459                0.276189  0.257627  0.0663719\n",
       "GBM_4_AutoML_3_20221108_212840      0.841016   0.229327  0.338145                0.289268  0.258507  0.0668257\n",
       "GLM_1_AutoML_3_20221108_212840      0.840345   0.229809  0.340574                0.278193  0.258375  0.0667578\n",
       "GBM_1_AutoML_3_20221108_212840      0.839758   0.2295    0.336907                0.285513  0.25845   0.0667963\n",
       "XGBoost_2_AutoML_3_20221108_212840  0.83703    0.231889  0.325112                0.28651   0.26002   0.0676105\n",
       "XRT_1_AutoML_3_20221108_212840      0.834391   0.235813  0.32865                 0.279346  0.260424  0.0678206\n",
       "XGBoost_1_AutoML_3_20221108_212840  0.829586   0.236668  0.311399                0.280775  0.262507  0.0689097\n",
       "DRF_1_AutoML_3_20221108_212840      0.826372   0.237241  0.311899                0.295128  0.261893  0.0685882\n",
       "[10 rows x 7 columns]\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca2fe522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "#Using the leader model for prediction. \n",
    "OverWeight_pred=aml.leader.predict(df_test)\n",
    "#taken from references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4b29335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class='dataframe'>\n",
       "<thead>\n",
       "<tr><th>predict  </th><th style=\"text-align: right;\">      No</th><th style=\"text-align: right;\">      Yes</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>No       </td><td style=\"text-align: right;\">0.985609</td><td style=\"text-align: right;\">0.0143905</td></tr>\n",
       "<tr><td>No       </td><td style=\"text-align: right;\">0.938227</td><td style=\"text-align: right;\">0.0617734</td></tr>\n",
       "<tr><td>No       </td><td style=\"text-align: right;\">0.863413</td><td style=\"text-align: right;\">0.136587 </td></tr>\n",
       "<tr><td>No       </td><td style=\"text-align: right;\">0.869415</td><td style=\"text-align: right;\">0.130585 </td></tr>\n",
       "<tr><td>No       </td><td style=\"text-align: right;\">0.985219</td><td style=\"text-align: right;\">0.014781 </td></tr>\n",
       "<tr><td>Yes      </td><td style=\"text-align: right;\">0.82308 </td><td style=\"text-align: right;\">0.17692  </td></tr>\n",
       "<tr><td>Yes      </td><td style=\"text-align: right;\">0.680419</td><td style=\"text-align: right;\">0.319581 </td></tr>\n",
       "<tr><td>Yes      </td><td style=\"text-align: right;\">0.803622</td><td style=\"text-align: right;\">0.196378 </td></tr>\n",
       "<tr><td>No       </td><td style=\"text-align: right;\">0.941121</td><td style=\"text-align: right;\">0.0588793</td></tr>\n",
       "<tr><td>No       </td><td style=\"text-align: right;\">0.856496</td><td style=\"text-align: right;\">0.143504 </td></tr>\n",
       "</tbody>\n",
       "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[10 rows x 3 columns]</pre>"
      ],
      "text/plain": [
       "predict          No        Yes\n",
       "---------  --------  ---------\n",
       "No         0.985609  0.0143905\n",
       "No         0.938227  0.0617734\n",
       "No         0.863413  0.136587\n",
       "No         0.869415  0.130585\n",
       "No         0.985219  0.014781\n",
       "Yes        0.82308   0.17692\n",
       "Yes        0.680419  0.319581\n",
       "Yes        0.803622  0.196378\n",
       "No         0.941121  0.0588793\n",
       "No         0.856496  0.143504\n",
       "[10 rows x 3 columns]\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OverWeight_pred.head()\n",
    "#predicitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3341d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: gbm\n",
       "** Reported on test data. **\n",
       "\n",
       "MSE: 0.06421168735086555\n",
       "RMSE: 0.2534002512841405\n",
       "LogLoss: 0.2219595592380514\n",
       "Mean Per-Class Error: 0.29638109903264\n",
       "AUC: 0.8446787122854429\n",
       "AUCPR: 0.34711474875913134\n",
       "Gini: 0.6893574245708858</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-11.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-11 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-11 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-11 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-11 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-11 .h2o-table th,\n",
       "#h2o-table-11 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-11 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-11\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.1999965081240496</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>No</th>\n",
       "<th>Yes</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>No</td>\n",
       "<td>39873.0</td>\n",
       "<td>4125.0</td>\n",
       "<td>0.0938</td>\n",
       "<td> (4125.0/43998.0)</td></tr>\n",
       "<tr><td>Yes</td>\n",
       "<td>2012.0</td>\n",
       "<td>2020.0</td>\n",
       "<td>0.499</td>\n",
       "<td> (2012.0/4032.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>41885.0</td>\n",
       "<td>6145.0</td>\n",
       "<td>0.1278</td>\n",
       "<td> (6137.0/48030.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-12.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-12 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-12 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-12 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-12 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-12 .h2o-table th,\n",
       "#h2o-table-12 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-12 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-12\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.1999965</td>\n",
       "<td>0.3969736</td>\n",
       "<td>202.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0910592</td>\n",
       "<td>0.5255823</td>\n",
       "<td>287.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.3116686</td>\n",
       "<td>0.3978873</td>\n",
       "<td>141.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.5326257</td>\n",
       "<td>0.9173641</td>\n",
       "<td>54.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.8535919</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0041600</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.8535919</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.1619385</td>\n",
       "<td>0.3413020</td>\n",
       "<td>229.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.0980873</td>\n",
       "<td>0.7653770</td>\n",
       "<td>281.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.0802957</td>\n",
       "<td>0.7711380</td>\n",
       "<td>296.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.8535919</td>\n",
       "<td>43998.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.8535919</td>\n",
       "<td>4031.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0041600</td>\n",
       "<td>43998.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0041600</td>\n",
       "<td>4032.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.8535919</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.8535919</td>\n",
       "<td>0.9997520</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0041600</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0041600</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-13.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-13 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-13 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-13 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-13 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-13 .h2o-table th,\n",
       "#h2o-table-13 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-13 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-13\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate:  8.39 %, avg score:  8.48 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0100146</td>\n",
       "<td>0.5400756</td>\n",
       "<td>6.5876213</td>\n",
       "<td>6.5876213</td>\n",
       "<td>0.5530146</td>\n",
       "<td>0.6216426</td>\n",
       "<td>0.5530146</td>\n",
       "<td>0.6216426</td>\n",
       "<td>0.0659722</td>\n",
       "<td>0.0659722</td>\n",
       "<td>558.7621275</td>\n",
       "<td>558.7621275</td>\n",
       "<td>0.0610856</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0200083</td>\n",
       "<td>0.4605366</td>\n",
       "<td>5.5838449</td>\n",
       "<td>6.0862553</td>\n",
       "<td>0.46875</td>\n",
       "<td>0.4959122</td>\n",
       "<td>0.5109261</td>\n",
       "<td>0.5588428</td>\n",
       "<td>0.0558036</td>\n",
       "<td>0.1217758</td>\n",
       "<td>458.3844866</td>\n",
       "<td>508.6255327</td>\n",
       "<td>0.1110935</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0300021</td>\n",
       "<td>0.4065459</td>\n",
       "<td>5.4349423</td>\n",
       "<td>5.8693017</td>\n",
       "<td>0.45625</td>\n",
       "<td>0.4317428</td>\n",
       "<td>0.4927134</td>\n",
       "<td>0.5165056</td>\n",
       "<td>0.0543155</td>\n",
       "<td>0.1760913</td>\n",
       "<td>443.4942336</td>\n",
       "<td>486.9301659</td>\n",
       "<td>0.1594769</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0400167</td>\n",
       "<td>0.3676457</td>\n",
       "<td>4.6063818</td>\n",
       "<td>5.5532431</td>\n",
       "<td>0.3866944</td>\n",
       "<td>0.3868883</td>\n",
       "<td>0.4661811</td>\n",
       "<td>0.4840675</td>\n",
       "<td>0.0461310</td>\n",
       "<td>0.2222222</td>\n",
       "<td>360.6381794</td>\n",
       "<td>455.3243149</td>\n",
       "<td>0.1989030</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0500104</td>\n",
       "<td>0.3356269</td>\n",
       "<td>4.3926246</td>\n",
       "<td>5.3213127</td>\n",
       "<td>0.36875</td>\n",
       "<td>0.3514125</td>\n",
       "<td>0.4467111</td>\n",
       "<td>0.4575586</td>\n",
       "<td>0.0438988</td>\n",
       "<td>0.2661210</td>\n",
       "<td>339.2624628</td>\n",
       "<td>432.1312721</td>\n",
       "<td>0.2359151</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1</td>\n",
       "<td>0.2366000</td>\n",
       "<td>3.2992980</td>\n",
       "<td>4.3105159</td>\n",
       "<td>0.2769679</td>\n",
       "<td>0.2807438</td>\n",
       "<td>0.3618572</td>\n",
       "<td>0.3691696</td>\n",
       "<td>0.1649306</td>\n",
       "<td>0.4310516</td>\n",
       "<td>229.9298036</td>\n",
       "<td>331.0515873</td>\n",
       "<td>0.3613893</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1500104</td>\n",
       "<td>0.1761481</td>\n",
       "<td>2.3854160</td>\n",
       "<td>3.6687269</td>\n",
       "<td>0.2002498</td>\n",
       "<td>0.2039495</td>\n",
       "<td>0.3079806</td>\n",
       "<td>0.3140886</td>\n",
       "<td>0.1192956</td>\n",
       "<td>0.5503472</td>\n",
       "<td>138.5416047</td>\n",
       "<td>266.8726868</td>\n",
       "<td>0.4370239</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2</td>\n",
       "<td>0.1391551</td>\n",
       "<td>1.9547721</td>\n",
       "<td>3.2403274</td>\n",
       "<td>0.1640983</td>\n",
       "<td>0.1573305</td>\n",
       "<td>0.2720175</td>\n",
       "<td>0.2749072</td>\n",
       "<td>0.0977183</td>\n",
       "<td>0.6480655</td>\n",
       "<td>95.4772069</td>\n",
       "<td>224.0327381</td>\n",
       "<td>0.4891264</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3</td>\n",
       "<td>0.0870839</td>\n",
       "<td>1.4508929</td>\n",
       "<td>2.6438492</td>\n",
       "<td>0.1217989</td>\n",
       "<td>0.1113753</td>\n",
       "<td>0.2219446</td>\n",
       "<td>0.2203966</td>\n",
       "<td>0.1450893</td>\n",
       "<td>0.7931548</td>\n",
       "<td>45.0892857</td>\n",
       "<td>164.3849206</td>\n",
       "<td>0.5383477</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4</td>\n",
       "<td>0.0552705</td>\n",
       "<td>0.8606151</td>\n",
       "<td>2.1980407</td>\n",
       "<td>0.0722465</td>\n",
       "<td>0.0699255</td>\n",
       "<td>0.1845201</td>\n",
       "<td>0.1827788</td>\n",
       "<td>0.0860615</td>\n",
       "<td>0.8792163</td>\n",
       "<td>-13.9384921</td>\n",
       "<td>119.8040675</td>\n",
       "<td>0.5231319</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0348572</td>\n",
       "<td>0.5109127</td>\n",
       "<td>1.8606151</td>\n",
       "<td>0.0428899</td>\n",
       "<td>0.0448423</td>\n",
       "<td>0.1561940</td>\n",
       "<td>0.1551915</td>\n",
       "<td>0.0510913</td>\n",
       "<td>0.9303075</td>\n",
       "<td>-48.9087302</td>\n",
       "<td>86.0615079</td>\n",
       "<td>0.4697412</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6</td>\n",
       "<td>0.0218398</td>\n",
       "<td>0.2876984</td>\n",
       "<td>1.5984623</td>\n",
       "<td>0.0241516</td>\n",
       "<td>0.0277484</td>\n",
       "<td>0.1341870</td>\n",
       "<td>0.1339510</td>\n",
       "<td>0.0287698</td>\n",
       "<td>0.9590774</td>\n",
       "<td>-71.2301587</td>\n",
       "<td>59.8462302</td>\n",
       "<td>0.3919834</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.7</td>\n",
       "<td>0.0144428</td>\n",
       "<td>0.1835317</td>\n",
       "<td>1.3963294</td>\n",
       "<td>0.0154070</td>\n",
       "<td>0.0178187</td>\n",
       "<td>0.1172184</td>\n",
       "<td>0.1173607</td>\n",
       "<td>0.0183532</td>\n",
       "<td>0.9774306</td>\n",
       "<td>-81.6468254</td>\n",
       "<td>39.6329365</td>\n",
       "<td>0.3028544</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.8</td>\n",
       "<td>0.0099767</td>\n",
       "<td>0.1165675</td>\n",
       "<td>1.2363591</td>\n",
       "<td>0.0097856</td>\n",
       "<td>0.0121541</td>\n",
       "<td>0.1037893</td>\n",
       "<td>0.1042098</td>\n",
       "<td>0.0116567</td>\n",
       "<td>0.9890873</td>\n",
       "<td>-88.3432540</td>\n",
       "<td>23.6359127</td>\n",
       "<td>0.2064154</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.9</td>\n",
       "<td>0.0068316</td>\n",
       "<td>0.0570437</td>\n",
       "<td>1.1053241</td>\n",
       "<td>0.0047887</td>\n",
       "<td>0.0083903</td>\n",
       "<td>0.0927892</td>\n",
       "<td>0.0935632</td>\n",
       "<td>0.0057044</td>\n",
       "<td>0.9947917</td>\n",
       "<td>-94.2956349</td>\n",
       "<td>10.5324074</td>\n",
       "<td>0.1034784</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0033921</td>\n",
       "<td>0.0520833</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0043723</td>\n",
       "<td>0.0056074</td>\n",
       "<td>0.0839475</td>\n",
       "<td>0.0847676</td>\n",
       "<td>0.0052083</td>\n",
       "<td>1.0</td>\n",
       "<td>-94.7916667</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>"
      ],
      "text/plain": [
       "ModelMetricsBinomial: gbm\n",
       "** Reported on test data. **\n",
       "\n",
       "MSE: 0.06421168735086555\n",
       "RMSE: 0.2534002512841405\n",
       "LogLoss: 0.2219595592380514\n",
       "Mean Per-Class Error: 0.29638109903264\n",
       "AUC: 0.8446787122854429\n",
       "AUCPR: 0.34711474875913134\n",
       "Gini: 0.6893574245708858\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.1999965081240496\n",
       "       No     Yes    Error    Rate\n",
       "-----  -----  -----  -------  ----------------\n",
       "No     39873  4125   0.0938   (4125.0/43998.0)\n",
       "Yes    2012   2020   0.499    (2012.0/4032.0)\n",
       "Total  41885  6145   0.1278   (6137.0/48030.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.199997     0.396974  202\n",
       "max f2                       0.0910592    0.525582  287\n",
       "max f0point5                 0.311669     0.397887  141\n",
       "max accuracy                 0.532626     0.917364  54\n",
       "max precision                0.853592     1         0\n",
       "max recall                   0.00415997   1         399\n",
       "max specificity              0.853592     1         0\n",
       "max absolute_mcc             0.161938     0.341302  229\n",
       "max min_per_class_accuracy   0.0980873    0.765377  281\n",
       "max mean_per_class_accuracy  0.0802957    0.771138  296\n",
       "max tns                      0.853592     43998     0\n",
       "max fns                      0.853592     4031      0\n",
       "max fps                      0.00415997   43998     399\n",
       "max tps                      0.00415997   4032      399\n",
       "max tnr                      0.853592     1         0\n",
       "max fnr                      0.853592     0.999752  0\n",
       "max fpr                      0.00415997   1         399\n",
       "max tpr                      0.00415997   1         399\n",
       "\n",
       "Gains/Lift Table: Avg response rate:  8.39 %, avg score:  8.48 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0100146                   0.540076           6.58762    6.58762            0.553015         0.621643    0.553015                    0.621643            0.0659722       0.0659722                  558.762   558.762            0.0610856\n",
       "2        0.0200083                   0.460537           5.58384    6.08626            0.46875          0.495912    0.510926                    0.558843            0.0558036       0.121776                   458.384   508.626            0.111093\n",
       "3        0.0300021                   0.406546           5.43494    5.8693             0.45625          0.431743    0.492713                    0.516506            0.0543155       0.176091                   443.494   486.93             0.159477\n",
       "4        0.0400167                   0.367646           4.60638    5.55324            0.386694         0.386888    0.466181                    0.484068            0.046131        0.222222                   360.638   455.324            0.198903\n",
       "5        0.0500104                   0.335627           4.39262    5.32131            0.36875          0.351412    0.446711                    0.457559            0.0438988       0.266121                   339.262   432.131            0.235915\n",
       "6        0.1                         0.2366             3.2993     4.31052            0.276968         0.280744    0.361857                    0.36917             0.164931        0.431052                   229.93    331.052            0.361389\n",
       "7        0.15001                     0.176148           2.38542    3.66873            0.20025          0.20395     0.307981                    0.314089            0.119296        0.550347                   138.542   266.873            0.437024\n",
       "8        0.2                         0.139155           1.95477    3.24033            0.164098         0.157331    0.272017                    0.274907            0.0977183       0.648065                   95.4772   224.033            0.489126\n",
       "9        0.3                         0.0870839          1.45089    2.64385            0.121799         0.111375    0.221945                    0.220397            0.145089        0.793155                   45.0893   164.385            0.538348\n",
       "10       0.4                         0.0552705          0.860615   2.19804            0.0722465        0.0699255   0.18452                     0.182779            0.0860615       0.879216                   -13.9385  119.804            0.523132\n",
       "11       0.5                         0.0348572          0.510913   1.86062            0.0428899        0.0448423   0.156194                    0.155192            0.0510913       0.930308                   -48.9087  86.0615            0.469741\n",
       "12       0.6                         0.0218398          0.287698   1.59846            0.0241516        0.0277484   0.134187                    0.133951            0.0287698       0.959077                   -71.2302  59.8462            0.391983\n",
       "13       0.7                         0.0144428          0.183532   1.39633            0.015407         0.0178187   0.117218                    0.117361            0.0183532       0.977431                   -81.6468  39.6329            0.302854\n",
       "14       0.8                         0.00997668         0.116567   1.23636            0.00978555       0.0121541   0.103789                    0.10421             0.0116567       0.989087                   -88.3433  23.6359            0.206415\n",
       "15       0.9                         0.00683157         0.0570437  1.10532            0.00478867       0.0083903   0.0927892                   0.0935632           0.00570437      0.994792                   -94.2956  10.5324            0.103478\n",
       "16       1                           0.00339215         0.0520833  1                  0.00437227       0.00560738  0.0839475                   0.0847676           0.00520833      1                          -94.7917  0                  0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml.leader.model_performance(df_test)\n",
    "#creating a performance report for the leading model (GBM_5_AutoML_1_20221107_231030)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "99822200",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ids = list(aml.leaderboard['model_id'].as_data_frame().iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a6e37934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GBM_2_AutoML_3_20221108_212840',\n",
       " 'GBM_3_AutoML_3_20221108_212840',\n",
       " 'XGBoost_3_AutoML_3_20221108_212840',\n",
       " 'GBM_4_AutoML_3_20221108_212840',\n",
       " 'GLM_1_AutoML_3_20221108_212840',\n",
       " 'GBM_1_AutoML_3_20221108_212840',\n",
       " 'XGBoost_2_AutoML_3_20221108_212840',\n",
       " 'XRT_1_AutoML_3_20221108_212840',\n",
       " 'XGBoost_1_AutoML_3_20221108_212840',\n",
       " 'DRF_1_AutoML_3_20221108_212840']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "24dab411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-32.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-32 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-32 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-32 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-32 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-32 .h2o-table th,\n",
       "#h2o-table-32 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-32 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-32\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.21090732948169086</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>No</th>\n",
       "<th>Yes</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>No</td>\n",
       "<td>187394.0</td>\n",
       "<td>17312.0</td>\n",
       "<td>0.0846</td>\n",
       "<td> (17312.0/204706.0)</td></tr>\n",
       "<tr><td>Yes</td>\n",
       "<td>9196.0</td>\n",
       "<td>9996.0</td>\n",
       "<td>0.4792</td>\n",
       "<td> (9196.0/19192.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>196590.0</td>\n",
       "<td>27308.0</td>\n",
       "<td>0.1184</td>\n",
       "<td> (26508.0/223898.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.21090732948169086\n",
       "       No      Yes    Error    Rate\n",
       "-----  ------  -----  -------  ------------------\n",
       "No     187394  17312  0.0846   (17312.0/204706.0)\n",
       "Yes    9196    9996   0.4792   (9196.0/19192.0)\n",
       "Total  196590  27308  0.1184   (26508.0/223898.0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using confusion matrix\n",
    "aml.leader.confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0fdf718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2wAAAJTCAYAAAB0N5WdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABCTklEQVR4nO3deZglVX3/8feHGRQIOIigUTSO4o4gwrjgCm5RxwUV40KioIbgGn/GRBKNkrhAzOaCoEgQNRqNIoobgujgggsDDAy4LxMVYxCRUUCQGb+/P6oarndu93TP9PQ93fN+PU8/3bfq1KlTdavr3s89p+qmqpAkSZIktWebcTdAkiRJkjSagU2SJEmSGmVgkyRJkqRGGdgkSZIkqVEGNkmSJElqlIFNkiRJkhplYJMWiCQHJKkkR21mPYf29Rw6g2VO7pdZujnrltSOyc4FSdYkWTOeVmmUJEf1z9UB427LfOLrneYLA5u0mZK8vz95P38aZc/syx40B01bMAbC6Ipxt2VL25Q3EFuDJCs29oZ04I3UoQPTkuTRSd6aZFWSXya5Nsm3k7wpya02st67JHlbkm8luSrJ1f2yxyW562Zszy5Jjuy367Ikv03y6ySXJHlXkscnyabWvxBtzodSfcisoZ/rk1ya5MNJ7r8Fmjxr5ut5YWBf/y7JHlOU+/xA2UPnsInSvLB43A2QFoATgGcAfw4cP1mh/tO4hwP/C3xiC7Tj68Ddgcu3QN3SfHVT4NPAb4EvAJ8FFgEPA/4SeHqSB1fVd4cXTPIS4N/oPtz8At3/bQH7AUcAhyd5WVW9ZSYNSvIE4N3AzsAa4FN054WbAHsABwGHAh8GnjqTuufIw8fdgM3wZuDK/u8dgb2BJwNPTPKEqvr0uBq2mY4FPgD8aNwNGWEd3fvN5wJ/NzwzyZ2Bhw6Ua93fAscAl467Idp6zId/DKlpVbUiyXeAeyfZt6rOn6Toc4EA76qqdVugHdcA35rteqV5bj3wKuC4qvrlxMQk2wDHAX9BF8oeP7hQkmfRvbm/AnhSVX1haP6DgY8Cb05yZVW9ZzqNSfIw4BS6N6d/DpxUVb8bKrMd8KfAo6a/mXOnqr4/7jZshjdV1ZrBCUn+CvgX4BV04X7eqarLaffDuv+j+0DisCSvHvH69zy618ZP0H1Y0bSq+l+67ZHmjEMipdnxzv73n4+amWQRcBjdp/Mn9tMOSvKfSb7TD7O6Ksl5SV7Sv5kcrmNiuNcdk7w4yUVJfjMxTHCy4UJJ9kvy5iQXJrmiHw723ST/muTmU21UkuVJzunb98t+6NCdZ7JjktyvX+5n/bCvHyd5R5LbzKSeSeq+YZhQkkcm+WK/H3/eDyvbuS937ySf6LfhqiSnZcT1B7lx2N1Nk7wuyQ+TXJfk+0lek+Qmk7Tj4UlOH9i/30lyTJIlU6zjJklenW543XX987sCeFdf9F1Dw7eW9svfpl/uywP79KfphubefcT6lvbLn9z//YEkl/ftXJnkcVPs36clOWtgu9Yk+a8ky0aUfUa6YU0TQw6/meRVSW46Wf1zoaqur6rXD4a1fvrvgH/sHx4wOC/JTsCb+ofPHA5r/fJfBA7pH/57v8yU+vPA2+k+LH1JVZ04HNb6uq+tqhOBZw4tP3i8P7o/ltYmqYEyMzqv9MvcKcmH+ufu6v5/fvkU2zHpNWwzOQ76bVmRZNckJyT53/5/4ZIkhw2VPRn4fP/wNUP/GwdM1tZpOqP/vduINm6T5Igk5+bGIbHnJnn+FPtzJueDO/bb/r105/MrkqxO8vYkt+jLrGDj54WR17DNZB8PLHPTvr4f9GV/mO58eNOJ+qazU4e8E/hD4PfON0m2BZ4NnANcMkl7Nuk1bCbnr778gf2++nWSXyX5ZEafUze4hi2bd55t8typttjDJs2OdwOvB56Z5K/63q5BjwF2B86sqh/2044Bfgd8jW5oxRK6YVpvBu4D/Nkk63oz8GDgk3RDqdZvpG1/DjwJOJsbh4PtC7wMeEyS+1XVr0cs9+S+3acCK4B9gKcAByZ5QFV9eyPrpX9D8E7gOuA04MfAnek+UX18kvtX1WwM4XkC3RuBT9C9IX4A3ZCyOyQ5EjgL+CLwH8BedL0peyTZa9QbZuC/6Z6DDwPXA08EjgKWpRs2NfgG+S/ohsJeDXwIuIwuALyi38YHVtWVI9ZxSr+OT9P11FxGt5+v7Nf3MWDVQPmJOh4CHEn35vUU4Cq6fXow8IR+fReOWN/t6YbN/gB4L7AL8DTgY0keUVUTb4ZJEro3iM+m+9T+I8DPgdsCBwLfBlYOlP8P4DnAT/qyVwL3B14LPDzJIwc/VU/3ocJrgH+oqqNGtHWu/Lb/PfyJ/8HAzYGvV9VnJlu4qk5Pci7d83gwN76pnswBdM/Vj4GTNta4KXriDwYeTXfsvB1YOjBvRueVdB/AfAW4RV/fKuBOdMfkjHqbZnoc9HYGvkz3XHwY2K7fvpOS/K6q3t2X+2j/+9l057IVA3WsmUk7R3hE/3vliHnvpQvOP6b7sK3ozqfHAQ/ixtAOzOx8kOTWwLnAzejO5afQbf8d6J6nY4FfACez8fPCVHZmevt44n//FGA58N2+DdvSnU/3nMa6JvNfdD3Zz+PG5xK6c/et6M5pd5pk2Rm9hs30/NV7HN3+nfifugfwWOA+Se7R92BOx7TPs31bN+V/RlujqvLHH39m4Qf4IN2L+aEj5n2sn3fwwLQ9RpTbhi78FXC/oXkn99MvBe4wYtkD+vlHDU2/PbBoRPnn9uVfMTT90H56AY8bmveX/fSzJmnb0oFpd6F7g/A9YPeh8g+jC5qnTnPfTmzbiknaug546NB+PLOfdwVwyNBy/9HPe+LQ9BX99O8ANx+Yvh3dm9oC/mxo314H/Aq421Bdx/XlT5hkHRcBu47Y1olt2uA46uffEthpxPR70YW3Tw9NXzrwfL5maN4f99M/NTT98H7614ElQ/MWAbce0d6PANsPlT2qn/eXk0w/atQ2TrLdE/vt5H75UT+rptp3I+p8RV/+vyY5Pl4/jTpe35c9cRplX92Xfe90t3uSY+N3wKMnKTPT88oZkzxHTxw4bg4dmrcGWDNJ22ZyHEzUfyID5yi6N8vrgG8MlT9gpsfNUJuLrud04nj5Z+B0unPRl4HbDC3zjH6Z84EdB6b/Ad0b/qLrgd2k8wHw4lH7ZWAd2w88nti/k50XJvbxAZu5j/+sL/8F4CYD03emG3K/wXl4I/u9gJ/0f5/Yr/O2A/NPB9YCOwCvm+R4m+lr2Kacv9YBDx8qe3Q/72+Gpp/Mhq93Swf29WuGyk92np1Y97T/Z/zZen/G3gB//FkoP3QX4hfwpaHpt6brpfkZsO006tm3r+fVQ9NPnuoEzgzfzNBdM7AW+NzQ9IkXkbNGLLOILoAVcPsRbVs6MO3f+2nLJ1n/qf2L5AbhY4ptWzFJWzd4Aww8q5/3hRHzHjrJC+sKhkLZiDZ8fmDaK/tpbxhR/uZ0b9x+A9x0xDqeOMm2TmzToZtwDJ4GXDt4nA28kVjD6Dc9/wNcPjRtdb/Mvaexzgv643vnSY6Xy+l6qgan7wrcjRGBdYr1TOy36fxsdN/R9TZd0z9HewzN+1RfzxHTqOcIRrwZm6TsxJv2YyaZf9SIn50H5k8cG6duwrGxwXmFrseh6HoDRh0bE/v80KHpa9gwsG3KcVB0PVE3G7HM2f38nQamHcDmB7ZRPz8CXghsM7TMxIc+jxpR38T5/nMD02Z0PuDGwHb4NNo/8dyPPLaZOrDNZB9/tp/2kBHlD2HzAtv9Bo9BuiC2nu76UpgksE1R92SvYTM5f03s1/8cMe8O/bwPD00/mckD2xqmf56d8f+MP1vvj0MipdnzOeD7wAOT3L2qvtlPP4xu+PHJVXX9ROH++oS/pht2cUe6T1QH7T7Jer4+k0b11wj8BfB0uk9Vl/D7169Otp6zhydU1fokX6K7k9296V6EJrN///uhSe4zYv4t6V6U7gKcN9U2TMOooUw/7X+Pqnvi7l63naS+DbadbkjlOrrtnrBv//tzw4Wr6pdJLqAbwng3YHiY4oyex0Hpri86AlhGF36Gz+W7suFF8auqatTw2R9z43NFkj8A7gn8X1VdsJF27EDXs3c58NKMvgv9dXR3L71Bbd4NEg6sqhWTtOdkumFQU0pyF+DjdEO9nl4b3kRjYkNqGu2ZzbKvGTHtZDYc9jbpsTPD88rEsfylSY6NFXQfbkxpU4+D3ner6lcjpv+4/70zMGrI9qa6Q/U3HUl3c5c70fV8Hks3lHpwiOO+dL2ZK0bUczZd2Nic88FpwBuAtyX5Y+AzdD1936iq6RxP0zWTfXxvum0+Z0T5L21OI6rqa0lWA89J8jq64ZHbcOM14CPN5DVsJuevIaNeQyb2z5TXeg+Z7nl2c/5ntBUysEmzpKoqyYl0wyieB/xVP5b+Odw4JAWAdDfDOJfuE7yvA++hG7q3ju7F8y/pbkc+ys9m2LQP0o3//wHd0Myf0b0QALx0ivX830bWv2Qj671F//uvN1Jux43Mn461I6atm8a8bSepb4Nt78PqL+iC5oSJfTDZHcMmpu88Yt5Mn0fghlvNvxn4JV0PwI/oeoqK7g5r92L0c3rlJFWu4/ff/Ey0dTq3rL45XQjZjdFhozn9NVufp7u25OlVddqIYhPP2x9No8qJ0D+du8ZNlBn5IUlV3fCurf9g5IGT1DPy2NmE88rE8bux//WN2Zzj4MpJpk/8jy6aYX3TVlXXAhcnOYSux/WZSY6tqq/0RZYAV1TVb0csuy7J5WzG+aCq/ifJfel6xx5Nd90wwI+T/EvN8OsipnDlJNNH7eOJbR513dRkx8lMvBN4C932HgacN41gNZPXsJ373zO95f6VwxP65xhmdgxuUE9v+Dw7786dGi8DmzS73kV357lnJflbupuD7EE3ZON7A+WeR/emaoObLiTZn+6N1WSm/clrfzesJ9ENc3nsUA/fNsDfTLH4ZF8o/If971FBaNDE/CWTfLrbslsx9H1G6e7wdwu6YU0TJrbxDxl9h7NbD5W7waZ8gp5kMfAPdG9Y9q3u9tKD8/cfueDMXNn/nqznddDEdl1QVftOWbIB/R3fzqJ7Hp9aVR+bpOiX6N5MPoJumNtUJm5Y8eVpNGGizAFJtqnRN7yZjsmOnZmeVyaev439r2/MvDoOhlXV9UnOpxvWdl+661Wh265dkmw7eO6EG/4Xd2Uzzwf9SIyn9fXdi+54ejHd10VcXVX/sTnbtgl+RbfNi0eEtim/ZH6a3gv8E/AOunPMP05VeBNew67sf0/n/DVO8/p/RnPP2/pLs6iq/o9umMuudL0dz+tnnTBUdOJuWKeMqGajQ5BmYGI9pw2/4aB7Y7L9FMtu0I4+tDyof7ixT0W/2v9+8MYa2aBRz8GD6T7kGtzuib8PGC7c93bsQ3dN2TeH509hYjjNqE91d6X7BPmcEWFtR24ckrXJqupq4GLgVknuvZGyV9G9Md0zyS6bu+4tKcledEPbdgGeMkVYg+5OelcC903yyCnqfCTd/9Ev+2U2ZgXdNaC3owuEs22m55WJ4/dB/f/2sAOms9I5PA6m+t/YXBPD3gbfF13QP37IiPIP6dtx/lB52ITzQVWtq6rzquqf6G52Ar//nWRbctsHTWzzA0bMe9CIaTNS3R0yP0zXM3013d0jpzKj17CZnL/GaT6dO9UGA5s0+ybG4/8V3SeDl9PdYGPQmv73AYMT+xeYv53Ftky2nlsCb9vIsg8b8d0xL6LrMfx8VU11/Rp014RcT/cdVXcZnpnue8haDXN/n4Hv9+mvdTm6f/iugXL/SbeNL04yfEvq19Ldrvs/q+o6pu8X/e9Rw/Euoxv+uF8f0Cbaty3dMMldZ7CeqUwMxXpHhr47Kt33Ut16YNK/ATehu0X4zsMVJbl5kn2Hpu2a5G5JZqu9U0qyD90wyJ3obvbyianK9z3Cf9U/fH+SDYYmJnkA8P7+4Utr9FdjDNe7nu7aw3XAW5McltHfubgt3V3zZmpN//uAofpGnleq6id0w2rvQPe/PbjME5nZh0czPg42wVT/G5usv8Z24lw0eP3qxFcvHN1fczRRfge6r0+A7o6iE2Z0Pkhy3ySjeq0mpg1+PcwW2fYRJr4A/nUZ+N7J/jzw97O0jlfRvTb+8TT+b9b0vw8YnLiR17CZnL/GaS7+Z7RAOCRSmn1nAD+k+/QP4NgR10C8h+7arjclOZDu+27uTPddMB+h+96W2XAu3TCsJyc5h26o163ovl/t29x4Y45RPg6cmuRUul6Be9HdyOAK4AUbW3FVfSvJc+je9FyS5HS62+VvS/em48F0341zt03btC3qm3RtHvwetj3ovvvuvROFqmpNkpfSvXE4P8l/023TQ+kuMP8W3a3jZ+IrdG/UXtp/8jpx3chbq2ptkrfQfWfR6iQfo3vBP5Cu5+jz/d+b60S6T9OfBXy3X8/PgdvQfSXDSXTX3VBVJyXZj+6Y+H6Sz9ANJ92FLgg8hC7kHjFQ/4vov4dtop4tpQ/eZ/XtOQvYf5Kho2+qge/L67drZ+CNwBfTfVnweXTDEfej28+/owtr79mgtklU1VlJDqa7zf5JwKuTnE33v7gd3T5+BN2wzYuY3vdsTdiU88oL6Y65NyV5FN3NMO5E94b643TfWTid7dqU42Cmvk13bdLTk/y2r7/o7hK7sQ+QJrw0yZX93xM3HXkC3fuhY6vqhh6zqnp/H1z/hO588FFuvFb0DsB/V9X7BsrP9HzwTOCF/fP/Pbqe2j3o9vl13Pjl7bCR88I0t3063kN3c49H013fdxrdOfspdDfmuCvdcb/Jqvvuzel+/+amvIZN+/w1TnP0P6OFYhy3pvTHn4X+w423dy7grpOUuQfd8MnL6IaGnEc3hHJpv9zJQ+VPZuhWwkPzD2DELa/pTv7H0X1SeS3dnSzfQPcJ/hom/z6lQ+ne6H2lb9+VdEOt7jJi3ZO2je6Lqk+mu6PkdXSB72K6axgeNs39ObFtKyZr63T3Rz9vsn28op9+U7pbTP+wb/MP6ALGTSdp36Pogvov+/Lfo3ujv/OIsivoL2GbYnsf3e/3qwaOo6X9vMV0Xxj7DbpbhP+MLkTeftTzMNm2Tqc9dHfMO5vueotr+/3xPrrr54bLTnxx+WV037/3M7obX7yODb+T6qjJnpsp9snEc3PAFGUmtv/QgWkT27+xn8n+r+5G90XI36Z7w3wN3QcPxw9v1wzPEbeg6/X6At2byevp7tT3Tbow9zg2vM38ocPbN6LeGZ1X+mXuxI3DQK/uj73lk62PEeeNTTwONvifHvFcLh2afh+64L2WLjhMeUwMtXn4OV/f7/szgD+ZZLlt6N5Qrxx4/s9jxNcAzPR8QHeb++PpQvIVdP/P36N7k37PGZ4Xjhq1LzZxH29Hd23ZxPlvDd33De7el//oDI7zor+t/zTKTvY9bDN6DRtYbqPnr8mO8an236j9xuadZ6f9P+PP1vuTqkKSBH0vykNr4G59kqQbrtk8g+57BGdz6L6kjfAaNkmSJAGQ5DYjpt2CG6/bO3VuWyTJa9gkSZI04d+S3Ivuy7N/TndHx8fQDU18R1VN+sXtkrYMA5skSZImfITuxh6Pp/sakWvpbkF/Et0NPSTNMa9hkyRJkqRG2cO2hb373e+uZz/72eNuhiRJkqR2TXrDM286soVdffXV426CJEmSpHnKwCZJkiRJjTKwSZIkSVKjDGySJEmS1CgDmyRJkiQ1ysAmSZIkSY0ysEmSJElSowxskiRJktQoA5skSZIkNcrAJkmSJEmNMrBJkiRJUqMMbJIkSZLUKAObJEmSJDXKwCZJkiRJjTKwSZIkSVKjDGySJEmS1CgDmyRJkiQ1ysAmSZIkSY0ysEmSJElSowxskiRJktQoA5skSZIkNcrAJkmSJEmNMrBJkiRJUqMMbJIkSZLUKAObJEmSJDXKwCZJkiRJjTKwSZIkSVKjDGySJEmS1CgDmyRJkiQ1avG4G7DQrb50LUuP/OS4myFJkiQJWHPM8nE3YUbsYZMkSZKkRhnYJEmSJKlRBjZJkiRJapSBTZIkSZIaZWCTJEmSpEYZ2CRJkiSpUQY2SZIkSWqUgU2SJEmSGmVgkyRJkqRGGdgkSZIkqVEGNkmSJElqlIFNkiRJkhplYJMkSZKkRhnYJEmSJKlRBjZJkiRJapSBTZIkSZIaNZbAluRWSd6f5AdJzkvylSRP2sS6ViRZNvB4aZKLN6NtVw3U88yB6YcmOXZT65UkSZKkmZrzwJYkwEeBL1TVHatqP+DpwG3nui0bsRR45sYKSZIkSdKWMo4etocBv62qt09MqKr/qaq3JlmU5J+TnJvkoiR/AZDkgL4n7cNJvpXkfX3wm9IU9e2Y5Kwk5ydZneSJIxY/BnhwklVJ/l8/7TZJTk/y3SRv3PxdIUmSJEmTG0dg2xM4f5J5zwXWVtV9gPsAf57kDv28ewMvBe4B3BF44MBy7+uD1SrgU9Oo71rgSVW1L3Ag8K8jAuCRwBerap+q+vd+2j7A04C9gKclud2ojUhyeJKVSVauv2btFLtCkiRJkiY39puOJHlbkguTnAs8CnhWH7y+BtwCuHNf9OtV9ZOq+h2wim7I4oRD+mC1D/DYgemT1RfgDUkuAj4L7A7cahrNPauq1lbVtcA3gNuPKlRVJ1TVsqpatmiHJdOoVpIkSZI2tHgM67wEeMrEg6p6YZJdgZXAj4AXV9VnBhdIcgBw3cCk9Uyv7ZmkvkOB3YD9qur6JGuA7aZR36a0QZIkSZI2yTh62D4HbJfk+QPTduh/fwZ4fpJtAZLcJckfbMa6JqtvCXBZH9YOZHRP2a+BnTZj3ZIkSZK0Wea8h6iqKslBwL8n+Rvg58DVwCuAD9ENdTy/v6bs58BBm7G6Eyep733Ax5OspBte+a0Ry14ErEtyIXAy8MvNaIckSZIkzViqatxtWNCe/8qj69Pr9x53MyRJkiQBa45ZPu4mjDLpHfDHftMRSZIkSdJoBjZJkiRJapSBTZIkSZIaZWCTJEmSpEYZ2CRJkiSpUQY2SZIkSWqUgU2SJEmSGmVgkyRJkqRGGdgkSZIkqVEGNkmSJElqlIFNkiRJkhplYJMkSZKkRhnYJEmSJKlRi8fdgIVur92XcPwLlo+7GZIkSZLmIXvYJEmSJKlRBjZJkiRJapSBTZIkSZIaZWCTJEmSpEYZ2CRJkiSpUQY2SZIkSWqUgU2SJEmSGmVgkyRJkqRGGdgkSZIkqVGLx92AhW71pWtZeuQnx90MSZIkaV5bc8zycTdhLOxhkyRJkqRGGdgkSZIkqVEGNkmSJElqlIFNkiRJkhplYJMkSZKkRhnYJEmSJKlRBjZJkiRJapSBTZIkSZIaZWCTJEmSpEYZ2CRJkiSpUQY2SZIkSWqUgU2SJEmSGmVgkyRJkqRGGdgkSZIkqVEGNkmSJElqlIFNkiRJkho1a4EtyZOSVJK7bWY9L0/yrSQXJ7kwybM2Uv7QJLfZnHVKkiRJUotms4ftGcCXgKdvagVJjgAeCdy3qu4JPATIRhY7FNiigS3J4i1ZvyRJkiSNMiuBLcmOwAOB59IHtiTbJDkuySVJPpHkU0kO7uftl+TsJOcl+UySW/dV/R3wgqr6FUBVra2qd/fLvDrJuX3P2wnpHAwsA96XZFWS7SerO8l9klyU5CtJ/jnJxf307ZK8K8nqJBckObCffmiSDyX5OHBGkvcmeeLANr8vyRNmY/9JkiRJ0iiz1cN2EHB6VX0HuCLJvsCTgaXAXsDzgP0BkmwLvBU4uKr2A04CXp9kJ2Cnqvr+JOs4tqru0/e8bQ88rqo+DKwEDqmqfYB1o+rul38XcERV7Q+sH6j3hQBVtRddL+G7k2zXz9sfeHZVPQw4ETis34YlwAOAT41qaJLDk6xMsnL9NWs3uvMkSZIkaZTZCmzPAD7Q//2B/vGDgA9V1e+q6mfA5/v5dwXuCZyZZBXwKuC2dEMfa4p1HJjka0lWAw8D9hxRZmTdSXamC4Pn9OXeP7DMg4D3AlTVt4D/Ae7Szzuzqq7o550N3CnJLfvtO6Wq1o1qaFWdUFXLqmrZoh2WTLFJkiRJkjS5zb42K8kt6ALUPZMUsIgueJ062SLAJX1P13BdVye5Y1X9YGj6dsBxwLKq+nGSo4DthpefrO4kN59qE6aYd/XQ4/cCh9AN+3zOFMtJkiRJ0mabjR62g4H3VNXtq2ppVd0O+CFwOfCU/lq2WwEH9OW/DeyW5IYhkkkmesuOBt6W5Gb9vJslOZwbw9nl/fVyBw+s/9fATlPVXVW/BH6d5P59ucEbo3yBLoSR5C7AH/X1jHIy8FKAqrpkWntHkiRJkjbRbNz98BnAMUPTTgHuDvwEuBj4DvA1YG1V/ba/Wchb+mvBFgNvAi4Bjgd2BM5Ncj1wPfCvVXVlkncCq4E1wLkD6zoZeHuS39BdczZZ3c8F3pnkamAFMHFx2XH98qvproE7tKquSzbseKuq/0vyTeCjM91JkiRJkjRTqZrqsrHNrDzZsaqu6odNfh14YH8925ybaEv/95HAravqL2dYxw50oXHfqprW3USe/8qj69Pr955xeyVJkiTdaM0xy8fdhC1p0su0tvT3i32iv+HHTYDXjius9ZYn+Vu6bf4fuu9vm7Ykj6C76+S/TTesSZIkSdLm2KKBraoO2JL1z0RVfRD44GYs/1m669skSZIkaU7M1m39JUmSJEmzzMAmSZIkSY0ysEmSJElSowxskiRJktQoA5skSZIkNcrAJkmSJEmNMrBJkiRJUqMMbJIkSZLUKAObJEmSJDXKwCZJkiRJjTKwSZIkSVKjDGySJEmS1KjF427AQrfX7ks4/gXLx90MSZIkSfOQPWySJEmS1CgDmyRJkiQ1ysAmSZIkSY0ysEmSJElSowxskiRJktQoA5skSZIkNcrAJkmSJEmNMrBJkiRJUqMMbJIkSZLUqMXjbsBCt/rStSw98pPjboYkCVhzzPJxN0GSpBmxh02SJEmSGmVgkyRJkqRGGdgkSZIkqVEGNkmSJElqlIFNkiRJkhplYJMkSZKkRhnYJEmSJKlRBjZJkiRJapSBTZIkSZIaZWCTJEmSpEYZ2CRJkiSpUQY2SZIkSWqUgU2SJEmSGmVgkyRJkqRGGdgkSZIkqVELKrAleWWSS5JclGRVkvsleWmSHWZYz9IkF2+pdkqSJEnSdCwedwNmS5L9gccB+1bVdUl2BW4CfBD4T+CaEcssqqr1c9tSSZIkSZqehdTDdmvg8qq6DqCqLgcOBm4DfD7J5wGSXJXkH5N8Ddg/ycuSXNz/vHS40iR3THJBkvsk2SPJ6UnOS/LFJHebu82TJEmStLVZSIHtDOB2Sb6T5LgkD62qtwA/BQ6sqgP7cn8AXFxV9wN+AxwG3A+4P/DnSe49UWGSuwKnAIdV1bnACcCLq2o/4OXAcaMakuTwJCuTrFx/zdots7WSJEmSFrwFE9iq6ipgP+Bw4OfAB5McOqLoeroQBvAg4NSqurpf/iPAg/t5uwEfA/60qlYl2RF4APChJKuAd9D16o1qywlVtayqli3aYcmsbJ8kSZKkrc+CuYYNoL8ebQWwIslq4Nkjil07cN1apqhuLfBj4IHAJXTh9sqq2mfWGixJkiRJU1gwPWxJ7prkzgOT9gH+B/g1sNMki30BOCjJDkn+AHgS8MV+3m+Bg4BnJXlmVf0K+GGSp/brS5J7zf6WSJIkSVJnIfWw7Qi8NcnOwDrge3TDI58BfDrJ/w5cxwZAVZ2f5GTg6/2kE6vqgiRL+/lXJ3kccGaSq4FDgOOTvArYFvgAcOEW3zJJkiRJW6VU1bjbsKA9/5VH16fX7z3uZkiSgDXHLB93EyRJGmXSS7UWzJBISZIkSVpoDGySJEmS1CgDmyRJkiQ1ysAmSZIkSY0ysEmSJElSowxskiRJktQoA5skSZIkNcrAJkmSJEmNMrBJkiRJUqMMbJIkSZLUKAObJEmSJDXKwCZJkiRJjTKwSZIkSVKjDGySJEmS1KjF427AQrfX7ks4/gXLx90MSZIkSfOQPWySJEmS1CgDmyRJkiQ1ysAmSZIkSY0ysEmSJElSowxskiRJktQoA5skSZIkNcrAJkmSJEmNMrBJkiRJUqMMbJIkSZLUqMXjbsBCt/rStSw98pPjboYEwJpjlo+7CZIkSZoBe9gkSZIkqVEGNkmSJElqlIFNkiRJkhplYJMkSZKkRhnYJEmSJKlRBjZJkiRJapSBTZIkSZIaZWCTJEmSpEYZ2CRJkiSpUQY2SZIkSWqUgU2SJEmSGmVgkyRJkqRGGdgkSZIkqVEGNkmSJElqlIFNkiRJkhplYJMkSZKkRs2LwJZkfZJVSS5JcmGSlyXZpp+3LMlbNrL8oUmOneE6/27o8Tkzb7kkSZIkbbp5EdiA31TVPlW1J/BI4LHAawCqamVVvWQLrPP3AltVPWALrEOSJEmSJjVfAtsNquoy4HDgRekckOQTAEnum+ScJBf0v+86sOjtkpye5NtJXjMxMcmfJvl634P3jiSLkhwDbN9Pe19f7qqBZf4myeq+t++YudlySZIkSVubeRfYAKrqB3Rtv+XQrG8BD6mqewOvBt4wMO++wCHAPsBT+6GUdweeBjywqvYB1gOHVNWR3Nird8jgCpI8BjgIuF9V3Qt443D7khyeZGWSleuvWbvZ2ytJkiRp67R43A3YDBkxbQnw7iR3BgrYdmDemVX1C4AkHwEeBKwD9gPOTQKwPXDZRtb7COBdVXUNQFVdMVygqk4ATgB4/iuPLtbPYKskSZIkqTcvA1uSO9L1hl0G3H1g1muBz1fVk5IsBVYMzKuhaoou9L27qv52JqsfUZckSZIkzbp5NyQyyW7A24Fjq2o4OC0BLu3/PnRo3iOT7JJke7ohjV8GzgIOTnLLvu5dkty+L399km3Z0BnAc5LsMLHMZm6SJEmSJI00XwLbxA1ALgE+Sxea/mFEuTcCRyf5MrBoaN6XgPcCq4BT+rtLfgN4FXBGkouAM4Fb9+VPAC6auOnIhKo6HTgNWJlkFfDyWdg+SZIkSdpANuyk0mx6/iuPrk+v33vczZAAWHPM8nE3QZIkSRsadX8OYP70sEmSJEnSVsfAJkmSJEmNMrBJkiRJUqMMbJIkSZLUKAObJEmSJDXKwCZJkiRJjTKwSZIkSVKjDGySJEmS1CgDmyRJkiQ1ysAmSZIkSY0ysEmSJElSowxskiRJktQoA5skSZIkNcrAJkmSJEmNWjzuBix0e+2+hONfsHzczZAkSZI0D9nDJkmSJEmNMrBJkiRJUqMMbJIkSZLUKAObJEmSJDXKwCZJkiRJjTKwSZIkSVKjDGySJEmS1CgDmyRJkiQ1ysAmSZIkSY1aPO4GLHSrL13L0iM/Oe5maCu15pjl426CJEmSNoM9bJIkSZLUKAObJEmSJDXKwCZJkiRJjTKwSZIkSVKjDGySJEmS1CgDmyRJkiQ1ysAmSZIkSY0ysEmSJElSowxskiRJktQoA5skSZIkNcrAJkmSJEmNMrBJkiRJUqMMbJIkSZLUKAObJEmSJDXKwCZJkiRJjdrqA1uSVya5JMlFSVYlud+42yRJkiRJAIvH3YBxSrI/8Dhg36q6LsmuwE3G3CxJkiRJAuxhuzVweVVdB1BVl1fVT5Psl+TsJOcl+UySWydZkuTbSe4KkOS/kvz5WFsvSZIkaUHb2gPbGcDtknwnyXFJHppkW+CtwMFVtR9wEvD6qloLvAg4OcnTgZtX1TtHVZrk8CQrk6xcf83audoWSZIkSQvMVh3YquoqYD/gcODnwAeBvwDuCZyZZBXwKuC2ffkzgdXA24DnTVHvCVW1rKqWLdphyRbdBkmSJEkL11Z9DRtAVa0HVgArkqwGXghcUlX7D5dNsg1wd+A3wC7AT+awqZIkSZK2Mlt1D1uSuya588CkfYBvArv1NyQhybZJ9uzn/79+/jOAk/rhk5IkSZK0RWztPWw7Am9NsjOwDvge3fDIE4C3JFlCt4/elOR6umGQ962qXyf5At1wydeMpeWSJEmSFrytOrBV1XnAA0bMuhx4yIjpdx9Y9mVbql2SJEmSBFv5kEhJkiRJapmBTZIkSZIaZWCTJEmSpEYZ2CRJkiSpUQY2SZIkSWqUgU2SJEmSGmVgkyRJkqRGGdgkSZIkqVEGNkmSJElqlIFNkiRJkhplYJMkSZKkRhnYJEmSJKlRBjZJkiRJapSBTZIkSZIatXjcDVjo9tp9Cce/YPm4myFJkiRpHrKHTZIkSZIaZWCTJEmSpEYZ2CRJkiSpUQY2SZIkSWqUgU2SJEmSGmVgkyRJkqRGGdgkSZIkqVEGNkmSJElqlIFNkiRJkhq1eNwNWOhWX7qWpUd+ctzN0Cxbc8zycTdBkiRJWwF72CRJkiSpUQY2SZIkSWqUgU2SJEmSGmVgkyRJkqRGGdgkSZIkqVEGNkmSJElqlIFNkiRJkhplYJMkSZKkRhnYJEmSJKlRBjZJkiRJapSBTZIkSZIaZWCTJEmSpEYZ2CRJkiSpUQY2SZIkSWqUgU2SJEmSGmVgkyRJkqRGbfHAlmR9klVJLklyYZKXJdmmn7csyVv6v2+a5LN92acleXC/zKokpyY5aKDObyd51cDjU5I8eYo2rEiyrP/7qhHzb5Pkw7O42ZIkSZK02eaih+03VbVPVe0JPBJ4LPAagKpaWVUv6cvdG9i2L/tB4BDgX6pqH+Ac4AEASW4BXAXsP7CO/fsym6SqflpVB2/q8pIkSZK0JczpkMiqugw4HHhROgck+USSWwL/CezT96j9BfAnwKuTvA/4Mn1g639/Atitr+MOdKHwZ0mOT7Ky75n7h6nakmTXJF9JsjzJ0iQX99MPTfKRJKcn+W6SNw4s89wk3+l77N6Z5NjZ3keSJEmSNGHOr2Grqh/0673lwLTLgOcBX+x72N4BnAb8dVUdApwH3DPJTegC21eAbwN37x9/ua/qlVW1DNgbeGiSvUe1IcmtgE8Cr66qT44osg/wNGAv4GlJbpfkNsDfA/en6ym822TbmOTwPjiuXH/N2unsFkmSJEnawLhuOpKZFK6q64BLgH3pAtPX6ELbA/qfieGQf5LkfOACYE/gHiOq2xY4C/ibqjpzklWeVVVrq+pa4BvA7YH7AmdX1RVVdT3woSnae0JVLauqZYt2WDKTTZUkSZKkG8x5YEtyR2A9cNkMFz0HeAiwU1X9EvgqNwa2L/dDI18OPLyq9qbrQdtuRD3r6Hrs/niKdV038Pd6YDEzDJmSJEmStLnmNLAl2Q14O3BsVdUMF/8y8BfAhf3ji+h62/6IrvftZsDVwNp+yONjJqmngOcAd0ty5AzW/3W6YZY3T7IYeMoM2y9JkiRJM7J4DtaxfZJVdEMR1wHvBf5tE+o5B7gjcDRAVa1Lchnw46r6HXBhkgvowtsPuPG6tg1U1fokTwc+nuRXwKc2tvKqujTJG+iGY/6UbqikF6hJkiRJ2mIy846urVeSHavqqr6H7VTgpKo6daplnv/Ko+vT60fe+0Tz2Jpjlo+7CZIkSVo4Jr38alw3HZmvjup7Cy8Gfgh8dKytkSRJkrSgzcWQyAWjql4+7jZIkiRJ2nrYwyZJkiRJjTKwSZIkSVKjDGySJEmS1CgDmyRJkiQ1ysAmSZIkSY0ysEmSJElSowxskiRJktQoA5skSZIkNcrAJkmSJEmNMrBJkiRJUqMMbJIkSZLUqMXjbsBCt9fuSzj+BcvH3QxJkiRJ85A9bJIkSZLUKAObJEmSJDXKwCZJkiRJjTKwSZIkSVKjDGySJEmS1CgDmyRJkiQ1ysAmSZIkSY0ysEmSJElSowxskiRJktSoxeNuwEK3+tK1LD3yk+NuhmbRmmOWj7sJkiRJ2krYwyZJkiRJjTKwSZIkSVKjDGySJEmS1CgDmyRJkiQ1ysAmSZIkSY0ysEmSJElSowxskiRJktQoA5skSZIkNcrAJkmSJEmNMrBJkiRJUqMMbJIkSZLUKAObJEmSJDXKwCZJkiRJjTKwSZIkSVKjDGySJEmS1CgDmyRJkiQ1aqOBLcn6JKuSXJzkQ0l2SLI0ycWbu/IkRyR51iYue1X/e4O2JDkqycs3sd5Dkxzb/31QknsMzFuRZNmm1CtJkiRJMzWdHrbfVNU+VXVP4LfAEbO18qp6e1W9Z7bq2wIOAu6xsUKSJEmStCXMdEjkF4E79X8vSvLOJJckOSPJ9kn2SHL+ROEkd05yXv/3MUm+keSiJP/ST7uhJyzJnZJ8NsmFSc7v69oxyVn949VJnjjTDezrOT3JeUm+mORu/fTHJ/lakgv69d5qaLkHAE8A/rnvYdyjn/XUJF9P8p0kD55peyRJkiRpuqYd2JIsBh4DrO4n3Rl4W1XtCVwJPKWqvg+sTbJPX+Yw4OQkuwBPAvasqr2B141Yxfv6+u4FPAD4X+Ba4ElVtS9wIPCvSTJi2T36ULUqySp+vxfwBODFVbUf8HLguH76l4D7V9W9gQ8AfzNYYVWdA5wG/HXfw/j9ftbiqrov8FLgNZPsq8OTrEyycv01a0cVkSRJkqSNmk5g274PQSuBHwH/0U//YVWt6v8+D1ja/30icFiSRcDTgPcDv6ILXycmeTJwzeAKkuwE7F5VpwJU1bVVdQ0Q4A1JLgI+C+wO/F5PWO/7fajap6r2Ad7e17sjXfj7UL8N7wBu3S9zW+AzSVYDfw3sOY19AfCREdv8e6rqhKpaVlXLFu2wZJrVSpIkSdLvWzyNMr/pQ9AN+k6u6wYmrQe27/8+ha7n6XPAeVX1i36Z+wIPB54OvAh42GCVk6z7EGA3YL+quj7JGmC7abR5wjbAlcPt770V+LeqOi3JAcBR06xzYrvXM739J0mSJEmbZNZv619V1wKfAY4H3gU39HQtqapP0Q0l3GdomV8BP0lyUF/+pkl2AJYAl/Vh7UDg9jNsy6+AHyZ5al9vktyrn70EuLT/+9mTVPFrYKeZrFOSJEmSZsuW+h629wEFnNE/3gn4RD+08Wzg/41Y5s+Al/RlzgH+sK9nWZKVdL1t39qEthwCPDfJhcAlwMSNS46iGyr5ReDySZb9APDX/Y1J9pikjCRJkiRtEamq2a+0u/Pjkqr6+1mvfJ55/iuPrk+v33vczdAsWnPM8nE3QZIkSQvLZJeIzf41WElOBfbg969RkyRJkiTN0KwHtqp60mzXKUmSJElboy11DZskSZIkaTMZ2CRJkiSpUQY2SZIkSWqUgU2SJEmSGmVgkyRJkqRGGdgkSZIkqVEGNkmSJElqlIFNkiRJkhplYJMkSZKkRhnYJEmSJKlRBjZJkiRJapSBTZIkSZIatXjcDVjo9tp9Cce/YPm4myFJkiRpHrKHTZIkSZIaZWCTJEmSpEYZ2CRJkiSpUQY2SZIkSWqUgU2SJEmSGmVgkyRJkqRGGdgkSZIkqVEGNkmSJElqlIFNkiRJkhq1eNwNWOhWX7qWpUd+ctzN0EasOWb5uJsgSZIkbcAeNkmSJElqlIFNkiRJkhplYJMkSZKkRhnYJEmSJKlRBjZJkiRJapSBTZIkSZIaZWCTJEmSpEYZ2CRJkiSpUQY2SZIkSWqUgU2SJEmSGmVgkyRJkqRGGdgkSZIkqVEGNkmSJElqlIFNkiRJkhplYJMkSZKkRhnYJEmSJKlRW31gS7I+yaokFyY5P8kD+ulLk1SS1w6U3TXJ9UmO7R8fleTl42q7JEmSpIVtqw9swG+qap+quhfwt8DRA/N+ADxu4PFTgUvmsnGSJEmStl4Gtt93M+CXA49/A3wzybL+8dOA/57zVkmSJEnaKhnYYPt+SOS3gBOB1w7N/wDw9CS3BdYDP91YhUkOT7Iyycr116yd/RZLkiRJ2ioY2G4cEnk34NHAe5JkYP7pwCOBZwAfnE6FVXVCVS2rqmWLdlgy+y2WJEmStFUwsA2oqq8AuwK7DUz7LXAe8FfAKWNqmiRJkqSt0OJxN6AlSe4GLAJ+AewwMOtfgbOr6he/3/kmSZIkSVuOga2/hq3/O8Czq2r9YDCrqkvw7pCSJEmS5thWH9iqatEk09cA9xwx/WTg5P7vo7ZcyyRJkiRt7byGTZIkSZIaZWCTJEmSpEYZ2CRJkiSpUQY2SZIkSWqUgU2SJEmSGmVgkyRJkqRGGdgkSZIkqVEGNkmSJElqlIFNkiRJkhplYJMkSZKkRhnYJEmSJKlRBjZJkiRJapSBTZIkSZIatXjcDVjo9tp9Cce/YPm4myFJkiRpHrKHTZIkSZIaZWCTJEmSpEYZ2CRJkiSpUQY2SZIkSWqUgU2SJEmSGmVgkyRJkqRGGdgkSZIkqVEGNkmSJElqlIFNkiRJkhq1eNwNWOhWX7qWpUd+ctzN2CqtOWb5uJsgSZIkbRZ72CRJkiSpUQY2SZIkSWqUgU2SJEmSGmVgkyRJkqRGGdgkSZIkqVEGNkmSJElqlIFNkiRJkhplYJMkSZKkRhnYJEmSJKlRBjZJkiRJapSBTZIkSZIaZWCTJEmSpEYZ2CRJkiSpUQY2SZIkSWqUgU2SJEmSGmVgkyRJkqRGLR53A+ZKkvXAarpt/iHwZ1V15VgbJUmSJElT2Jp62H5TVftU1T2BK4AXjrtBkiRJkjSVrSmwDfoKsDtAkvsmOSfJBf3vu/bTFyX5lySrk1yU5MX99P2SnJ3kvCSfSXLrMW6HJEmSpAVsqwtsSRYBDwdO6yd9C3hIVd0beDXwhn764cAdgHtX1d7A+5JsC7wVOLiq9gNOAl4/Yh2HJ1mZZOX6a9Zu2Q2SJEmStGBtTYFt+ySrgF8AuwBn9tOXAB9KcjHw78Ce/fRHAG+vqnUAVXUFcFfgnsCZfV2vAm47vKKqOqGqllXVskU7LNlyWyRJkiRpQduaAttvqmof4PbATbjxGrbXAp/vr217PLBdPz1ADdUR4JL+Wrh9qmqvqnrUlm+6JEmSpK3R1hTYAKiqtcBLgJf3QxyXAJf2sw8dKHoGcESSxQBJdgG+DeyWZP9+2rZJ9kSSJEmStoCtLrABVNUFwIXA04E3Akcn+TKwaKDYicCPgIuSXAg8s6p+CxwM/FM/bRXwgLlsuyRJkqStx1bzPWxVtePQ48cPPLzLwN9/389fB7ys/xlcbhXwkC3TSkmSJEm60VbZwyZJkiRJ84GBTZIkSZIaZWCTJEmSpEYZ2CRJkiSpUQY2SZIkSWqUgU2SJEmSGmVgkyRJkqRGGdgkSZIkqVEGNkmSJElqlIFNkiRJkhplYJMkSZKkRhnYJEmSJKlRBjZJkiRJapSBTZIkSZIatXjcDVjo9tp9Cce/YPm4myFJkiRpHrKHTZIkSZIaZWCTJEmSpEYZ2CRJkiSpUQY2SZIkSWqUgU2SJEmSGmVgkyRJkqRGGdgkSZIkqVEGNkmSJElqlIFNkiRJkhq1eNwNWOhWX7qWpUd+ctzNWJDWHLN83E2QJEmStih72CRJkiSpUQY2SZIkSWqUgU2SJEmSGmVgkyRJkqRGGdgkSZIkqVEGNkmSJElqlIFNkiRJkhplYJMkSZKkRhnYJEmSJKlRBjZJkiRJapSBTZIkSZIaZWCTJEmSpEYZ2CRJkiSpUQY2SZIkSWqUgU2SJEmSGrXRwJbkqoG/H5vku0n+KMkRSZ41ovzSJBfPdkOTrEmyuv/5RpLXJblpP+82ST482+uUJEmSpHFaPN2CSR4OvBV4VFX9CHj7FmvV5A6sqsuT7Aic0P88u6p+Chw8hvZIkiRJ0hYzrSGRSR4MvBNYXlXf76cdleTl/d/7JbkwyVeAFw4sd2iSjyQ5ve+Ze+PAvEcl+UqS85N8KMmOSR6e5NSBMo9M8pHh9lTVVcARwEFJdhns1UuyZ5KvJ1mV5KIkd+6n/+nA9HckWdRPPz7JyiSXJPmHgXUf0/fkXZTkX/ppuyU5Jcm5/c8Dp72nJUmSJGmGphPYbgp8DDioqr41SZl3AS+pqv1HzNsHeBqwF/C0JLdLsivwKuARVbUvsBJ4GfA54O5JduuXPayvewNV9Svgh8Cdh2YdAby5qvYBlgE/SXL3vg0P7KevBw7py7+yqpYBewMPTbJ3kl2AJwF7VtXewOv6sm8G/r2q7gM8BThxVNuSHN6HwJXrr1k7qogkSZIkbdR0Atv1wDnAc0fNTLIE2Lmqzu4nvXeoyFlVtbaqrgW+AdweuD9wD+DLSVYBzwZuX1XVL/+nSXYG9gc+PUXbMmLaV4C/S/KKvs7fAA8H9gPO7df3cOCOffk/SXI+cAGwZ9+uXwHXAicmeTJwTV/2EcCxfR2nATdLstNwA6rqhKpaVlXLFu2wZIrmS5IkSdLkpnMN2++APwE+m+TvquoNQ/MD1BTLXzfw9/p+nQHOrKpnjCj/LuDjdIHpQ1W1blSlfVBaCnwHuCEVVdX7k3wNWA58Jsnz+vW9u6r+dqiOOwAvB+5TVb9McjKwXVWtS3JfumD3dOBFwMPoAu7+fQiUJEmSpC1qWtewVdU1wOOAQ5I8d2jelcDaJA/qJx3Cxn0VeGCSOwEk2SHJXfr6fgr8lG7I5MmjFu5vOnIc8NGq+uXQvDsCP6iqt9D1gu0NnAUcnOSWfZldktweuBlwdd/+WwGPGah/SVV9Cngp3bBOgDPowtvEuiamS5IkSdKsm/ZdIqvqiiSPBr6Q5PKh2YcBJyW5BvjMNOr6eZJDgf+auDU/XUD7Tv/3+4DdquobQ4t+PknoguapwGtHVP80uiGV1wM/A/6xb/urgDOSbEM3zPOFVfXVJBcAlwA/AL7c17ET8LEk29H1zv2/fvpLgLcluYhu332B7po5SZIkSZp16S4ba0uSY4ELquo/xt2WzfX8Vx5dn16/97ibsSCtOWb5uJsgSZIkzYZR9+YAZtDDNleSnEc3TPGvxt0WSZIkSRqn5gJbVe037jZIkiRJUgumddMRSZIkSdLcM7BJkiRJUqMMbJIkSZLUKAObJEmSJDXKwCZJkiRJjTKwSZIkSVKjDGySJEmS1CgDmyRJkiQ1ysAmSZIkSY0ysEmSJElSowxskiRJktQoA5skSZIkNWrxuBuw0O21+xKOf8HycTdDkiRJ0jxkD5skSZIkNcrAJkmSJEmNMrBJkiRJUqMMbJIkSZLUKAObJEmSJDXKwCZJkiRJjTKwSZIkSVKjDGySJEmS1CgDmyRJkiQ1ysAmSZIkSY0ysEmSJElSowxskiRJktQoA5skSZIkNcrAJkmSJEmNMrBJkiRJUqMMbJIkSZLUKAObJEmSJDXKwCZJkiRJjTKwSZIkSVKjDGySJEmS1CgDmyRJkiQ1ysAmSZIkSY0ysEmSJElSowxskiRJktQoA5skSZIkNcrAJkmSJEmNMrBJkiRJUqMMbJIkSZLUKAObJEmSJDUqVTXuNixor3jFK3697bbbfnvc7dDCcdVVV+264447Xj7udmjh8JjSbPJ40mzzmNJsa/SYuvx1r3vdo0fNMLBtYUlWVtWycbdDC4fHlGabx5Rmk8eTZpvHlGbbfDumHBIpSZIkSY0ysEmSJElSowxsW94J426AFhyPKc02jynNJo8nzTaPKc22eXVMeQ2bJEmSJDXKHjZJkiRJapSBTZIkSZIaZWCbJUkeneTbSb6X5MgR85PkLf38i5LsO452an6YxvF0SH8cXZTknCT3Gkc7NX9s7JgaKHefJOuTHDyX7dP8M51jKskBSVYluSTJ2XPdRs0v03jtW5Lk40ku7I+pw8bRTs0PSU5KclmSiyeZP2/emxvYZkGSRcDbgMcA9wCekeQeQ8UeA9y5/zkcOH5OG6l5Y5rH0w+Bh1bV3sBrmWcXz2puTfOYmij3T8Bn5raFmm+mc0wl2Rk4DnhCVe0JPHWu26n5Y5rnqRcC36iqewEHAP+a5CZz2lDNJycDI7+Iujdv3psb2GbHfYHvVdUPquq3wAeAJw6VeSLwnup8Fdg5ya3nuqGaFzZ6PFXVOVX1y/7hV4HbznEbNb9M5xwF8GLgFOCyuWyc5qXpHFPPBD5SVT8CqCqPK01lOsdUATslCbAjcAWwbm6bqfmiqr5Ad4xMZt68NzewzY7dgR8PPP5JP22mZSSY+bHyXODTW7RFmu82ekwl2R14EvD2OWyX5q/pnKfuAtw8yYok5yV51py1TvPRdI6pY4G7Az8FVgN/WVW/m5vmaQGaN+/NF4+7AQtERkwb/r6E6ZSRYAbHSpID6QLbg7ZoizTfTeeYehPwiqpa3314LU1pOsfUYmA/4OHA9sBXkny1qr6zpRuneWk6x9QfA6uAhwF7AGcm+WJV/WoLt00L07x5b25gmx0/AW438Pi2dJ/+zLSMBNM8VpLsDZwIPKaqfjFHbdP8NJ1jahnwgT6s7Qo8Nsm6qvronLRQ8810X/cur6qrgauTfAG4F2Bg0yjTOaYOA46p7kuEv5fkh8DdgK/PTRO1wMyb9+YOiZwd5wJ3TnKH/uLXpwOnDZU5DXhWf0ea+wNrq+p/57qhmhc2ejwl+SPgI8Cf+Wm1pmGjx1RV3aGqllbVUuDDwAsMa5rCdF73PgY8OMniJDsA9wO+Ocft1PwxnWPqR3Q9tiS5FXBX4Adz2kotJPPmvbk9bLOgqtYleRHdndUWASdV1SVJjujnvx34FPBY4HvANXSfEkkbmObx9GrgFsBxfY/IuqpaNq42q23TPKakaZvOMVVV30xyOnAR8DvgxKoaeXttaZrnqdcCJydZTTec7RVVdfnYGq2mJfkvuruJ7prkJ8BrgG1h/r03T9erLEmSJElqjUMiJUmSJKlRBjZJkiRJapSBTZIkSZIaZWCTJEmSpEYZ2CRJkiSpUQY2SZIkSWqUgU2SJEmSGvX/Aer2BsUWpncLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1008x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<h2o.plot._plot_result._MObject at 0x7fb6d87598b0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "aml.leader.varimp_plot()\n",
    "#variance importance plot for the leader model.\n",
    "#taken from references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2a0c54be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
       "=============\n",
       "H2OXGBoostEstimator : XGBoost\n",
       "Model Key: XGBoost_3_AutoML_3_20221108_212840\n",
       "</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-14.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-14 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-14 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-14 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-14 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-14 .h2o-table th,\n",
       "#h2o-table-14 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-14 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-14\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Model Summary: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>number_of_trees</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>55.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: xgboost\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.06395236788288416\n",
       "RMSE: 0.2528880540533383\n",
       "LogLoss: 0.22035946660347489\n",
       "Mean Per-Class Error: 0.29272633188266417\n",
       "AUC: 0.8519084415463216\n",
       "AUCPR: 0.3814190648417427\n",
       "Gini: 0.7038168830926432</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-15.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-15 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-15 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-15 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-15 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-15 .h2o-table th,\n",
       "#h2o-table-15 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-15 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-15\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.21242088954735622</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>No</th>\n",
       "<th>Yes</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>No</td>\n",
       "<td>187064.0</td>\n",
       "<td>17642.0</td>\n",
       "<td>0.0862</td>\n",
       "<td> (17642.0/204706.0)</td></tr>\n",
       "<tr><td>Yes</td>\n",
       "<td>9582.0</td>\n",
       "<td>9610.0</td>\n",
       "<td>0.4993</td>\n",
       "<td> (9582.0/19192.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>196646.0</td>\n",
       "<td>27252.0</td>\n",
       "<td>0.1216</td>\n",
       "<td> (27224.0/223898.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-16.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-16 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-16 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-16 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-16 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-16 .h2o-table th,\n",
       "#h2o-table-16 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-16 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-16\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.2124209</td>\n",
       "<td>0.4138317</td>\n",
       "<td>199.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1018012</td>\n",
       "<td>0.5338837</td>\n",
       "<td>278.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.3245512</td>\n",
       "<td>0.4148415</td>\n",
       "<td>138.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4871197</td>\n",
       "<td>0.9178063</td>\n",
       "<td>74.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9230320</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0023855</td>\n",
       "<td>1.0</td>\n",
       "<td>398.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9230320</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.1977421</td>\n",
       "<td>0.3560641</td>\n",
       "<td>208.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.1018012</td>\n",
       "<td>0.7695915</td>\n",
       "<td>278.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.0930588</td>\n",
       "<td>0.7725375</td>\n",
       "<td>286.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9230320</td>\n",
       "<td>204706.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9230320</td>\n",
       "<td>19191.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0018907</td>\n",
       "<td>204706.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0023855</td>\n",
       "<td>19192.0</td>\n",
       "<td>398.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9230320</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9230320</td>\n",
       "<td>0.9999479</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0018907</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0023855</td>\n",
       "<td>1.0</td>\n",
       "<td>398.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-17.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-17 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-17 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-17 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-17 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-17 .h2o-table th,\n",
       "#h2o-table-17 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-17 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-17\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate:  8.57 %, avg score:  8.58 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0100001</td>\n",
       "<td>0.5454391</td>\n",
       "<td>7.6645835</td>\n",
       "<td>7.6645835</td>\n",
       "<td>0.6569897</td>\n",
       "<td>0.6360089</td>\n",
       "<td>0.6569897</td>\n",
       "<td>0.6360089</td>\n",
       "<td>0.0766465</td>\n",
       "<td>0.0766465</td>\n",
       "<td>666.4583473</td>\n",
       "<td>666.4583473</td>\n",
       "<td>0.0728948</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0200002</td>\n",
       "<td>0.4633881</td>\n",
       "<td>5.9451324</td>\n",
       "<td>6.8048579</td>\n",
       "<td>0.5096025</td>\n",
       "<td>0.5000470</td>\n",
       "<td>0.5832961</td>\n",
       "<td>0.5680279</td>\n",
       "<td>0.0594519</td>\n",
       "<td>0.1360984</td>\n",
       "<td>494.5132388</td>\n",
       "<td>580.4857931</td>\n",
       "<td>0.1269829</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0300003</td>\n",
       "<td>0.4112042</td>\n",
       "<td>5.1531428</td>\n",
       "<td>6.2542862</td>\n",
       "<td>0.4417151</td>\n",
       "<td>0.4356757</td>\n",
       "<td>0.5361024</td>\n",
       "<td>0.5239105</td>\n",
       "<td>0.0515319</td>\n",
       "<td>0.1876303</td>\n",
       "<td>415.3142798</td>\n",
       "<td>525.4286220</td>\n",
       "<td>0.1724084</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0400048</td>\n",
       "<td>0.3703723</td>\n",
       "<td>4.7602324</td>\n",
       "<td>5.8806477</td>\n",
       "<td>0.4080357</td>\n",
       "<td>0.3901641</td>\n",
       "<td>0.5040750</td>\n",
       "<td>0.4904627</td>\n",
       "<td>0.0476240</td>\n",
       "<td>0.2352543</td>\n",
       "<td>376.0232407</td>\n",
       "<td>488.0647664</td>\n",
       "<td>0.2135549</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0500004</td>\n",
       "<td>0.3397464</td>\n",
       "<td>3.9721429</td>\n",
       "<td>5.4991172</td>\n",
       "<td>0.3404826</td>\n",
       "<td>0.3541731</td>\n",
       "<td>0.4713711</td>\n",
       "<td>0.4632170</td>\n",
       "<td>0.0397040</td>\n",
       "<td>0.2749583</td>\n",
       "<td>297.2142939</td>\n",
       "<td>449.9117198</td>\n",
       "<td>0.2460486</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1000009</td>\n",
       "<td>0.2398401</td>\n",
       "<td>3.3784609</td>\n",
       "<td>4.4387890</td>\n",
       "<td>0.2895936</td>\n",
       "<td>0.2837860</td>\n",
       "<td>0.3804824</td>\n",
       "<td>0.3735015</td>\n",
       "<td>0.1689246</td>\n",
       "<td>0.4438829</td>\n",
       "<td>237.8460859</td>\n",
       "<td>343.8789029</td>\n",
       "<td>0.3761223</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1500237</td>\n",
       "<td>0.1805089</td>\n",
       "<td>2.4165731</td>\n",
       "<td>3.7645164</td>\n",
       "<td>0.2071429</td>\n",
       "<td>0.2081964</td>\n",
       "<td>0.3226853</td>\n",
       "<td>0.3183834</td>\n",
       "<td>0.1208837</td>\n",
       "<td>0.5647666</td>\n",
       "<td>141.6573126</td>\n",
       "<td>276.4516385</td>\n",
       "<td>0.4536267</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2000018</td>\n",
       "<td>0.1425423</td>\n",
       "<td>1.9329011</td>\n",
       "<td>3.3068171</td>\n",
       "<td>0.1656836</td>\n",
       "<td>0.1614080</td>\n",
       "<td>0.2834524</td>\n",
       "<td>0.2791571</td>\n",
       "<td>0.0966028</td>\n",
       "<td>0.6613693</td>\n",
       "<td>93.2901052</td>\n",
       "<td>230.6817064</td>\n",
       "<td>0.5046226</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3000027</td>\n",
       "<td>0.0903046</td>\n",
       "<td>1.3667031</td>\n",
       "<td>2.6601124</td>\n",
       "<td>0.1171505</td>\n",
       "<td>0.1140976</td>\n",
       "<td>0.2280185</td>\n",
       "<td>0.2241373</td>\n",
       "<td>0.1366715</td>\n",
       "<td>0.7980409</td>\n",
       "<td>36.6703090</td>\n",
       "<td>166.0112406</td>\n",
       "<td>0.5447312</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.3999991</td>\n",
       "<td>0.0574882</td>\n",
       "<td>0.8347526</td>\n",
       "<td>2.2037877</td>\n",
       "<td>0.0715530</td>\n",
       "<td>0.0726463</td>\n",
       "<td>0.1889034</td>\n",
       "<td>0.1862658</td>\n",
       "<td>0.0834723</td>\n",
       "<td>0.8815131</td>\n",
       "<td>-16.5247373</td>\n",
       "<td>120.3787748</td>\n",
       "<td>0.5266579</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5001161</td>\n",
       "<td>0.0361844</td>\n",
       "<td>0.5313707</td>\n",
       "<td>1.8689907</td>\n",
       "<td>0.0455478</td>\n",
       "<td>0.0462545</td>\n",
       "<td>0.1602054</td>\n",
       "<td>0.1582373</td>\n",
       "<td>0.0531992</td>\n",
       "<td>0.9347124</td>\n",
       "<td>-46.8629300</td>\n",
       "<td>86.8990690</td>\n",
       "<td>0.4753414</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6000009</td>\n",
       "<td>0.0219814</td>\n",
       "<td>0.3150775</td>\n",
       "<td>1.6103040</td>\n",
       "<td>0.0270077</td>\n",
       "<td>0.0289124</td>\n",
       "<td>0.1380314</td>\n",
       "<td>0.1367080</td>\n",
       "<td>0.0314714</td>\n",
       "<td>0.9661838</td>\n",
       "<td>-68.4922469</td>\n",
       "<td>61.0303980</td>\n",
       "<td>0.4005140</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.6999973</td>\n",
       "<td>0.0134207</td>\n",
       "<td>0.1698685</td>\n",
       "<td>1.4045340</td>\n",
       "<td>0.0145607</td>\n",
       "<td>0.0174599</td>\n",
       "<td>0.1203933</td>\n",
       "<td>0.1196731</td>\n",
       "<td>0.0169862</td>\n",
       "<td>0.9831701</td>\n",
       "<td>-83.0131488</td>\n",
       "<td>40.4534050</td>\n",
       "<td>0.3097213</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.7999982</td>\n",
       "<td>0.0081765</td>\n",
       "<td>0.0932672</td>\n",
       "<td>1.2406239</td>\n",
       "<td>0.0079946</td>\n",
       "<td>0.0106338</td>\n",
       "<td>0.1063433</td>\n",
       "<td>0.1060430</td>\n",
       "<td>0.0093268</td>\n",
       "<td>0.9924969</td>\n",
       "<td>-90.6732805</td>\n",
       "<td>24.0623863</td>\n",
       "<td>0.2105462</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8999991</td>\n",
       "<td>0.0047262</td>\n",
       "<td>0.0510625</td>\n",
       "<td>1.1084491</td>\n",
       "<td>0.0043770</td>\n",
       "<td>0.0062897</td>\n",
       "<td>0.0950136</td>\n",
       "<td>0.0949592</td>\n",
       "<td>0.0051063</td>\n",
       "<td>0.9976032</td>\n",
       "<td>-94.8937513</td>\n",
       "<td>10.8449065</td>\n",
       "<td>0.1067548</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0009442</td>\n",
       "<td>0.0239681</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0020545</td>\n",
       "<td>0.0033650</td>\n",
       "<td>0.0857176</td>\n",
       "<td>0.0857997</td>\n",
       "<td>0.0023968</td>\n",
       "<td>1.0</td>\n",
       "<td>-97.6031894</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: xgboost\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.06637189113184688\n",
       "RMSE: 0.2576274269790522\n",
       "LogLoss: 0.22762759473977812\n",
       "Mean Per-Class Error: 0.27618870238825843\n",
       "AUC: 0.8435790782332893\n",
       "AUCPR: 0.3434588136032144\n",
       "Gini: 0.6871581564665785</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-18.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-18 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-18 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-18 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-18 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-18 .h2o-table th,\n",
       "#h2o-table-18 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-18 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-18\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.17301240337045887</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>No</th>\n",
       "<th>Yes</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>No</td>\n",
       "<td>38462.0</td>\n",
       "<td>5256.0</td>\n",
       "<td>0.1202</td>\n",
       "<td> (5256.0/43718.0)</td></tr>\n",
       "<tr><td>Yes</td>\n",
       "<td>1793.0</td>\n",
       "<td>2356.0</td>\n",
       "<td>0.4322</td>\n",
       "<td> (1793.0/4149.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>40255.0</td>\n",
       "<td>7612.0</td>\n",
       "<td>0.1473</td>\n",
       "<td> (7049.0/47867.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-19.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-19 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-19 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-19 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-19 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-19 .h2o-table th,\n",
       "#h2o-table-19 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-19 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-19\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.1730124</td>\n",
       "<td>0.4006462</td>\n",
       "<td>221.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1041757</td>\n",
       "<td>0.5322750</td>\n",
       "<td>275.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.2844224</td>\n",
       "<td>0.3789017</td>\n",
       "<td>154.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.5400776</td>\n",
       "<td>0.9152861</td>\n",
       "<td>57.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.8235585</td>\n",
       "<td>0.8333333</td>\n",
       "<td>3.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0019703</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.8719520</td>\n",
       "<td>0.9999771</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.1492300</td>\n",
       "<td>0.3474447</td>\n",
       "<td>238.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.0994812</td>\n",
       "<td>0.7660231</td>\n",
       "<td>279.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.0811358</td>\n",
       "<td>0.7700010</td>\n",
       "<td>295.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.8719520</td>\n",
       "<td>43717.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.8719520</td>\n",
       "<td>4149.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0019703</td>\n",
       "<td>43718.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0019703</td>\n",
       "<td>4149.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.8719520</td>\n",
       "<td>0.9999771</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.8719520</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0019703</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0019703</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-20.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-20 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-20 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-20 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-20 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-20 .h2o-table th,\n",
       "#h2o-table-20 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-20 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-20\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate:  8.67 %, avg score:  8.55 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0100069</td>\n",
       "<td>0.5461605</td>\n",
       "<td>6.8884783</td>\n",
       "<td>6.8884783</td>\n",
       "<td>0.5970772</td>\n",
       "<td>0.6343759</td>\n",
       "<td>0.5970772</td>\n",
       "<td>0.6343759</td>\n",
       "<td>0.0689323</td>\n",
       "<td>0.0689323</td>\n",
       "<td>588.8478296</td>\n",
       "<td>588.8478296</td>\n",
       "<td>0.0645176</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0200138</td>\n",
       "<td>0.4632082</td>\n",
       "<td>5.2988295</td>\n",
       "<td>6.0936539</td>\n",
       "<td>0.4592902</td>\n",
       "<td>0.5018253</td>\n",
       "<td>0.5281837</td>\n",
       "<td>0.5681006</td>\n",
       "<td>0.0530248</td>\n",
       "<td>0.1219571</td>\n",
       "<td>429.8829459</td>\n",
       "<td>509.3653877</td>\n",
       "<td>0.1116181</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0299998</td>\n",
       "<td>0.4107290</td>\n",
       "<td>4.4892917</td>\n",
       "<td>5.5596113</td>\n",
       "<td>0.3891213</td>\n",
       "<td>0.4363776</td>\n",
       "<td>0.4818942</td>\n",
       "<td>0.5242541</td>\n",
       "<td>0.0448301</td>\n",
       "<td>0.1667872</td>\n",
       "<td>348.9291668</td>\n",
       "<td>455.9611303</td>\n",
       "<td>0.1497690</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0400694</td>\n",
       "<td>0.3664205</td>\n",
       "<td>4.4041648</td>\n",
       "<td>5.2692436</td>\n",
       "<td>0.3817427</td>\n",
       "<td>0.3870902</td>\n",
       "<td>0.4567258</td>\n",
       "<td>0.4897843</td>\n",
       "<td>0.0443480</td>\n",
       "<td>0.2111352</td>\n",
       "<td>340.4164779</td>\n",
       "<td>426.9243616</td>\n",
       "<td>0.1873006</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0500136</td>\n",
       "<td>0.3370934</td>\n",
       "<td>3.7325578</td>\n",
       "<td>4.9637037</td>\n",
       "<td>0.3235294</td>\n",
       "<td>0.3509687</td>\n",
       "<td>0.4302423</td>\n",
       "<td>0.4621836</td>\n",
       "<td>0.0371174</td>\n",
       "<td>0.2482526</td>\n",
       "<td>273.2557810</td>\n",
       "<td>396.3703748</td>\n",
       "<td>0.2170526</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1000063</td>\n",
       "<td>0.2386483</td>\n",
       "<td>3.2639143</td>\n",
       "<td>4.1139866</td>\n",
       "<td>0.2829085</td>\n",
       "<td>0.2813811</td>\n",
       "<td>0.3565908</td>\n",
       "<td>0.3718012</td>\n",
       "<td>0.1631718</td>\n",
       "<td>0.4114244</td>\n",
       "<td>226.3914283</td>\n",
       "<td>311.3986558</td>\n",
       "<td>0.3409729</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1499990</td>\n",
       "<td>0.1783284</td>\n",
       "<td>2.6371656</td>\n",
       "<td>3.6217815</td>\n",
       "<td>0.2285834</td>\n",
       "<td>0.2068893</td>\n",
       "<td>0.3139276</td>\n",
       "<td>0.3168382</td>\n",
       "<td>0.1318390</td>\n",
       "<td>0.5432634</td>\n",
       "<td>163.7165602</td>\n",
       "<td>262.1781468</td>\n",
       "<td>0.4305867</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2000125</td>\n",
       "<td>0.1418367</td>\n",
       "<td>2.1204171</td>\n",
       "<td>3.2463620</td>\n",
       "<td>0.1837928</td>\n",
       "<td>0.1603630</td>\n",
       "<td>0.2813871</td>\n",
       "<td>0.2777113</td>\n",
       "<td>0.1060497</td>\n",
       "<td>0.6493131</td>\n",
       "<td>112.0417135</td>\n",
       "<td>224.6361976</td>\n",
       "<td>0.4919408</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.2999979</td>\n",
       "<td>0.0900938</td>\n",
       "<td>1.4150057</td>\n",
       "<td>2.6359949</td>\n",
       "<td>0.1226494</td>\n",
       "<td>0.1139307</td>\n",
       "<td>0.2284819</td>\n",
       "<td>0.2231253</td>\n",
       "<td>0.1414799</td>\n",
       "<td>0.7907930</td>\n",
       "<td>41.5005675</td>\n",
       "<td>163.5994897</td>\n",
       "<td>0.5373733</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4000042</td>\n",
       "<td>0.0572581</td>\n",
       "<td>0.8724447</td>\n",
       "<td>2.1950843</td>\n",
       "<td>0.0756215</td>\n",
       "<td>0.0722966</td>\n",
       "<td>0.1902648</td>\n",
       "<td>0.1854162</td>\n",
       "<td>0.0872499</td>\n",
       "<td>0.8780429</td>\n",
       "<td>-12.7555282</td>\n",
       "<td>119.5084326</td>\n",
       "<td>0.5234064</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5000104</td>\n",
       "<td>0.0363731</td>\n",
       "<td>0.5253949</td>\n",
       "<td>1.8611325</td>\n",
       "<td>0.0455400</td>\n",
       "<td>0.0464366</td>\n",
       "<td>0.1613186</td>\n",
       "<td>0.1576191</td>\n",
       "<td>0.0525428</td>\n",
       "<td>0.9305857</td>\n",
       "<td>-47.4605114</td>\n",
       "<td>86.1132485</td>\n",
       "<td>0.4714384</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.5999958</td>\n",
       "<td>0.0220013</td>\n",
       "<td>0.2868580</td>\n",
       "<td>1.5987900</td>\n",
       "<td>0.0248642</td>\n",
       "<td>0.0289804</td>\n",
       "<td>0.1385794</td>\n",
       "<td>0.1361823</td>\n",
       "<td>0.0286816</td>\n",
       "<td>0.9592673</td>\n",
       "<td>-71.3141950</td>\n",
       "<td>59.8789956</td>\n",
       "<td>0.3933677</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.7000021</td>\n",
       "<td>0.0134175</td>\n",
       "<td>0.2000357</td>\n",
       "<td>1.3989560</td>\n",
       "<td>0.0173386</td>\n",
       "<td>0.0175104</td>\n",
       "<td>0.1212582</td>\n",
       "<td>0.1192282</td>\n",
       "<td>0.0200048</td>\n",
       "<td>0.9792721</td>\n",
       "<td>-79.9964333</td>\n",
       "<td>39.8955987</td>\n",
       "<td>0.3057738</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.7999875</td>\n",
       "<td>0.0082096</td>\n",
       "<td>0.1036546</td>\n",
       "<td>1.2370645</td>\n",
       "<td>0.0089845</td>\n",
       "<td>0.0106565</td>\n",
       "<td>0.1072259</td>\n",
       "<td>0.1056585</td>\n",
       "<td>0.0103639</td>\n",
       "<td>0.9896361</td>\n",
       "<td>-89.6345411</td>\n",
       "<td>23.7064454</td>\n",
       "<td>0.2076469</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8999937</td>\n",
       "<td>0.0047352</td>\n",
       "<td>0.0650718</td>\n",
       "<td>1.1068340</td>\n",
       "<td>0.0056403</td>\n",
       "<td>0.0063203</td>\n",
       "<td>0.0959378</td>\n",
       "<td>0.0946201</td>\n",
       "<td>0.0065076</td>\n",
       "<td>0.9961436</td>\n",
       "<td>-93.4928156</td>\n",
       "<td>10.6833984</td>\n",
       "<td>0.1052749</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0010466</td>\n",
       "<td>0.0385611</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0033424</td>\n",
       "<td>0.0033578</td>\n",
       "<td>0.0866777</td>\n",
       "<td>0.0854933</td>\n",
       "<td>0.0038564</td>\n",
       "<td>1.0</td>\n",
       "<td>-96.1438907</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-21.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-21 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-21 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-21 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-21 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-21 .h2o-table th,\n",
       "#h2o-table-21 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-21 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-21\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Scoring History: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>timestamp</th>\n",
       "<th>duration</th>\n",
       "<th>number_of_trees</th>\n",
       "<th>training_rmse</th>\n",
       "<th>training_logloss</th>\n",
       "<th>training_auc</th>\n",
       "<th>training_pr_auc</th>\n",
       "<th>training_lift</th>\n",
       "<th>training_classification_error</th>\n",
       "<th>validation_rmse</th>\n",
       "<th>validation_logloss</th>\n",
       "<th>validation_auc</th>\n",
       "<th>validation_pr_auc</th>\n",
       "<th>validation_lift</th>\n",
       "<th>validation_classification_error</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>2022-11-08 21:33:05</td>\n",
       "<td> 0.010 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>0.5</td>\n",
       "<td>0.6931472</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0857176</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9142824</td>\n",
       "<td>0.5</td>\n",
       "<td>0.6931472</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0866777</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9133223</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2022-11-08 21:33:09</td>\n",
       "<td> 4.543 sec</td>\n",
       "<td>5.0</td>\n",
       "<td>0.2734588</td>\n",
       "<td>0.2849356</td>\n",
       "<td>0.8141570</td>\n",
       "<td>0.3317111</td>\n",
       "<td>6.8920250</td>\n",
       "<td>0.1445256</td>\n",
       "<td>0.2751436</td>\n",
       "<td>0.2870134</td>\n",
       "<td>0.8161120</td>\n",
       "<td>0.3184008</td>\n",
       "<td>6.3345098</td>\n",
       "<td>0.1449433</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2022-11-08 21:33:13</td>\n",
       "<td> 8.264 sec</td>\n",
       "<td>10.0</td>\n",
       "<td>0.2582142</td>\n",
       "<td>0.2393936</td>\n",
       "<td>0.8308744</td>\n",
       "<td>0.3480517</td>\n",
       "<td>7.1331168</td>\n",
       "<td>0.1327211</td>\n",
       "<td>0.2604472</td>\n",
       "<td>0.2419950</td>\n",
       "<td>0.8320573</td>\n",
       "<td>0.3332827</td>\n",
       "<td>6.6476224</td>\n",
       "<td>0.1407859</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2022-11-08 21:33:17</td>\n",
       "<td>11.921 sec</td>\n",
       "<td>15.0</td>\n",
       "<td>0.2562013</td>\n",
       "<td>0.2297295</td>\n",
       "<td>0.8399505</td>\n",
       "<td>0.3551298</td>\n",
       "<td>7.1591691</td>\n",
       "<td>0.1312517</td>\n",
       "<td>0.2586867</td>\n",
       "<td>0.2327534</td>\n",
       "<td>0.8396360</td>\n",
       "<td>0.3391195</td>\n",
       "<td>6.6717080</td>\n",
       "<td>0.1472204</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2022-11-08 21:33:21</td>\n",
       "<td>15.720 sec</td>\n",
       "<td>20.0</td>\n",
       "<td>0.2553712</td>\n",
       "<td>0.2261867</td>\n",
       "<td>0.8435738</td>\n",
       "<td>0.3593158</td>\n",
       "<td>7.2393031</td>\n",
       "<td>0.1319663</td>\n",
       "<td>0.2580940</td>\n",
       "<td>0.2297035</td>\n",
       "<td>0.8418481</td>\n",
       "<td>0.3415727</td>\n",
       "<td>6.7680504</td>\n",
       "<td>0.1433764</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2022-11-08 21:33:24</td>\n",
       "<td>19.398 sec</td>\n",
       "<td>25.0</td>\n",
       "<td>0.2548886</td>\n",
       "<td>0.2244699</td>\n",
       "<td>0.8456934</td>\n",
       "<td>0.3623229</td>\n",
       "<td>7.3467455</td>\n",
       "<td>0.1333911</td>\n",
       "<td>0.2579201</td>\n",
       "<td>0.2286152</td>\n",
       "<td>0.8426154</td>\n",
       "<td>0.3426860</td>\n",
       "<td>6.7439648</td>\n",
       "<td>0.1455700</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2022-11-08 21:33:28</td>\n",
       "<td>23.092 sec</td>\n",
       "<td>30.0</td>\n",
       "<td>0.2544722</td>\n",
       "<td>0.2234008</td>\n",
       "<td>0.8471358</td>\n",
       "<td>0.3656960</td>\n",
       "<td>7.4215877</td>\n",
       "<td>0.1326944</td>\n",
       "<td>0.2576511</td>\n",
       "<td>0.2278649</td>\n",
       "<td>0.8435095</td>\n",
       "<td>0.3443444</td>\n",
       "<td>6.6957936</td>\n",
       "<td>0.1491424</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2022-11-08 21:33:32</td>\n",
       "<td>26.791 sec</td>\n",
       "<td>35.0</td>\n",
       "<td>0.2539642</td>\n",
       "<td>0.2223873</td>\n",
       "<td>0.8486776</td>\n",
       "<td>0.3707060</td>\n",
       "<td>7.4770070</td>\n",
       "<td>0.1323549</td>\n",
       "<td>0.2576747</td>\n",
       "<td>0.2277134</td>\n",
       "<td>0.8438228</td>\n",
       "<td>0.3429855</td>\n",
       "<td>6.6717080</td>\n",
       "<td>0.1490380</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2022-11-08 21:33:35</td>\n",
       "<td>30.557 sec</td>\n",
       "<td>40.0</td>\n",
       "<td>0.2536291</td>\n",
       "<td>0.2217000</td>\n",
       "<td>0.8498040</td>\n",
       "<td>0.3739772</td>\n",
       "<td>7.5134802</td>\n",
       "<td>0.1223370</td>\n",
       "<td>0.2575968</td>\n",
       "<td>0.2276046</td>\n",
       "<td>0.8437920</td>\n",
       "<td>0.3439568</td>\n",
       "<td>6.7198792</td>\n",
       "<td>0.1467608</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2022-11-08 21:33:39</td>\n",
       "<td>34.539 sec</td>\n",
       "<td>45.0</td>\n",
       "<td>0.2533234</td>\n",
       "<td>0.2211676</td>\n",
       "<td>0.8505724</td>\n",
       "<td>0.3772701</td>\n",
       "<td>7.5968475</td>\n",
       "<td>0.1217876</td>\n",
       "<td>0.2575816</td>\n",
       "<td>0.2275356</td>\n",
       "<td>0.8438487</td>\n",
       "<td>0.3437724</td>\n",
       "<td>6.7680504</td>\n",
       "<td>0.1471160</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2022-11-08 21:33:43</td>\n",
       "<td>38.468 sec</td>\n",
       "<td>50.0</td>\n",
       "<td>0.2531287</td>\n",
       "<td>0.2207618</td>\n",
       "<td>0.8512637</td>\n",
       "<td>0.3790079</td>\n",
       "<td>7.6333207</td>\n",
       "<td>0.1303093</td>\n",
       "<td>0.2576005</td>\n",
       "<td>0.2275350</td>\n",
       "<td>0.8437717</td>\n",
       "<td>0.3437669</td>\n",
       "<td>6.9607351</td>\n",
       "<td>0.1521090</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2022-11-08 21:33:48</td>\n",
       "<td>42.713 sec</td>\n",
       "<td>55.0</td>\n",
       "<td>0.2528881</td>\n",
       "<td>0.2203595</td>\n",
       "<td>0.8519084</td>\n",
       "<td>0.3814191</td>\n",
       "<td>7.6645835</td>\n",
       "<td>0.1215911</td>\n",
       "<td>0.2576274</td>\n",
       "<td>0.2276276</td>\n",
       "<td>0.8435791</td>\n",
       "<td>0.3434588</td>\n",
       "<td>6.8884783</td>\n",
       "<td>0.1472622</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-22.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-22 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-22 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-22 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-22 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-22 .h2o-table th,\n",
       "#h2o-table-22 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-22 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-22\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Variable Importances: </caption>\n",
       "    <thead><tr><th>variable</th>\n",
       "<th>relative_importance</th>\n",
       "<th>scaled_importance</th>\n",
       "<th>percentage</th></tr></thead>\n",
       "    <tbody><tr><td>DiffWalking.No</td>\n",
       "<td>4103.1484375</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0875864</td></tr>\n",
       "<tr><td>Diabetic.Yes</td>\n",
       "<td>3668.9157715</td>\n",
       "<td>0.8941709</td>\n",
       "<td>0.0783172</td></tr>\n",
       "<tr><td>AgeCategory.80 or older</td>\n",
       "<td>3489.6950684</td>\n",
       "<td>0.8504920</td>\n",
       "<td>0.0744916</td></tr>\n",
       "<tr><td>Stroke.No</td>\n",
       "<td>3385.1030273</td>\n",
       "<td>0.8250014</td>\n",
       "<td>0.0722589</td></tr>\n",
       "<tr><td>GenHealth.Very good</td>\n",
       "<td>2257.4892578</td>\n",
       "<td>0.5501846</td>\n",
       "<td>0.0481887</td></tr>\n",
       "<tr><td>GenHealth.Excellent</td>\n",
       "<td>2237.9616699</td>\n",
       "<td>0.5454255</td>\n",
       "<td>0.0477719</td></tr>\n",
       "<tr><td>Sex.Female</td>\n",
       "<td>1920.0090332</td>\n",
       "<td>0.4679356</td>\n",
       "<td>0.0409848</td></tr>\n",
       "<tr><td>AgeCategory.70-74</td>\n",
       "<td>1915.5727539</td>\n",
       "<td>0.4668544</td>\n",
       "<td>0.0408901</td></tr>\n",
       "<tr><td>AgeCategory.75-79</td>\n",
       "<td>1809.0966797</td>\n",
       "<td>0.4409045</td>\n",
       "<td>0.0386172</td></tr>\n",
       "<tr><td>PhysicalHealth</td>\n",
       "<td>1585.5604248</td>\n",
       "<td>0.3864253</td>\n",
       "<td>0.0338456</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>Smoking.Yes</td>\n",
       "<td>85.7803116</td>\n",
       "<td>0.0209060</td>\n",
       "<td>0.0018311</td></tr>\n",
       "<tr><td>Race.American Indian/Alaskan Native</td>\n",
       "<td>82.2688293</td>\n",
       "<td>0.0200502</td>\n",
       "<td>0.0017561</td></tr>\n",
       "<tr><td>AgeCategory.55-59</td>\n",
       "<td>80.6028976</td>\n",
       "<td>0.0196442</td>\n",
       "<td>0.0017206</td></tr>\n",
       "<tr><td>Race.Other</td>\n",
       "<td>79.4932251</td>\n",
       "<td>0.0193737</td>\n",
       "<td>0.0016969</td></tr>\n",
       "<tr><td>AlcoholDrinking.No</td>\n",
       "<td>60.6702423</td>\n",
       "<td>0.0147863</td>\n",
       "<td>0.0012951</td></tr>\n",
       "<tr><td>Race.Asian</td>\n",
       "<td>54.0739441</td>\n",
       "<td>0.0131786</td>\n",
       "<td>0.0011543</td></tr>\n",
       "<tr><td>PhysicalActivity.Yes</td>\n",
       "<td>46.0828400</td>\n",
       "<td>0.0112311</td>\n",
       "<td>0.0009837</td></tr>\n",
       "<tr><td>AlcoholDrinking.Yes</td>\n",
       "<td>39.2535095</td>\n",
       "<td>0.0095667</td>\n",
       "<td>0.0008379</td></tr>\n",
       "<tr><td>Diabetic.No, borderline diabetes</td>\n",
       "<td>21.5210133</td>\n",
       "<td>0.0052450</td>\n",
       "<td>0.0004594</td></tr>\n",
       "<tr><td>Diabetic.Yes (during pregnancy)</td>\n",
       "<td>13.7965717</td>\n",
       "<td>0.0033624</td>\n",
       "<td>0.0002945</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[50 rows x 4 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
      ],
      "text/plain": [
       "Model Details\n",
       "=============\n",
       "H2OXGBoostEstimator : XGBoost\n",
       "Model Key: XGBoost_3_AutoML_3_20221108_212840\n",
       "\n",
       "\n",
       "Model Summary: \n",
       "    number_of_trees\n",
       "--  -----------------\n",
       "    55\n",
       "\n",
       "ModelMetricsBinomial: xgboost\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.06395236788288416\n",
       "RMSE: 0.2528880540533383\n",
       "LogLoss: 0.22035946660347489\n",
       "Mean Per-Class Error: 0.29272633188266417\n",
       "AUC: 0.8519084415463216\n",
       "AUCPR: 0.3814190648417427\n",
       "Gini: 0.7038168830926432\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.21242088954735622\n",
       "       No      Yes    Error    Rate\n",
       "-----  ------  -----  -------  ------------------\n",
       "No     187064  17642  0.0862   (17642.0/204706.0)\n",
       "Yes    9582    9610   0.4993   (9582.0/19192.0)\n",
       "Total  196646  27252  0.1216   (27224.0/223898.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.212421     0.413832  199\n",
       "max f2                       0.101801     0.533884  278\n",
       "max f0point5                 0.324551     0.414841  138\n",
       "max accuracy                 0.48712      0.917806  74\n",
       "max precision                0.923032     1         0\n",
       "max recall                   0.00238551   1         398\n",
       "max specificity              0.923032     1         0\n",
       "max absolute_mcc             0.197742     0.356064  208\n",
       "max min_per_class_accuracy   0.101801     0.769591  278\n",
       "max mean_per_class_accuracy  0.0930588    0.772538  286\n",
       "max tns                      0.923032     204706    0\n",
       "max fns                      0.923032     19191     0\n",
       "max fps                      0.00189072   204706    399\n",
       "max tps                      0.00238551   19192     398\n",
       "max tnr                      0.923032     1         0\n",
       "max fnr                      0.923032     0.999948  0\n",
       "max fpr                      0.00189072   1         399\n",
       "max tpr                      0.00238551   1         398\n",
       "\n",
       "Gains/Lift Table: Avg response rate:  8.57 %, avg score:  8.58 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0100001                   0.545439           7.66458    7.66458            0.65699          0.636009    0.65699                     0.636009            0.0766465       0.0766465                  666.458   666.458            0.0728948\n",
       "2        0.0200002                   0.463388           5.94513    6.80486            0.509603         0.500047    0.583296                    0.568028            0.0594519       0.136098                   494.513   580.486            0.126983\n",
       "3        0.0300003                   0.411204           5.15314    6.25429            0.441715         0.435676    0.536102                    0.523911            0.0515319       0.18763                    415.314   525.429            0.172408\n",
       "4        0.0400048                   0.370372           4.76023    5.88065            0.408036         0.390164    0.504075                    0.490463            0.047624        0.235254                   376.023   488.065            0.213555\n",
       "5        0.0500004                   0.339746           3.97214    5.49912            0.340483         0.354173    0.471371                    0.463217            0.039704        0.274958                   297.214   449.912            0.246049\n",
       "6        0.100001                    0.23984            3.37846    4.43879            0.289594         0.283786    0.380482                    0.373501            0.168925        0.443883                   237.846   343.879            0.376122\n",
       "7        0.150024                    0.180509           2.41657    3.76452            0.207143         0.208196    0.322685                    0.318383            0.120884        0.564767                   141.657   276.452            0.453627\n",
       "8        0.200002                    0.142542           1.9329     3.30682            0.165684         0.161408    0.283452                    0.279157            0.0966028       0.661369                   93.2901   230.682            0.504623\n",
       "9        0.300003                    0.0903046          1.3667     2.66011            0.117151         0.114098    0.228018                    0.224137            0.136672        0.798041                   36.6703   166.011            0.544731\n",
       "10       0.399999                    0.0574882          0.834753   2.20379            0.071553         0.0726463   0.188903                    0.186266            0.0834723       0.881513                   -16.5247  120.379            0.526658\n",
       "11       0.500116                    0.0361844          0.531371   1.86899            0.0455478        0.0462545   0.160205                    0.158237            0.0531992       0.934712                   -46.8629  86.8991            0.475341\n",
       "12       0.600001                    0.0219814          0.315078   1.6103             0.0270077        0.0289124   0.138031                    0.136708            0.0314714       0.966184                   -68.4922  61.0304            0.400514\n",
       "13       0.699997                    0.0134207          0.169869   1.40453            0.0145607        0.0174599   0.120393                    0.119673            0.0169862       0.98317                    -83.0131  40.4534            0.309721\n",
       "14       0.799998                    0.00817649         0.0932672  1.24062            0.00799464       0.0106338   0.106343                    0.106043            0.0093268       0.992497                   -90.6733  24.0624            0.210546\n",
       "15       0.899999                    0.00472616         0.0510625  1.10845            0.00437695       0.00628974  0.0950136                   0.0949592           0.00510629      0.997603                   -94.8938  10.8449            0.106755\n",
       "16       1                           0.000944155        0.0239681  1                  0.00205449       0.00336505  0.0857176                   0.0857997           0.00239683      1                          -97.6032  0                  0\n",
       "\n",
       "ModelMetricsBinomial: xgboost\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.06637189113184688\n",
       "RMSE: 0.2576274269790522\n",
       "LogLoss: 0.22762759473977812\n",
       "Mean Per-Class Error: 0.27618870238825843\n",
       "AUC: 0.8435790782332893\n",
       "AUCPR: 0.3434588136032144\n",
       "Gini: 0.6871581564665785\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.17301240337045887\n",
       "       No     Yes    Error    Rate\n",
       "-----  -----  -----  -------  ----------------\n",
       "No     38462  5256   0.1202   (5256.0/43718.0)\n",
       "Yes    1793   2356   0.4322   (1793.0/4149.0)\n",
       "Total  40255  7612   0.1473   (7049.0/47867.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.173012     0.400646  221\n",
       "max f2                       0.104176     0.532275  275\n",
       "max f0point5                 0.284422     0.378902  154\n",
       "max accuracy                 0.540078     0.915286  57\n",
       "max precision                0.823558     0.833333  3\n",
       "max recall                   0.0019703    1         399\n",
       "max specificity              0.871952     0.999977  0\n",
       "max absolute_mcc             0.14923      0.347445  238\n",
       "max min_per_class_accuracy   0.0994812    0.766023  279\n",
       "max mean_per_class_accuracy  0.0811358    0.770001  295\n",
       "max tns                      0.871952     43717     0\n",
       "max fns                      0.871952     4149      0\n",
       "max fps                      0.0019703    43718     399\n",
       "max tps                      0.0019703    4149      399\n",
       "max tnr                      0.871952     0.999977  0\n",
       "max fnr                      0.871952     1         0\n",
       "max fpr                      0.0019703    1         399\n",
       "max tpr                      0.0019703    1         399\n",
       "\n",
       "Gains/Lift Table: Avg response rate:  8.67 %, avg score:  8.55 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0100069                   0.546161           6.88848    6.88848            0.597077         0.634376    0.597077                    0.634376            0.0689323       0.0689323                  588.848   588.848            0.0645176\n",
       "2        0.0200138                   0.463208           5.29883    6.09365            0.45929          0.501825    0.528184                    0.568101            0.0530248       0.121957                   429.883   509.365            0.111618\n",
       "3        0.0299998                   0.410729           4.48929    5.55961            0.389121         0.436378    0.481894                    0.524254            0.0448301       0.166787                   348.929   455.961            0.149769\n",
       "4        0.0400694                   0.366421           4.40416    5.26924            0.381743         0.38709     0.456726                    0.489784            0.044348        0.211135                   340.416   426.924            0.187301\n",
       "5        0.0500136                   0.337093           3.73256    4.9637             0.323529         0.350969    0.430242                    0.462184            0.0371174       0.248253                   273.256   396.37             0.217053\n",
       "6        0.100006                    0.238648           3.26391    4.11399            0.282908         0.281381    0.356591                    0.371801            0.163172        0.411424                   226.391   311.399            0.340973\n",
       "7        0.149999                    0.178328           2.63717    3.62178            0.228583         0.206889    0.313928                    0.316838            0.131839        0.543263                   163.717   262.178            0.430587\n",
       "8        0.200013                    0.141837           2.12042    3.24636            0.183793         0.160363    0.281387                    0.277711            0.10605         0.649313                   112.042   224.636            0.491941\n",
       "9        0.299998                    0.0900938          1.41501    2.63599            0.122649         0.113931    0.228482                    0.223125            0.14148         0.790793                   41.5006   163.599            0.537373\n",
       "10       0.400004                    0.0572581          0.872445   2.19508            0.0756215        0.0722966   0.190265                    0.185416            0.0872499       0.878043                   -12.7555  119.508            0.523406\n",
       "11       0.50001                     0.0363731          0.525395   1.86113            0.04554          0.0464366   0.161319                    0.157619            0.0525428       0.930586                   -47.4605  86.1132            0.471438\n",
       "12       0.599996                    0.0220013          0.286858   1.59879            0.0248642        0.0289804   0.138579                    0.136182            0.0286816       0.959267                   -71.3142  59.879             0.393368\n",
       "13       0.700002                    0.0134175          0.200036   1.39896            0.0173386        0.0175104   0.121258                    0.119228            0.0200048       0.979272                   -79.9964  39.8956            0.305774\n",
       "14       0.799987                    0.00820958         0.103655   1.23706            0.00898454       0.0106565   0.107226                    0.105658            0.0103639       0.989636                   -89.6345  23.7064            0.207647\n",
       "15       0.899994                    0.00473523         0.0650718  1.10683            0.00564028       0.00632031  0.0959378                   0.0946201           0.00650759      0.996144                   -93.4928  10.6834            0.105275\n",
       "16       1                           0.00104658         0.0385611  1                  0.00334239       0.00335785  0.0866777                   0.0854933           0.00385635      1                          -96.1439  0                  0\n",
       "\n",
       "Scoring History: \n",
       "    timestamp            duration    number_of_trees    training_rmse    training_logloss    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_auc    validation_pr_auc    validation_lift    validation_classification_error\n",
       "--  -------------------  ----------  -----------------  ---------------  ------------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ----------------  -------------------  -----------------  ---------------------------------\n",
       "    2022-11-08 21:33:05  0.010 sec   0                  0.5              0.693147            0.5             0.0857176          1                0.914282                         0.5                0.693147              0.5               0.0866777            1                  0.913322\n",
       "    2022-11-08 21:33:09  4.543 sec   5                  0.273459         0.284936            0.814157        0.331711           6.89202          0.144526                         0.275144           0.287013              0.816112          0.318401             6.33451            0.144943\n",
       "    2022-11-08 21:33:13  8.264 sec   10                 0.258214         0.239394            0.830874        0.348052           7.13312          0.132721                         0.260447           0.241995              0.832057          0.333283             6.64762            0.140786\n",
       "    2022-11-08 21:33:17  11.921 sec  15                 0.256201         0.22973             0.839951        0.35513            7.15917          0.131252                         0.258687           0.232753              0.839636          0.33912              6.67171            0.14722\n",
       "    2022-11-08 21:33:21  15.720 sec  20                 0.255371         0.226187            0.843574        0.359316           7.2393           0.131966                         0.258094           0.229703              0.841848          0.341573             6.76805            0.143376\n",
       "    2022-11-08 21:33:24  19.398 sec  25                 0.254889         0.22447             0.845693        0.362323           7.34675          0.133391                         0.25792            0.228615              0.842615          0.342686             6.74396            0.14557\n",
       "    2022-11-08 21:33:28  23.092 sec  30                 0.254472         0.223401            0.847136        0.365696           7.42159          0.132694                         0.257651           0.227865              0.843509          0.344344             6.69579            0.149142\n",
       "    2022-11-08 21:33:32  26.791 sec  35                 0.253964         0.222387            0.848678        0.370706           7.47701          0.132355                         0.257675           0.227713              0.843823          0.342986             6.67171            0.149038\n",
       "    2022-11-08 21:33:35  30.557 sec  40                 0.253629         0.2217              0.849804        0.373977           7.51348          0.122337                         0.257597           0.227605              0.843792          0.343957             6.71988            0.146761\n",
       "    2022-11-08 21:33:39  34.539 sec  45                 0.253323         0.221168            0.850572        0.37727            7.59685          0.121788                         0.257582           0.227536              0.843849          0.343772             6.76805            0.147116\n",
       "    2022-11-08 21:33:43  38.468 sec  50                 0.253129         0.220762            0.851264        0.379008           7.63332          0.130309                         0.257601           0.227535              0.843772          0.343767             6.96074            0.152109\n",
       "    2022-11-08 21:33:48  42.713 sec  55                 0.252888         0.220359            0.851908        0.381419           7.66458          0.121591                         0.257627           0.227628              0.843579          0.343459             6.88848            0.147262\n",
       "\n",
       "Variable Importances: \n",
       "variable                             relative_importance    scaled_importance      percentage\n",
       "-----------------------------------  ---------------------  ---------------------  ----------------------\n",
       "DiffWalking.No                       4103.1484375           1.0                    0.0875864232996671\n",
       "Diabetic.Yes                         3668.915771484375      0.8941708610765742     0.07831722754048064\n",
       "AgeCategory.80 or older              3489.695068359375      0.8504920359365807     0.07449155547253702\n",
       "Stroke.No                            3385.10302734375       0.8250013566182981     0.07225891804356986\n",
       "GenHealth.Very good                  2257.4892578125        0.5501846428904633     0.048188705025180294\n",
       "GenHealth.Excellent                  2237.961669921875      0.5454254711987555     0.047771866198834584\n",
       "Sex.Female                           1920.009033203125      0.46793555301473905    0.04098480142331275\n",
       "AgeCategory.70-74                    1915.57275390625       0.4668543639316607     0.040890103938615266\n",
       "AgeCategory.75-79                    1809.0966796875        0.4409045169201242     0.03861724965370123\n",
       "PhysicalHealth                       1585.5604248046875     0.38642531435464       0.03384561115677242\n",
       "---                                  ---                    ---                    ---\n",
       "Smoking.Yes                          85.78031158447266      0.020905973276642554   0.001831079424899543\n",
       "Race.American Indian/Alaskan Native  82.26882934570312      0.020050171374211494   0.0017561227972125559\n",
       "AgeCategory.55-59                    80.60289764404297      0.01964415835103284    0.0017205615686992524\n",
       "Race.Other                           79.49322509765625      0.019373714187656963   0.0016968743317268887\n",
       "AlcoholDrinking.No                   60.67024230957031      0.01478626553089948    0.0012950761118106387\n",
       "Race.Asian                           54.073944091796875     0.013178646816088255   0.001154270538550716\n",
       "PhysicalActivity.Yes                 46.08283996582031      0.011231092578726702   0.0009836912287181066\n",
       "AlcoholDrinking.Yes                  39.253509521484375     0.009566680347884533   0.000837911314522421\n",
       "Diabetic.No, borderline diabetes     21.521013259887695     0.0052449999281527805  0.00045939078391391295\n",
       "Diabetic.Yes (during pregnancy)      13.796571731567383     0.0033624354423729967  0.00029450369397348463\n",
       "[50 rows x 4 columns]\n",
       "\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2o.get_model([mid for mid in model_ids if \"XGBoost\" in mid][0])\n",
    "#we are using xgboost model as well to predict, while it's still not in the top of the aml leader board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a2bbcc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = h2o.get_model([mid for mid in model_ids if \"XGBoost\" in mid][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e83899e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_id': {'default': None,\n",
       "  'actual': {'__meta': {'schema_version': 3,\n",
       "    'schema_name': 'ModelKeyV3',\n",
       "    'schema_type': 'Key<Model>'},\n",
       "   'name': 'XGBoost_3_AutoML_3_20221108_212840',\n",
       "   'type': 'Key<Model>',\n",
       "   'URL': '/3/Models/XGBoost_3_AutoML_3_20221108_212840'},\n",
       "  'input': None},\n",
       " 'training_frame': {'default': None,\n",
       "  'actual': {'__meta': {'schema_version': 3,\n",
       "    'schema_name': 'FrameKeyV3',\n",
       "    'schema_type': 'Key<Frame>'},\n",
       "   'name': 'AutoML_3_20221108_212840_training_py_10_sid_b108',\n",
       "   'type': 'Key<Frame>',\n",
       "   'URL': '/3/Frames/AutoML_3_20221108_212840_training_py_10_sid_b108'},\n",
       "  'input': {'__meta': {'schema_version': 3,\n",
       "    'schema_name': 'FrameKeyV3',\n",
       "    'schema_type': 'Key<Frame>'},\n",
       "   'name': 'AutoML_3_20221108_212840_training_py_10_sid_b108',\n",
       "   'type': 'Key<Frame>',\n",
       "   'URL': '/3/Frames/AutoML_3_20221108_212840_training_py_10_sid_b108'}},\n",
       " 'validation_frame': {'default': None,\n",
       "  'actual': {'__meta': {'schema_version': 3,\n",
       "    'schema_name': 'FrameKeyV3',\n",
       "    'schema_type': 'Key<Frame>'},\n",
       "   'name': 'py_12_sid_b108',\n",
       "   'type': 'Key<Frame>',\n",
       "   'URL': '/3/Frames/py_12_sid_b108'},\n",
       "  'input': {'__meta': {'schema_version': 3,\n",
       "    'schema_name': 'FrameKeyV3',\n",
       "    'schema_type': 'Key<Frame>'},\n",
       "   'name': 'py_12_sid_b108',\n",
       "   'type': 'Key<Frame>',\n",
       "   'URL': '/3/Frames/py_12_sid_b108'}},\n",
       " 'nfolds': {'default': 0, 'actual': 0, 'input': 0},\n",
       " 'keep_cross_validation_models': {'default': True,\n",
       "  'actual': False,\n",
       "  'input': False},\n",
       " 'keep_cross_validation_predictions': {'default': False,\n",
       "  'actual': True,\n",
       "  'input': True},\n",
       " 'keep_cross_validation_fold_assignment': {'default': False,\n",
       "  'actual': False,\n",
       "  'input': False},\n",
       " 'score_each_iteration': {'default': False, 'actual': False, 'input': False},\n",
       " 'fold_assignment': {'default': 'AUTO', 'actual': None, 'input': 'AUTO'},\n",
       " 'fold_column': {'default': None, 'actual': None, 'input': None},\n",
       " 'response_column': {'default': None,\n",
       "  'actual': {'__meta': {'schema_version': 3,\n",
       "    'schema_name': 'ColSpecifierV3',\n",
       "    'schema_type': 'VecSpecifier'},\n",
       "   'column_name': 'HeartDisease',\n",
       "   'is_member_of_frames': None},\n",
       "  'input': {'__meta': {'schema_version': 3,\n",
       "    'schema_name': 'ColSpecifierV3',\n",
       "    'schema_type': 'VecSpecifier'},\n",
       "   'column_name': 'HeartDisease',\n",
       "   'is_member_of_frames': None}},\n",
       " 'ignored_columns': {'default': None, 'actual': [], 'input': []},\n",
       " 'ignore_const_cols': {'default': True, 'actual': True, 'input': True},\n",
       " 'offset_column': {'default': None, 'actual': None, 'input': None},\n",
       " 'weights_column': {'default': None, 'actual': None, 'input': None},\n",
       " 'stopping_rounds': {'default': 0, 'actual': 3, 'input': 3},\n",
       " 'stopping_metric': {'default': 'AUTO',\n",
       "  'actual': 'logloss',\n",
       "  'input': 'logloss'},\n",
       " 'stopping_tolerance': {'default': 0.001,\n",
       "  'actual': 0.0021133668599572068,\n",
       "  'input': 0.0021133668599572068},\n",
       " 'max_runtime_secs': {'default': 0.0, 'actual': 0.0, 'input': 0.0},\n",
       " 'seed': {'default': -1, 'actual': 18, 'input': 18},\n",
       " 'distribution': {'default': 'AUTO',\n",
       "  'actual': 'bernoulli',\n",
       "  'input': 'bernoulli'},\n",
       " 'tweedie_power': {'default': 1.5, 'actual': 1.5, 'input': 1.5},\n",
       " 'categorical_encoding': {'default': 'AUTO',\n",
       "  'actual': 'OneHotInternal',\n",
       "  'input': 'AUTO'},\n",
       " 'quiet_mode': {'default': True, 'actual': True, 'input': True},\n",
       " 'checkpoint': {'default': None, 'actual': None, 'input': None},\n",
       " 'export_checkpoints_dir': {'default': None, 'actual': None, 'input': None},\n",
       " 'ntrees': {'default': 50, 'actual': 10000, 'input': 10000},\n",
       " 'max_depth': {'default': 6, 'actual': 5, 'input': 5},\n",
       " 'min_rows': {'default': 1.0, 'actual': 3.0, 'input': 3.0},\n",
       " 'min_child_weight': {'default': 1.0, 'actual': 3.0, 'input': 1.0},\n",
       " 'learn_rate': {'default': 0.3, 'actual': 0.3, 'input': 0.3},\n",
       " 'eta': {'default': 0.3, 'actual': 0.3, 'input': 0.3},\n",
       " 'sample_rate': {'default': 1.0, 'actual': 0.8, 'input': 0.8},\n",
       " 'subsample': {'default': 1.0, 'actual': 0.8, 'input': 1.0},\n",
       " 'col_sample_rate': {'default': 1.0, 'actual': 0.8, 'input': 0.8},\n",
       " 'colsample_bylevel': {'default': 1.0, 'actual': 0.8, 'input': 1.0},\n",
       " 'col_sample_rate_per_tree': {'default': 1.0, 'actual': 0.8, 'input': 0.8},\n",
       " 'colsample_bytree': {'default': 1.0, 'actual': 0.8, 'input': 1.0},\n",
       " 'colsample_bynode': {'default': 1.0, 'actual': 1.0, 'input': 1.0},\n",
       " 'max_abs_leafnode_pred': {'default': 0.0, 'actual': 0.0, 'input': 0.0},\n",
       " 'max_delta_step': {'default': 0.0, 'actual': 0.0, 'input': 0.0},\n",
       " 'monotone_constraints': {'default': None, 'actual': None, 'input': None},\n",
       " 'interaction_constraints': {'default': None, 'actual': None, 'input': None},\n",
       " 'score_tree_interval': {'default': 0, 'actual': 5, 'input': 5},\n",
       " 'min_split_improvement': {'default': 0.0, 'actual': 0.0, 'input': 0.0},\n",
       " 'gamma': {'default': 0.0, 'actual': 0.0, 'input': 0.0},\n",
       " 'nthread': {'default': -1, 'actual': -1, 'input': -1},\n",
       " 'save_matrix_directory': {'default': None, 'actual': None, 'input': None},\n",
       " 'build_tree_one_node': {'default': False, 'actual': False, 'input': False},\n",
       " 'calibrate_model': {'default': False, 'actual': False, 'input': False},\n",
       " 'calibration_frame': {'default': None, 'actual': None, 'input': None},\n",
       " 'calibration_method': {'default': 'AUTO',\n",
       "  'actual': 'PlattScaling',\n",
       "  'input': 'AUTO'},\n",
       " 'max_bins': {'default': 256, 'actual': 256, 'input': 256},\n",
       " 'max_leaves': {'default': 0, 'actual': 0, 'input': 0},\n",
       " 'sample_type': {'default': 'uniform',\n",
       "  'actual': 'uniform',\n",
       "  'input': 'uniform'},\n",
       " 'normalize_type': {'default': 'tree', 'actual': 'tree', 'input': 'tree'},\n",
       " 'rate_drop': {'default': 0.0, 'actual': 0.0, 'input': 0.0},\n",
       " 'one_drop': {'default': False, 'actual': False, 'input': False},\n",
       " 'skip_drop': {'default': 0.0, 'actual': 0.0, 'input': 0.0},\n",
       " 'tree_method': {'default': 'auto', 'actual': 'exact', 'input': 'auto'},\n",
       " 'grow_policy': {'default': 'depthwise',\n",
       "  'actual': 'depthwise',\n",
       "  'input': 'depthwise'},\n",
       " 'booster': {'default': 'gbtree', 'actual': 'gbtree', 'input': 'gbtree'},\n",
       " 'reg_lambda': {'default': 1.0, 'actual': 1.0, 'input': 1.0},\n",
       " 'reg_alpha': {'default': 0.0, 'actual': 0.0, 'input': 0.0},\n",
       " 'dmatrix_type': {'default': 'auto', 'actual': 'dense', 'input': 'auto'},\n",
       " 'backend': {'default': 'auto', 'actual': 'cpu', 'input': 'auto'},\n",
       " 'gpu_id': {'default': None, 'actual': None, 'input': None},\n",
       " 'gainslift_bins': {'default': -1, 'actual': -1, 'input': -1},\n",
       " 'auc_type': {'default': 'AUTO', 'actual': 'AUTO', 'input': 'AUTO'},\n",
       " 'scale_pos_weight': {'default': 1.0, 'actual': 1.0, 'input': 1.0}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb3be117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'silent': True,\n",
       "  'eta': 0.3,\n",
       "  'colsample_bylevel': 0.8,\n",
       "  'objective': 'binary:logistic',\n",
       "  'min_child_weight': 3.0,\n",
       "  'nthread': 4,\n",
       "  'seed': 18,\n",
       "  'max_depth': 5,\n",
       "  'colsample_bytree': 0.8,\n",
       "  'lambda': 1.0,\n",
       "  'gamma': 0.0,\n",
       "  'alpha': 0.0,\n",
       "  'booster': 'gbtree',\n",
       "  'grow_policy': 'depthwise',\n",
       "  'nround': 10000,\n",
       "  'subsample': 0.8,\n",
       "  'max_delta_step': 0.0,\n",
       "  'tree_method': 'exact'},\n",
       " 10000)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.convert_H2OXGBoostParams_2_XGBoostParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e6e0c5a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
       "=============\n",
       "H2OXGBoostEstimator : XGBoost\n",
       "Model Key: XGBoost_3_AutoML_3_20221108_212840\n",
       "</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-23.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-23 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-23 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-23 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-23 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-23 .h2o-table th,\n",
       "#h2o-table-23 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-23 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-23\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Model Summary: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>number_of_trees</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>55.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: xgboost\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.06395236788288416\n",
       "RMSE: 0.2528880540533383\n",
       "LogLoss: 0.22035946660347489\n",
       "Mean Per-Class Error: 0.29272633188266417\n",
       "AUC: 0.8519084415463216\n",
       "AUCPR: 0.3814190648417427\n",
       "Gini: 0.7038168830926432</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-24.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-24 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-24 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-24 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-24 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-24 .h2o-table th,\n",
       "#h2o-table-24 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-24 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-24\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.21242088954735622</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>No</th>\n",
       "<th>Yes</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>No</td>\n",
       "<td>187064.0</td>\n",
       "<td>17642.0</td>\n",
       "<td>0.0862</td>\n",
       "<td> (17642.0/204706.0)</td></tr>\n",
       "<tr><td>Yes</td>\n",
       "<td>9582.0</td>\n",
       "<td>9610.0</td>\n",
       "<td>0.4993</td>\n",
       "<td> (9582.0/19192.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>196646.0</td>\n",
       "<td>27252.0</td>\n",
       "<td>0.1216</td>\n",
       "<td> (27224.0/223898.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-25.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-25 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-25 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-25 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-25 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-25 .h2o-table th,\n",
       "#h2o-table-25 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-25 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-25\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.2124209</td>\n",
       "<td>0.4138317</td>\n",
       "<td>199.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1018012</td>\n",
       "<td>0.5338837</td>\n",
       "<td>278.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.3245512</td>\n",
       "<td>0.4148415</td>\n",
       "<td>138.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4871197</td>\n",
       "<td>0.9178063</td>\n",
       "<td>74.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9230320</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0023855</td>\n",
       "<td>1.0</td>\n",
       "<td>398.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9230320</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.1977421</td>\n",
       "<td>0.3560641</td>\n",
       "<td>208.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.1018012</td>\n",
       "<td>0.7695915</td>\n",
       "<td>278.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.0930588</td>\n",
       "<td>0.7725375</td>\n",
       "<td>286.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9230320</td>\n",
       "<td>204706.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9230320</td>\n",
       "<td>19191.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0018907</td>\n",
       "<td>204706.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0023855</td>\n",
       "<td>19192.0</td>\n",
       "<td>398.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9230320</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9230320</td>\n",
       "<td>0.9999479</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0018907</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0023855</td>\n",
       "<td>1.0</td>\n",
       "<td>398.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-26.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-26 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-26 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-26 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-26 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-26 .h2o-table th,\n",
       "#h2o-table-26 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-26 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-26\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate:  8.57 %, avg score:  8.58 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0100001</td>\n",
       "<td>0.5454391</td>\n",
       "<td>7.6645835</td>\n",
       "<td>7.6645835</td>\n",
       "<td>0.6569897</td>\n",
       "<td>0.6360089</td>\n",
       "<td>0.6569897</td>\n",
       "<td>0.6360089</td>\n",
       "<td>0.0766465</td>\n",
       "<td>0.0766465</td>\n",
       "<td>666.4583473</td>\n",
       "<td>666.4583473</td>\n",
       "<td>0.0728948</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0200002</td>\n",
       "<td>0.4633881</td>\n",
       "<td>5.9451324</td>\n",
       "<td>6.8048579</td>\n",
       "<td>0.5096025</td>\n",
       "<td>0.5000470</td>\n",
       "<td>0.5832961</td>\n",
       "<td>0.5680279</td>\n",
       "<td>0.0594519</td>\n",
       "<td>0.1360984</td>\n",
       "<td>494.5132388</td>\n",
       "<td>580.4857931</td>\n",
       "<td>0.1269829</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0300003</td>\n",
       "<td>0.4112042</td>\n",
       "<td>5.1531428</td>\n",
       "<td>6.2542862</td>\n",
       "<td>0.4417151</td>\n",
       "<td>0.4356757</td>\n",
       "<td>0.5361024</td>\n",
       "<td>0.5239105</td>\n",
       "<td>0.0515319</td>\n",
       "<td>0.1876303</td>\n",
       "<td>415.3142798</td>\n",
       "<td>525.4286220</td>\n",
       "<td>0.1724084</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0400048</td>\n",
       "<td>0.3703723</td>\n",
       "<td>4.7602324</td>\n",
       "<td>5.8806477</td>\n",
       "<td>0.4080357</td>\n",
       "<td>0.3901641</td>\n",
       "<td>0.5040750</td>\n",
       "<td>0.4904627</td>\n",
       "<td>0.0476240</td>\n",
       "<td>0.2352543</td>\n",
       "<td>376.0232407</td>\n",
       "<td>488.0647664</td>\n",
       "<td>0.2135549</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0500004</td>\n",
       "<td>0.3397464</td>\n",
       "<td>3.9721429</td>\n",
       "<td>5.4991172</td>\n",
       "<td>0.3404826</td>\n",
       "<td>0.3541731</td>\n",
       "<td>0.4713711</td>\n",
       "<td>0.4632170</td>\n",
       "<td>0.0397040</td>\n",
       "<td>0.2749583</td>\n",
       "<td>297.2142939</td>\n",
       "<td>449.9117198</td>\n",
       "<td>0.2460486</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1000009</td>\n",
       "<td>0.2398401</td>\n",
       "<td>3.3784609</td>\n",
       "<td>4.4387890</td>\n",
       "<td>0.2895936</td>\n",
       "<td>0.2837860</td>\n",
       "<td>0.3804824</td>\n",
       "<td>0.3735015</td>\n",
       "<td>0.1689246</td>\n",
       "<td>0.4438829</td>\n",
       "<td>237.8460859</td>\n",
       "<td>343.8789029</td>\n",
       "<td>0.3761223</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1500237</td>\n",
       "<td>0.1805089</td>\n",
       "<td>2.4165731</td>\n",
       "<td>3.7645164</td>\n",
       "<td>0.2071429</td>\n",
       "<td>0.2081964</td>\n",
       "<td>0.3226853</td>\n",
       "<td>0.3183834</td>\n",
       "<td>0.1208837</td>\n",
       "<td>0.5647666</td>\n",
       "<td>141.6573126</td>\n",
       "<td>276.4516385</td>\n",
       "<td>0.4536267</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2000018</td>\n",
       "<td>0.1425423</td>\n",
       "<td>1.9329011</td>\n",
       "<td>3.3068171</td>\n",
       "<td>0.1656836</td>\n",
       "<td>0.1614080</td>\n",
       "<td>0.2834524</td>\n",
       "<td>0.2791571</td>\n",
       "<td>0.0966028</td>\n",
       "<td>0.6613693</td>\n",
       "<td>93.2901052</td>\n",
       "<td>230.6817064</td>\n",
       "<td>0.5046226</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3000027</td>\n",
       "<td>0.0903046</td>\n",
       "<td>1.3667031</td>\n",
       "<td>2.6601124</td>\n",
       "<td>0.1171505</td>\n",
       "<td>0.1140976</td>\n",
       "<td>0.2280185</td>\n",
       "<td>0.2241373</td>\n",
       "<td>0.1366715</td>\n",
       "<td>0.7980409</td>\n",
       "<td>36.6703090</td>\n",
       "<td>166.0112406</td>\n",
       "<td>0.5447312</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.3999991</td>\n",
       "<td>0.0574882</td>\n",
       "<td>0.8347526</td>\n",
       "<td>2.2037877</td>\n",
       "<td>0.0715530</td>\n",
       "<td>0.0726463</td>\n",
       "<td>0.1889034</td>\n",
       "<td>0.1862658</td>\n",
       "<td>0.0834723</td>\n",
       "<td>0.8815131</td>\n",
       "<td>-16.5247373</td>\n",
       "<td>120.3787748</td>\n",
       "<td>0.5266579</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5001161</td>\n",
       "<td>0.0361844</td>\n",
       "<td>0.5313707</td>\n",
       "<td>1.8689907</td>\n",
       "<td>0.0455478</td>\n",
       "<td>0.0462545</td>\n",
       "<td>0.1602054</td>\n",
       "<td>0.1582373</td>\n",
       "<td>0.0531992</td>\n",
       "<td>0.9347124</td>\n",
       "<td>-46.8629300</td>\n",
       "<td>86.8990690</td>\n",
       "<td>0.4753414</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6000009</td>\n",
       "<td>0.0219814</td>\n",
       "<td>0.3150775</td>\n",
       "<td>1.6103040</td>\n",
       "<td>0.0270077</td>\n",
       "<td>0.0289124</td>\n",
       "<td>0.1380314</td>\n",
       "<td>0.1367080</td>\n",
       "<td>0.0314714</td>\n",
       "<td>0.9661838</td>\n",
       "<td>-68.4922469</td>\n",
       "<td>61.0303980</td>\n",
       "<td>0.4005140</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.6999973</td>\n",
       "<td>0.0134207</td>\n",
       "<td>0.1698685</td>\n",
       "<td>1.4045340</td>\n",
       "<td>0.0145607</td>\n",
       "<td>0.0174599</td>\n",
       "<td>0.1203933</td>\n",
       "<td>0.1196731</td>\n",
       "<td>0.0169862</td>\n",
       "<td>0.9831701</td>\n",
       "<td>-83.0131488</td>\n",
       "<td>40.4534050</td>\n",
       "<td>0.3097213</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.7999982</td>\n",
       "<td>0.0081765</td>\n",
       "<td>0.0932672</td>\n",
       "<td>1.2406239</td>\n",
       "<td>0.0079946</td>\n",
       "<td>0.0106338</td>\n",
       "<td>0.1063433</td>\n",
       "<td>0.1060430</td>\n",
       "<td>0.0093268</td>\n",
       "<td>0.9924969</td>\n",
       "<td>-90.6732805</td>\n",
       "<td>24.0623863</td>\n",
       "<td>0.2105462</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8999991</td>\n",
       "<td>0.0047262</td>\n",
       "<td>0.0510625</td>\n",
       "<td>1.1084491</td>\n",
       "<td>0.0043770</td>\n",
       "<td>0.0062897</td>\n",
       "<td>0.0950136</td>\n",
       "<td>0.0949592</td>\n",
       "<td>0.0051063</td>\n",
       "<td>0.9976032</td>\n",
       "<td>-94.8937513</td>\n",
       "<td>10.8449065</td>\n",
       "<td>0.1067548</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0009442</td>\n",
       "<td>0.0239681</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0020545</td>\n",
       "<td>0.0033650</td>\n",
       "<td>0.0857176</td>\n",
       "<td>0.0857997</td>\n",
       "<td>0.0023968</td>\n",
       "<td>1.0</td>\n",
       "<td>-97.6031894</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: xgboost\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.06637189113184688\n",
       "RMSE: 0.2576274269790522\n",
       "LogLoss: 0.22762759473977812\n",
       "Mean Per-Class Error: 0.27618870238825843\n",
       "AUC: 0.8435790782332893\n",
       "AUCPR: 0.3434588136032144\n",
       "Gini: 0.6871581564665785</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-27.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-27 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-27 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-27 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-27 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-27 .h2o-table th,\n",
       "#h2o-table-27 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-27 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-27\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.17301240337045887</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>No</th>\n",
       "<th>Yes</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>No</td>\n",
       "<td>38462.0</td>\n",
       "<td>5256.0</td>\n",
       "<td>0.1202</td>\n",
       "<td> (5256.0/43718.0)</td></tr>\n",
       "<tr><td>Yes</td>\n",
       "<td>1793.0</td>\n",
       "<td>2356.0</td>\n",
       "<td>0.4322</td>\n",
       "<td> (1793.0/4149.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>40255.0</td>\n",
       "<td>7612.0</td>\n",
       "<td>0.1473</td>\n",
       "<td> (7049.0/47867.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-28.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-28 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-28 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-28 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-28 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-28 .h2o-table th,\n",
       "#h2o-table-28 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-28 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-28\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.1730124</td>\n",
       "<td>0.4006462</td>\n",
       "<td>221.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1041757</td>\n",
       "<td>0.5322750</td>\n",
       "<td>275.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.2844224</td>\n",
       "<td>0.3789017</td>\n",
       "<td>154.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.5400776</td>\n",
       "<td>0.9152861</td>\n",
       "<td>57.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.8235585</td>\n",
       "<td>0.8333333</td>\n",
       "<td>3.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0019703</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.8719520</td>\n",
       "<td>0.9999771</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.1492300</td>\n",
       "<td>0.3474447</td>\n",
       "<td>238.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.0994812</td>\n",
       "<td>0.7660231</td>\n",
       "<td>279.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.0811358</td>\n",
       "<td>0.7700010</td>\n",
       "<td>295.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.8719520</td>\n",
       "<td>43717.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.8719520</td>\n",
       "<td>4149.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0019703</td>\n",
       "<td>43718.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0019703</td>\n",
       "<td>4149.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.8719520</td>\n",
       "<td>0.9999771</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.8719520</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0019703</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0019703</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-29.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-29 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-29 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-29 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-29 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-29 .h2o-table th,\n",
       "#h2o-table-29 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-29 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-29\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate:  8.67 %, avg score:  8.55 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0100069</td>\n",
       "<td>0.5461605</td>\n",
       "<td>6.8884783</td>\n",
       "<td>6.8884783</td>\n",
       "<td>0.5970772</td>\n",
       "<td>0.6343759</td>\n",
       "<td>0.5970772</td>\n",
       "<td>0.6343759</td>\n",
       "<td>0.0689323</td>\n",
       "<td>0.0689323</td>\n",
       "<td>588.8478296</td>\n",
       "<td>588.8478296</td>\n",
       "<td>0.0645176</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0200138</td>\n",
       "<td>0.4632082</td>\n",
       "<td>5.2988295</td>\n",
       "<td>6.0936539</td>\n",
       "<td>0.4592902</td>\n",
       "<td>0.5018253</td>\n",
       "<td>0.5281837</td>\n",
       "<td>0.5681006</td>\n",
       "<td>0.0530248</td>\n",
       "<td>0.1219571</td>\n",
       "<td>429.8829459</td>\n",
       "<td>509.3653877</td>\n",
       "<td>0.1116181</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0299998</td>\n",
       "<td>0.4107290</td>\n",
       "<td>4.4892917</td>\n",
       "<td>5.5596113</td>\n",
       "<td>0.3891213</td>\n",
       "<td>0.4363776</td>\n",
       "<td>0.4818942</td>\n",
       "<td>0.5242541</td>\n",
       "<td>0.0448301</td>\n",
       "<td>0.1667872</td>\n",
       "<td>348.9291668</td>\n",
       "<td>455.9611303</td>\n",
       "<td>0.1497690</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0400694</td>\n",
       "<td>0.3664205</td>\n",
       "<td>4.4041648</td>\n",
       "<td>5.2692436</td>\n",
       "<td>0.3817427</td>\n",
       "<td>0.3870902</td>\n",
       "<td>0.4567258</td>\n",
       "<td>0.4897843</td>\n",
       "<td>0.0443480</td>\n",
       "<td>0.2111352</td>\n",
       "<td>340.4164779</td>\n",
       "<td>426.9243616</td>\n",
       "<td>0.1873006</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0500136</td>\n",
       "<td>0.3370934</td>\n",
       "<td>3.7325578</td>\n",
       "<td>4.9637037</td>\n",
       "<td>0.3235294</td>\n",
       "<td>0.3509687</td>\n",
       "<td>0.4302423</td>\n",
       "<td>0.4621836</td>\n",
       "<td>0.0371174</td>\n",
       "<td>0.2482526</td>\n",
       "<td>273.2557810</td>\n",
       "<td>396.3703748</td>\n",
       "<td>0.2170526</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1000063</td>\n",
       "<td>0.2386483</td>\n",
       "<td>3.2639143</td>\n",
       "<td>4.1139866</td>\n",
       "<td>0.2829085</td>\n",
       "<td>0.2813811</td>\n",
       "<td>0.3565908</td>\n",
       "<td>0.3718012</td>\n",
       "<td>0.1631718</td>\n",
       "<td>0.4114244</td>\n",
       "<td>226.3914283</td>\n",
       "<td>311.3986558</td>\n",
       "<td>0.3409729</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1499990</td>\n",
       "<td>0.1783284</td>\n",
       "<td>2.6371656</td>\n",
       "<td>3.6217815</td>\n",
       "<td>0.2285834</td>\n",
       "<td>0.2068893</td>\n",
       "<td>0.3139276</td>\n",
       "<td>0.3168382</td>\n",
       "<td>0.1318390</td>\n",
       "<td>0.5432634</td>\n",
       "<td>163.7165602</td>\n",
       "<td>262.1781468</td>\n",
       "<td>0.4305867</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2000125</td>\n",
       "<td>0.1418367</td>\n",
       "<td>2.1204171</td>\n",
       "<td>3.2463620</td>\n",
       "<td>0.1837928</td>\n",
       "<td>0.1603630</td>\n",
       "<td>0.2813871</td>\n",
       "<td>0.2777113</td>\n",
       "<td>0.1060497</td>\n",
       "<td>0.6493131</td>\n",
       "<td>112.0417135</td>\n",
       "<td>224.6361976</td>\n",
       "<td>0.4919408</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.2999979</td>\n",
       "<td>0.0900938</td>\n",
       "<td>1.4150057</td>\n",
       "<td>2.6359949</td>\n",
       "<td>0.1226494</td>\n",
       "<td>0.1139307</td>\n",
       "<td>0.2284819</td>\n",
       "<td>0.2231253</td>\n",
       "<td>0.1414799</td>\n",
       "<td>0.7907930</td>\n",
       "<td>41.5005675</td>\n",
       "<td>163.5994897</td>\n",
       "<td>0.5373733</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4000042</td>\n",
       "<td>0.0572581</td>\n",
       "<td>0.8724447</td>\n",
       "<td>2.1950843</td>\n",
       "<td>0.0756215</td>\n",
       "<td>0.0722966</td>\n",
       "<td>0.1902648</td>\n",
       "<td>0.1854162</td>\n",
       "<td>0.0872499</td>\n",
       "<td>0.8780429</td>\n",
       "<td>-12.7555282</td>\n",
       "<td>119.5084326</td>\n",
       "<td>0.5234064</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5000104</td>\n",
       "<td>0.0363731</td>\n",
       "<td>0.5253949</td>\n",
       "<td>1.8611325</td>\n",
       "<td>0.0455400</td>\n",
       "<td>0.0464366</td>\n",
       "<td>0.1613186</td>\n",
       "<td>0.1576191</td>\n",
       "<td>0.0525428</td>\n",
       "<td>0.9305857</td>\n",
       "<td>-47.4605114</td>\n",
       "<td>86.1132485</td>\n",
       "<td>0.4714384</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.5999958</td>\n",
       "<td>0.0220013</td>\n",
       "<td>0.2868580</td>\n",
       "<td>1.5987900</td>\n",
       "<td>0.0248642</td>\n",
       "<td>0.0289804</td>\n",
       "<td>0.1385794</td>\n",
       "<td>0.1361823</td>\n",
       "<td>0.0286816</td>\n",
       "<td>0.9592673</td>\n",
       "<td>-71.3141950</td>\n",
       "<td>59.8789956</td>\n",
       "<td>0.3933677</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.7000021</td>\n",
       "<td>0.0134175</td>\n",
       "<td>0.2000357</td>\n",
       "<td>1.3989560</td>\n",
       "<td>0.0173386</td>\n",
       "<td>0.0175104</td>\n",
       "<td>0.1212582</td>\n",
       "<td>0.1192282</td>\n",
       "<td>0.0200048</td>\n",
       "<td>0.9792721</td>\n",
       "<td>-79.9964333</td>\n",
       "<td>39.8955987</td>\n",
       "<td>0.3057738</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.7999875</td>\n",
       "<td>0.0082096</td>\n",
       "<td>0.1036546</td>\n",
       "<td>1.2370645</td>\n",
       "<td>0.0089845</td>\n",
       "<td>0.0106565</td>\n",
       "<td>0.1072259</td>\n",
       "<td>0.1056585</td>\n",
       "<td>0.0103639</td>\n",
       "<td>0.9896361</td>\n",
       "<td>-89.6345411</td>\n",
       "<td>23.7064454</td>\n",
       "<td>0.2076469</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8999937</td>\n",
       "<td>0.0047352</td>\n",
       "<td>0.0650718</td>\n",
       "<td>1.1068340</td>\n",
       "<td>0.0056403</td>\n",
       "<td>0.0063203</td>\n",
       "<td>0.0959378</td>\n",
       "<td>0.0946201</td>\n",
       "<td>0.0065076</td>\n",
       "<td>0.9961436</td>\n",
       "<td>-93.4928156</td>\n",
       "<td>10.6833984</td>\n",
       "<td>0.1052749</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0010466</td>\n",
       "<td>0.0385611</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0033424</td>\n",
       "<td>0.0033578</td>\n",
       "<td>0.0866777</td>\n",
       "<td>0.0854933</td>\n",
       "<td>0.0038564</td>\n",
       "<td>1.0</td>\n",
       "<td>-96.1438907</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-30.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-30 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-30 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-30 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-30 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-30 .h2o-table th,\n",
       "#h2o-table-30 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-30 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-30\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Scoring History: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>timestamp</th>\n",
       "<th>duration</th>\n",
       "<th>number_of_trees</th>\n",
       "<th>training_rmse</th>\n",
       "<th>training_logloss</th>\n",
       "<th>training_auc</th>\n",
       "<th>training_pr_auc</th>\n",
       "<th>training_lift</th>\n",
       "<th>training_classification_error</th>\n",
       "<th>validation_rmse</th>\n",
       "<th>validation_logloss</th>\n",
       "<th>validation_auc</th>\n",
       "<th>validation_pr_auc</th>\n",
       "<th>validation_lift</th>\n",
       "<th>validation_classification_error</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>2022-11-08 21:33:05</td>\n",
       "<td> 0.010 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>0.5</td>\n",
       "<td>0.6931472</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0857176</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9142824</td>\n",
       "<td>0.5</td>\n",
       "<td>0.6931472</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0866777</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9133223</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2022-11-08 21:33:09</td>\n",
       "<td> 4.543 sec</td>\n",
       "<td>5.0</td>\n",
       "<td>0.2734588</td>\n",
       "<td>0.2849356</td>\n",
       "<td>0.8141570</td>\n",
       "<td>0.3317111</td>\n",
       "<td>6.8920250</td>\n",
       "<td>0.1445256</td>\n",
       "<td>0.2751436</td>\n",
       "<td>0.2870134</td>\n",
       "<td>0.8161120</td>\n",
       "<td>0.3184008</td>\n",
       "<td>6.3345098</td>\n",
       "<td>0.1449433</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2022-11-08 21:33:13</td>\n",
       "<td> 8.264 sec</td>\n",
       "<td>10.0</td>\n",
       "<td>0.2582142</td>\n",
       "<td>0.2393936</td>\n",
       "<td>0.8308744</td>\n",
       "<td>0.3480517</td>\n",
       "<td>7.1331168</td>\n",
       "<td>0.1327211</td>\n",
       "<td>0.2604472</td>\n",
       "<td>0.2419950</td>\n",
       "<td>0.8320573</td>\n",
       "<td>0.3332827</td>\n",
       "<td>6.6476224</td>\n",
       "<td>0.1407859</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2022-11-08 21:33:17</td>\n",
       "<td>11.921 sec</td>\n",
       "<td>15.0</td>\n",
       "<td>0.2562013</td>\n",
       "<td>0.2297295</td>\n",
       "<td>0.8399505</td>\n",
       "<td>0.3551298</td>\n",
       "<td>7.1591691</td>\n",
       "<td>0.1312517</td>\n",
       "<td>0.2586867</td>\n",
       "<td>0.2327534</td>\n",
       "<td>0.8396360</td>\n",
       "<td>0.3391195</td>\n",
       "<td>6.6717080</td>\n",
       "<td>0.1472204</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2022-11-08 21:33:21</td>\n",
       "<td>15.720 sec</td>\n",
       "<td>20.0</td>\n",
       "<td>0.2553712</td>\n",
       "<td>0.2261867</td>\n",
       "<td>0.8435738</td>\n",
       "<td>0.3593158</td>\n",
       "<td>7.2393031</td>\n",
       "<td>0.1319663</td>\n",
       "<td>0.2580940</td>\n",
       "<td>0.2297035</td>\n",
       "<td>0.8418481</td>\n",
       "<td>0.3415727</td>\n",
       "<td>6.7680504</td>\n",
       "<td>0.1433764</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2022-11-08 21:33:24</td>\n",
       "<td>19.398 sec</td>\n",
       "<td>25.0</td>\n",
       "<td>0.2548886</td>\n",
       "<td>0.2244699</td>\n",
       "<td>0.8456934</td>\n",
       "<td>0.3623229</td>\n",
       "<td>7.3467455</td>\n",
       "<td>0.1333911</td>\n",
       "<td>0.2579201</td>\n",
       "<td>0.2286152</td>\n",
       "<td>0.8426154</td>\n",
       "<td>0.3426860</td>\n",
       "<td>6.7439648</td>\n",
       "<td>0.1455700</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2022-11-08 21:33:28</td>\n",
       "<td>23.092 sec</td>\n",
       "<td>30.0</td>\n",
       "<td>0.2544722</td>\n",
       "<td>0.2234008</td>\n",
       "<td>0.8471358</td>\n",
       "<td>0.3656960</td>\n",
       "<td>7.4215877</td>\n",
       "<td>0.1326944</td>\n",
       "<td>0.2576511</td>\n",
       "<td>0.2278649</td>\n",
       "<td>0.8435095</td>\n",
       "<td>0.3443444</td>\n",
       "<td>6.6957936</td>\n",
       "<td>0.1491424</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2022-11-08 21:33:32</td>\n",
       "<td>26.791 sec</td>\n",
       "<td>35.0</td>\n",
       "<td>0.2539642</td>\n",
       "<td>0.2223873</td>\n",
       "<td>0.8486776</td>\n",
       "<td>0.3707060</td>\n",
       "<td>7.4770070</td>\n",
       "<td>0.1323549</td>\n",
       "<td>0.2576747</td>\n",
       "<td>0.2277134</td>\n",
       "<td>0.8438228</td>\n",
       "<td>0.3429855</td>\n",
       "<td>6.6717080</td>\n",
       "<td>0.1490380</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2022-11-08 21:33:35</td>\n",
       "<td>30.557 sec</td>\n",
       "<td>40.0</td>\n",
       "<td>0.2536291</td>\n",
       "<td>0.2217000</td>\n",
       "<td>0.8498040</td>\n",
       "<td>0.3739772</td>\n",
       "<td>7.5134802</td>\n",
       "<td>0.1223370</td>\n",
       "<td>0.2575968</td>\n",
       "<td>0.2276046</td>\n",
       "<td>0.8437920</td>\n",
       "<td>0.3439568</td>\n",
       "<td>6.7198792</td>\n",
       "<td>0.1467608</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2022-11-08 21:33:39</td>\n",
       "<td>34.539 sec</td>\n",
       "<td>45.0</td>\n",
       "<td>0.2533234</td>\n",
       "<td>0.2211676</td>\n",
       "<td>0.8505724</td>\n",
       "<td>0.3772701</td>\n",
       "<td>7.5968475</td>\n",
       "<td>0.1217876</td>\n",
       "<td>0.2575816</td>\n",
       "<td>0.2275356</td>\n",
       "<td>0.8438487</td>\n",
       "<td>0.3437724</td>\n",
       "<td>6.7680504</td>\n",
       "<td>0.1471160</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2022-11-08 21:33:43</td>\n",
       "<td>38.468 sec</td>\n",
       "<td>50.0</td>\n",
       "<td>0.2531287</td>\n",
       "<td>0.2207618</td>\n",
       "<td>0.8512637</td>\n",
       "<td>0.3790079</td>\n",
       "<td>7.6333207</td>\n",
       "<td>0.1303093</td>\n",
       "<td>0.2576005</td>\n",
       "<td>0.2275350</td>\n",
       "<td>0.8437717</td>\n",
       "<td>0.3437669</td>\n",
       "<td>6.9607351</td>\n",
       "<td>0.1521090</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2022-11-08 21:33:48</td>\n",
       "<td>42.713 sec</td>\n",
       "<td>55.0</td>\n",
       "<td>0.2528881</td>\n",
       "<td>0.2203595</td>\n",
       "<td>0.8519084</td>\n",
       "<td>0.3814191</td>\n",
       "<td>7.6645835</td>\n",
       "<td>0.1215911</td>\n",
       "<td>0.2576274</td>\n",
       "<td>0.2276276</td>\n",
       "<td>0.8435791</td>\n",
       "<td>0.3434588</td>\n",
       "<td>6.8884783</td>\n",
       "<td>0.1472622</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-31.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-31 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-31 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-31 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-31 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-31 .h2o-table th,\n",
       "#h2o-table-31 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-31 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-31\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Variable Importances: </caption>\n",
       "    <thead><tr><th>variable</th>\n",
       "<th>relative_importance</th>\n",
       "<th>scaled_importance</th>\n",
       "<th>percentage</th></tr></thead>\n",
       "    <tbody><tr><td>DiffWalking.No</td>\n",
       "<td>4103.1484375</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0875864</td></tr>\n",
       "<tr><td>Diabetic.Yes</td>\n",
       "<td>3668.9157715</td>\n",
       "<td>0.8941709</td>\n",
       "<td>0.0783172</td></tr>\n",
       "<tr><td>AgeCategory.80 or older</td>\n",
       "<td>3489.6950684</td>\n",
       "<td>0.8504920</td>\n",
       "<td>0.0744916</td></tr>\n",
       "<tr><td>Stroke.No</td>\n",
       "<td>3385.1030273</td>\n",
       "<td>0.8250014</td>\n",
       "<td>0.0722589</td></tr>\n",
       "<tr><td>GenHealth.Very good</td>\n",
       "<td>2257.4892578</td>\n",
       "<td>0.5501846</td>\n",
       "<td>0.0481887</td></tr>\n",
       "<tr><td>GenHealth.Excellent</td>\n",
       "<td>2237.9616699</td>\n",
       "<td>0.5454255</td>\n",
       "<td>0.0477719</td></tr>\n",
       "<tr><td>Sex.Female</td>\n",
       "<td>1920.0090332</td>\n",
       "<td>0.4679356</td>\n",
       "<td>0.0409848</td></tr>\n",
       "<tr><td>AgeCategory.70-74</td>\n",
       "<td>1915.5727539</td>\n",
       "<td>0.4668544</td>\n",
       "<td>0.0408901</td></tr>\n",
       "<tr><td>AgeCategory.75-79</td>\n",
       "<td>1809.0966797</td>\n",
       "<td>0.4409045</td>\n",
       "<td>0.0386172</td></tr>\n",
       "<tr><td>PhysicalHealth</td>\n",
       "<td>1585.5604248</td>\n",
       "<td>0.3864253</td>\n",
       "<td>0.0338456</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>Smoking.Yes</td>\n",
       "<td>85.7803116</td>\n",
       "<td>0.0209060</td>\n",
       "<td>0.0018311</td></tr>\n",
       "<tr><td>Race.American Indian/Alaskan Native</td>\n",
       "<td>82.2688293</td>\n",
       "<td>0.0200502</td>\n",
       "<td>0.0017561</td></tr>\n",
       "<tr><td>AgeCategory.55-59</td>\n",
       "<td>80.6028976</td>\n",
       "<td>0.0196442</td>\n",
       "<td>0.0017206</td></tr>\n",
       "<tr><td>Race.Other</td>\n",
       "<td>79.4932251</td>\n",
       "<td>0.0193737</td>\n",
       "<td>0.0016969</td></tr>\n",
       "<tr><td>AlcoholDrinking.No</td>\n",
       "<td>60.6702423</td>\n",
       "<td>0.0147863</td>\n",
       "<td>0.0012951</td></tr>\n",
       "<tr><td>Race.Asian</td>\n",
       "<td>54.0739441</td>\n",
       "<td>0.0131786</td>\n",
       "<td>0.0011543</td></tr>\n",
       "<tr><td>PhysicalActivity.Yes</td>\n",
       "<td>46.0828400</td>\n",
       "<td>0.0112311</td>\n",
       "<td>0.0009837</td></tr>\n",
       "<tr><td>AlcoholDrinking.Yes</td>\n",
       "<td>39.2535095</td>\n",
       "<td>0.0095667</td>\n",
       "<td>0.0008379</td></tr>\n",
       "<tr><td>Diabetic.No, borderline diabetes</td>\n",
       "<td>21.5210133</td>\n",
       "<td>0.0052450</td>\n",
       "<td>0.0004594</td></tr>\n",
       "<tr><td>Diabetic.Yes (during pregnancy)</td>\n",
       "<td>13.7965717</td>\n",
       "<td>0.0033624</td>\n",
       "<td>0.0002945</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[50 rows x 4 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
      ],
      "text/plain": [
       "Model Details\n",
       "=============\n",
       "H2OXGBoostEstimator : XGBoost\n",
       "Model Key: XGBoost_3_AutoML_3_20221108_212840\n",
       "\n",
       "\n",
       "Model Summary: \n",
       "    number_of_trees\n",
       "--  -----------------\n",
       "    55\n",
       "\n",
       "ModelMetricsBinomial: xgboost\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.06395236788288416\n",
       "RMSE: 0.2528880540533383\n",
       "LogLoss: 0.22035946660347489\n",
       "Mean Per-Class Error: 0.29272633188266417\n",
       "AUC: 0.8519084415463216\n",
       "AUCPR: 0.3814190648417427\n",
       "Gini: 0.7038168830926432\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.21242088954735622\n",
       "       No      Yes    Error    Rate\n",
       "-----  ------  -----  -------  ------------------\n",
       "No     187064  17642  0.0862   (17642.0/204706.0)\n",
       "Yes    9582    9610   0.4993   (9582.0/19192.0)\n",
       "Total  196646  27252  0.1216   (27224.0/223898.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.212421     0.413832  199\n",
       "max f2                       0.101801     0.533884  278\n",
       "max f0point5                 0.324551     0.414841  138\n",
       "max accuracy                 0.48712      0.917806  74\n",
       "max precision                0.923032     1         0\n",
       "max recall                   0.00238551   1         398\n",
       "max specificity              0.923032     1         0\n",
       "max absolute_mcc             0.197742     0.356064  208\n",
       "max min_per_class_accuracy   0.101801     0.769591  278\n",
       "max mean_per_class_accuracy  0.0930588    0.772538  286\n",
       "max tns                      0.923032     204706    0\n",
       "max fns                      0.923032     19191     0\n",
       "max fps                      0.00189072   204706    399\n",
       "max tps                      0.00238551   19192     398\n",
       "max tnr                      0.923032     1         0\n",
       "max fnr                      0.923032     0.999948  0\n",
       "max fpr                      0.00189072   1         399\n",
       "max tpr                      0.00238551   1         398\n",
       "\n",
       "Gains/Lift Table: Avg response rate:  8.57 %, avg score:  8.58 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0100001                   0.545439           7.66458    7.66458            0.65699          0.636009    0.65699                     0.636009            0.0766465       0.0766465                  666.458   666.458            0.0728948\n",
       "2        0.0200002                   0.463388           5.94513    6.80486            0.509603         0.500047    0.583296                    0.568028            0.0594519       0.136098                   494.513   580.486            0.126983\n",
       "3        0.0300003                   0.411204           5.15314    6.25429            0.441715         0.435676    0.536102                    0.523911            0.0515319       0.18763                    415.314   525.429            0.172408\n",
       "4        0.0400048                   0.370372           4.76023    5.88065            0.408036         0.390164    0.504075                    0.490463            0.047624        0.235254                   376.023   488.065            0.213555\n",
       "5        0.0500004                   0.339746           3.97214    5.49912            0.340483         0.354173    0.471371                    0.463217            0.039704        0.274958                   297.214   449.912            0.246049\n",
       "6        0.100001                    0.23984            3.37846    4.43879            0.289594         0.283786    0.380482                    0.373501            0.168925        0.443883                   237.846   343.879            0.376122\n",
       "7        0.150024                    0.180509           2.41657    3.76452            0.207143         0.208196    0.322685                    0.318383            0.120884        0.564767                   141.657   276.452            0.453627\n",
       "8        0.200002                    0.142542           1.9329     3.30682            0.165684         0.161408    0.283452                    0.279157            0.0966028       0.661369                   93.2901   230.682            0.504623\n",
       "9        0.300003                    0.0903046          1.3667     2.66011            0.117151         0.114098    0.228018                    0.224137            0.136672        0.798041                   36.6703   166.011            0.544731\n",
       "10       0.399999                    0.0574882          0.834753   2.20379            0.071553         0.0726463   0.188903                    0.186266            0.0834723       0.881513                   -16.5247  120.379            0.526658\n",
       "11       0.500116                    0.0361844          0.531371   1.86899            0.0455478        0.0462545   0.160205                    0.158237            0.0531992       0.934712                   -46.8629  86.8991            0.475341\n",
       "12       0.600001                    0.0219814          0.315078   1.6103             0.0270077        0.0289124   0.138031                    0.136708            0.0314714       0.966184                   -68.4922  61.0304            0.400514\n",
       "13       0.699997                    0.0134207          0.169869   1.40453            0.0145607        0.0174599   0.120393                    0.119673            0.0169862       0.98317                    -83.0131  40.4534            0.309721\n",
       "14       0.799998                    0.00817649         0.0932672  1.24062            0.00799464       0.0106338   0.106343                    0.106043            0.0093268       0.992497                   -90.6733  24.0624            0.210546\n",
       "15       0.899999                    0.00472616         0.0510625  1.10845            0.00437695       0.00628974  0.0950136                   0.0949592           0.00510629      0.997603                   -94.8938  10.8449            0.106755\n",
       "16       1                           0.000944155        0.0239681  1                  0.00205449       0.00336505  0.0857176                   0.0857997           0.00239683      1                          -97.6032  0                  0\n",
       "\n",
       "ModelMetricsBinomial: xgboost\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.06637189113184688\n",
       "RMSE: 0.2576274269790522\n",
       "LogLoss: 0.22762759473977812\n",
       "Mean Per-Class Error: 0.27618870238825843\n",
       "AUC: 0.8435790782332893\n",
       "AUCPR: 0.3434588136032144\n",
       "Gini: 0.6871581564665785\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.17301240337045887\n",
       "       No     Yes    Error    Rate\n",
       "-----  -----  -----  -------  ----------------\n",
       "No     38462  5256   0.1202   (5256.0/43718.0)\n",
       "Yes    1793   2356   0.4322   (1793.0/4149.0)\n",
       "Total  40255  7612   0.1473   (7049.0/47867.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.173012     0.400646  221\n",
       "max f2                       0.104176     0.532275  275\n",
       "max f0point5                 0.284422     0.378902  154\n",
       "max accuracy                 0.540078     0.915286  57\n",
       "max precision                0.823558     0.833333  3\n",
       "max recall                   0.0019703    1         399\n",
       "max specificity              0.871952     0.999977  0\n",
       "max absolute_mcc             0.14923      0.347445  238\n",
       "max min_per_class_accuracy   0.0994812    0.766023  279\n",
       "max mean_per_class_accuracy  0.0811358    0.770001  295\n",
       "max tns                      0.871952     43717     0\n",
       "max fns                      0.871952     4149      0\n",
       "max fps                      0.0019703    43718     399\n",
       "max tps                      0.0019703    4149      399\n",
       "max tnr                      0.871952     0.999977  0\n",
       "max fnr                      0.871952     1         0\n",
       "max fpr                      0.0019703    1         399\n",
       "max tpr                      0.0019703    1         399\n",
       "\n",
       "Gains/Lift Table: Avg response rate:  8.67 %, avg score:  8.55 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0100069                   0.546161           6.88848    6.88848            0.597077         0.634376    0.597077                    0.634376            0.0689323       0.0689323                  588.848   588.848            0.0645176\n",
       "2        0.0200138                   0.463208           5.29883    6.09365            0.45929          0.501825    0.528184                    0.568101            0.0530248       0.121957                   429.883   509.365            0.111618\n",
       "3        0.0299998                   0.410729           4.48929    5.55961            0.389121         0.436378    0.481894                    0.524254            0.0448301       0.166787                   348.929   455.961            0.149769\n",
       "4        0.0400694                   0.366421           4.40416    5.26924            0.381743         0.38709     0.456726                    0.489784            0.044348        0.211135                   340.416   426.924            0.187301\n",
       "5        0.0500136                   0.337093           3.73256    4.9637             0.323529         0.350969    0.430242                    0.462184            0.0371174       0.248253                   273.256   396.37             0.217053\n",
       "6        0.100006                    0.238648           3.26391    4.11399            0.282908         0.281381    0.356591                    0.371801            0.163172        0.411424                   226.391   311.399            0.340973\n",
       "7        0.149999                    0.178328           2.63717    3.62178            0.228583         0.206889    0.313928                    0.316838            0.131839        0.543263                   163.717   262.178            0.430587\n",
       "8        0.200013                    0.141837           2.12042    3.24636            0.183793         0.160363    0.281387                    0.277711            0.10605         0.649313                   112.042   224.636            0.491941\n",
       "9        0.299998                    0.0900938          1.41501    2.63599            0.122649         0.113931    0.228482                    0.223125            0.14148         0.790793                   41.5006   163.599            0.537373\n",
       "10       0.400004                    0.0572581          0.872445   2.19508            0.0756215        0.0722966   0.190265                    0.185416            0.0872499       0.878043                   -12.7555  119.508            0.523406\n",
       "11       0.50001                     0.0363731          0.525395   1.86113            0.04554          0.0464366   0.161319                    0.157619            0.0525428       0.930586                   -47.4605  86.1132            0.471438\n",
       "12       0.599996                    0.0220013          0.286858   1.59879            0.0248642        0.0289804   0.138579                    0.136182            0.0286816       0.959267                   -71.3142  59.879             0.393368\n",
       "13       0.700002                    0.0134175          0.200036   1.39896            0.0173386        0.0175104   0.121258                    0.119228            0.0200048       0.979272                   -79.9964  39.8956            0.305774\n",
       "14       0.799987                    0.00820958         0.103655   1.23706            0.00898454       0.0106565   0.107226                    0.105658            0.0103639       0.989636                   -89.6345  23.7064            0.207647\n",
       "15       0.899994                    0.00473523         0.0650718  1.10683            0.00564028       0.00632031  0.0959378                   0.0946201           0.00650759      0.996144                   -93.4928  10.6834            0.105275\n",
       "16       1                           0.00104658         0.0385611  1                  0.00334239       0.00335785  0.0866777                   0.0854933           0.00385635      1                          -96.1439  0                  0\n",
       "\n",
       "Scoring History: \n",
       "    timestamp            duration    number_of_trees    training_rmse    training_logloss    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_auc    validation_pr_auc    validation_lift    validation_classification_error\n",
       "--  -------------------  ----------  -----------------  ---------------  ------------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ----------------  -------------------  -----------------  ---------------------------------\n",
       "    2022-11-08 21:33:05  0.010 sec   0                  0.5              0.693147            0.5             0.0857176          1                0.914282                         0.5                0.693147              0.5               0.0866777            1                  0.913322\n",
       "    2022-11-08 21:33:09  4.543 sec   5                  0.273459         0.284936            0.814157        0.331711           6.89202          0.144526                         0.275144           0.287013              0.816112          0.318401             6.33451            0.144943\n",
       "    2022-11-08 21:33:13  8.264 sec   10                 0.258214         0.239394            0.830874        0.348052           7.13312          0.132721                         0.260447           0.241995              0.832057          0.333283             6.64762            0.140786\n",
       "    2022-11-08 21:33:17  11.921 sec  15                 0.256201         0.22973             0.839951        0.35513            7.15917          0.131252                         0.258687           0.232753              0.839636          0.33912              6.67171            0.14722\n",
       "    2022-11-08 21:33:21  15.720 sec  20                 0.255371         0.226187            0.843574        0.359316           7.2393           0.131966                         0.258094           0.229703              0.841848          0.341573             6.76805            0.143376\n",
       "    2022-11-08 21:33:24  19.398 sec  25                 0.254889         0.22447             0.845693        0.362323           7.34675          0.133391                         0.25792            0.228615              0.842615          0.342686             6.74396            0.14557\n",
       "    2022-11-08 21:33:28  23.092 sec  30                 0.254472         0.223401            0.847136        0.365696           7.42159          0.132694                         0.257651           0.227865              0.843509          0.344344             6.69579            0.149142\n",
       "    2022-11-08 21:33:32  26.791 sec  35                 0.253964         0.222387            0.848678        0.370706           7.47701          0.132355                         0.257675           0.227713              0.843823          0.342986             6.67171            0.149038\n",
       "    2022-11-08 21:33:35  30.557 sec  40                 0.253629         0.2217              0.849804        0.373977           7.51348          0.122337                         0.257597           0.227605              0.843792          0.343957             6.71988            0.146761\n",
       "    2022-11-08 21:33:39  34.539 sec  45                 0.253323         0.221168            0.850572        0.37727            7.59685          0.121788                         0.257582           0.227536              0.843849          0.343772             6.76805            0.147116\n",
       "    2022-11-08 21:33:43  38.468 sec  50                 0.253129         0.220762            0.851264        0.379008           7.63332          0.130309                         0.257601           0.227535              0.843772          0.343767             6.96074            0.152109\n",
       "    2022-11-08 21:33:48  42.713 sec  55                 0.252888         0.220359            0.851908        0.381419           7.66458          0.121591                         0.257627           0.227628              0.843579          0.343459             6.88848            0.147262\n",
       "\n",
       "Variable Importances: \n",
       "variable                             relative_importance    scaled_importance      percentage\n",
       "-----------------------------------  ---------------------  ---------------------  ----------------------\n",
       "DiffWalking.No                       4103.1484375           1.0                    0.0875864232996671\n",
       "Diabetic.Yes                         3668.915771484375      0.8941708610765742     0.07831722754048064\n",
       "AgeCategory.80 or older              3489.695068359375      0.8504920359365807     0.07449155547253702\n",
       "Stroke.No                            3385.10302734375       0.8250013566182981     0.07225891804356986\n",
       "GenHealth.Very good                  2257.4892578125        0.5501846428904633     0.048188705025180294\n",
       "GenHealth.Excellent                  2237.961669921875      0.5454254711987555     0.047771866198834584\n",
       "Sex.Female                           1920.009033203125      0.46793555301473905    0.04098480142331275\n",
       "AgeCategory.70-74                    1915.57275390625       0.4668543639316607     0.040890103938615266\n",
       "AgeCategory.75-79                    1809.0966796875        0.4409045169201242     0.03861724965370123\n",
       "PhysicalHealth                       1585.5604248046875     0.38642531435464       0.03384561115677242\n",
       "---                                  ---                    ---                    ---\n",
       "Smoking.Yes                          85.78031158447266      0.020905973276642554   0.001831079424899543\n",
       "Race.American Indian/Alaskan Native  82.26882934570312      0.020050171374211494   0.0017561227972125559\n",
       "AgeCategory.55-59                    80.60289764404297      0.01964415835103284    0.0017205615686992524\n",
       "Race.Other                           79.49322509765625      0.019373714187656963   0.0016968743317268887\n",
       "AlcoholDrinking.No                   60.67024230957031      0.01478626553089948    0.0012950761118106387\n",
       "Race.Asian                           54.073944091796875     0.013178646816088255   0.001154270538550716\n",
       "PhysicalActivity.Yes                 46.08283996582031      0.011231092578726702   0.0009836912287181066\n",
       "AlcoholDrinking.Yes                  39.253509521484375     0.009566680347884533   0.000837911314522421\n",
       "Diabetic.No, borderline diabetes     21.521013259887695     0.0052449999281527805  0.00045939078391391295\n",
       "Diabetic.Yes (during pregnancy)      13.796571731567383     0.0033624354423729967  0.00029450369397348463\n",
       "[50 rows x 4 columns]\n",
       "\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "369017ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-33.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-33 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-33 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-33 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-33 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-33 .h2o-table th,\n",
       "#h2o-table-33 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-33 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-33\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.21242088954735622</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>No</th>\n",
       "<th>Yes</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>No</td>\n",
       "<td>187064.0</td>\n",
       "<td>17642.0</td>\n",
       "<td>0.0862</td>\n",
       "<td> (17642.0/204706.0)</td></tr>\n",
       "<tr><td>Yes</td>\n",
       "<td>9582.0</td>\n",
       "<td>9610.0</td>\n",
       "<td>0.4993</td>\n",
       "<td> (9582.0/19192.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>196646.0</td>\n",
       "<td>27252.0</td>\n",
       "<td>0.1216</td>\n",
       "<td> (27224.0/223898.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.21242088954735622\n",
       "       No      Yes    Error    Rate\n",
       "-----  ------  -----  -------  ------------------\n",
       "No     187064  17642  0.0862   (17642.0/204706.0)\n",
       "Yes    9582    9610   0.4993   (9582.0/19192.0)\n",
       "Total  196646  27252  0.1216   (27224.0/223898.0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusuion matrix for xgboost method\n",
    "out.confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "855db302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<h2o.plot._plot_result._MObject at 0x7fb6d86e1dc0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out.varimp_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7923ae40",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "**Evaluation:**  We can evaluate our model by using the above confusion matrix from it we can say that the error and rate of error in the cofusion matrix are significantly low suggesting that the model is working perfectly. \n",
    "\n",
    "Also while evaluating all the model we can see that present leader model has the least amount of **mean_per_class_error** and **log loss** as well. Which also suggests that our model fuctions perfectly.\n",
    "\n",
    "The model also gives the most important variables as \"DiffWalking.No\", \"Diabetic.Yes\", \"AgeCategory.80 or Older\" suggesting heart disease dependence on it. Also we know since the model thats involved GBM handles Overfitting finely as well. Probably the reason h2o choose it in the first place."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc45574b",
   "metadata": {},
   "source": [
    "**1. Is the relationship significant?**\n",
    "\n",
    "Statistical significance means that there is a good chance that we are right in finding that a relationship exists between two variables. We can observe from above that the dependent variable is dependent on variables such as DiffWalking, Diabetic, Stroke, AgeCategory. We can suggest that the relation ship is significant btw the dependant and independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b09a18",
   "metadata": {},
   "source": [
    "**2. Are any model assumptions violated?**\n",
    "\n",
    "To answer the above question we need to know answer to the below questions.\n",
    "\n",
    "What Are the Assumptions of GBM(Gradient boosting model)?\n",
    "1) Independence of observations\n",
    "\n",
    "2) Assumptions related to the interaction depth. If set to 1, strictly additive model is assumed. As we increase the interaction depth, this assumption is relaxed.\n",
    "\n",
    "What Are the Assumptions of XGBoost?\n",
    "\n",
    "1)XGBoost may assume that encoded integer values for each input variable have an ordinal relationship\n",
    "2)XGBoost assume that your data may not be complete (i.e. it can deal with missing values)\n",
    "\n",
    "So from above we can say, that every while many variables are real in nature still they can be assumed into finite interval, there by it won't be problem assuming it is ordinal. Similary for GBM model every observation in the dataset as we know are differnt and not dependent on other observations as well. \n",
    "\n",
    "So, no assumptions of either GBM or XGBoost model are Violated here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f402329c",
   "metadata": {},
   "source": [
    "**3. Is there any multicollinearity in the model?**\n",
    "\n",
    "Multicollinearity occurs when two or more independent variables are highly correlated with one another in a  model. As we could see that there is so much colienarity between Physical Health and DiffWalking, Mental health and Physical health."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634d90b7",
   "metadata": {},
   "source": [
    "**4. In the multivariate models are predictor variables independent of all the other predictor variables?**\n",
    "\n",
    "From above correlation we can see that these variables are the one with correlation. and Independent variables have both zero covariance and correlation. While they may be dependent on each other a bit, It its still not significant enough to call them dependent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c58a83",
   "metadata": {},
   "source": [
    "**5. In in multivariate models rank the most significant predictor variables and exclude insignificant ones from the model.**\n",
    "\n",
    "**Most Importatnt Variables: **\n",
    "1. DiffWalking.No\n",
    "2. Diabetic.Yes\n",
    "3. AgeCategory80orOlder\n",
    "4. Stroke.No\n",
    "\n",
    "\n",
    "are the most importatnt variables for predicitng the Heart diesases better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e91f89",
   "metadata": {},
   "source": [
    "**6. Does the model make sense?**\n",
    "\n",
    "Yes as we can see that the obesity level depending on \"DiffWalking.No\", \"Diabetic.Yes\", etc we can undersatad that the model in sensible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052947a5",
   "metadata": {},
   "source": [
    "**7. Does regularization help?**\n",
    "\n",
    "Regularization helps by ignificantly reducing the variance of the model, without substantial increase in its bias. it is reducing the variance(hence avoiding overfitting), without loosing any important properties in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c5d951",
   "metadata": {},
   "source": [
    "**8. Which independent variables are significant?**\n",
    "\n",
    "DiffWalking.No, Diabetic.Yes are the significant variables of all.\n",
    "Esp Total day charge is the most significant variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1b9d9c",
   "metadata": {},
   "source": [
    "**9. Which hyperparameters are important?**\n",
    "\n",
    "max_models and exclude_algos are the most important hyperparameters as they save us a lot of time here. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd28d39",
   "metadata": {},
   "source": [
    "**Reference**:\n",
    "\n",
    "https://github.com/aiskunks/Skunks_Skool/blob/main/INFO_6105/6105/6105_H2O_automl_lending_club.ipynb\n",
    "\n",
    "https://github.com/aiskunks/Skunks_Skool/blob/main/INFO_6105/6105/6105_H2O_automl_model.ipynb\n",
    "\n",
    "https://github.com/aiskunks/Skunks_Skool/blob/main/INFO_6105/6105/6105_Airlines_GBM_AutoML.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe5083c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
