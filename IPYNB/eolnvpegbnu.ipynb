{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Abstract** \n",
        "\n",
        "Since real predictive maintenance datasets are generally difficult to obtain and in particular difficult to publish, we present and provide a synthetic dataset that reflects real predictive maintenance encountered in industry to the best of our knowledge.\n",
        "\n",
        "In this notebook we perform classification on whether a machine would be failed or not based on some factors and patterns.\n",
        "\n",
        "\n",
        "Acknowledgement : https://archive.ics.uci.edu/ml/datasets/AI4I+2020+Predictive+Maintenance+Dataset"
      ],
      "metadata": {
        "id": "DI_PQJUFDwP7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset has `10000` entries and `8` feature with `6` nominal and `2` categorical features with `3.39` Target `Failure` observations.\n",
        "\n",
        " Numerical features : `Air temperature [K]` `Process temperature [K]` `Rotational speed [rpm]` `Torque [Nm]` `Tool wear [min]` `Target`\n",
        " \n",
        " Categorical features: `Type` `Failure Type`"
      ],
      "metadata": {
        "id": "hCDOOFFIE8FJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXNXcWr-hPlq",
        "outputId": "93b83c00-a83b-43ce-d77b-2528757ff0fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#this command might be relevant ony on GPU nodes. But the notebook will run on CPU as well\n",
        "#If running on CPU remove the command wherever it appears\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install default-jre\n",
        "!java -version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmyE6c36haY8",
        "outputId": "eccd56dd-6493-44f5-e308-92bc685af51d"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "default-jre is already the newest version (2:1.11-68ubuntu1~18.04.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 4 not upgraded.\n",
            "openjdk version \"11.0.16\" 2022-07-19\n",
            "OpenJDK Runtime Environment (build 11.0.16+8-post-Ubuntu-0ubuntu118.04)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.16+8-post-Ubuntu-0ubuntu118.04, mixed mode, sharing)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install h2o"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0qgSIw-oi9M",
        "outputId": "cc96f045-b5ce-4457-87a3-60911620991a"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: h2o in /usr/local/lib/python3.7/dist-packages (3.38.0.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from h2o) (0.16.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from h2o) (2.23.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from h2o) (0.8.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->h2o) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->h2o) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->h2o) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->h2o) (2022.9.24)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import h2o\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "CLYB53e4L8Nn"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing H2O AutoML "
      ],
      "metadata": {
        "id": "ObO9tkCKstJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "h2o.init()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "BzKmJhbBtqcm",
        "outputId": "7a59d367-1b88-44e7-dd70-5ca042cbd69d"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking whether there is an H2O instance running at http://localhost:54321 . connected.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "--------------------------  ----------------------------------\n",
              "H2O_cluster_uptime:         36 mins 13 secs\n",
              "H2O_cluster_timezone:       Etc/UTC\n",
              "H2O_data_parsing_timezone:  UTC\n",
              "H2O_cluster_version:        3.38.0.2\n",
              "H2O_cluster_version_age:    11 days\n",
              "H2O_cluster_name:           H2O_from_python_unknownUser_ao29qa\n",
              "H2O_cluster_total_nodes:    1\n",
              "H2O_cluster_free_memory:    3.162 Gb\n",
              "H2O_cluster_total_cores:    2\n",
              "H2O_cluster_allowed_cores:  2\n",
              "H2O_cluster_status:         locked, healthy\n",
              "H2O_connection_url:         http://localhost:54321\n",
              "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
              "H2O_internal_security:      False\n",
              "Python_version:             3.7.15 final\n",
              "--------------------------  ----------------------------------"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "\n",
              "#h2o-table-65.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-65 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-65 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-65 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-65 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-65 .h2o-table th,\n",
              "#h2o-table-65 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-65 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-65\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption></caption>\n",
              "    <thead></thead>\n",
              "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
              "<td>36 mins 13 secs</td></tr>\n",
              "<tr><td>H2O_cluster_timezone:</td>\n",
              "<td>Etc/UTC</td></tr>\n",
              "<tr><td>H2O_data_parsing_timezone:</td>\n",
              "<td>UTC</td></tr>\n",
              "<tr><td>H2O_cluster_version:</td>\n",
              "<td>3.38.0.2</td></tr>\n",
              "<tr><td>H2O_cluster_version_age:</td>\n",
              "<td>11 days </td></tr>\n",
              "<tr><td>H2O_cluster_name:</td>\n",
              "<td>H2O_from_python_unknownUser_ao29qa</td></tr>\n",
              "<tr><td>H2O_cluster_total_nodes:</td>\n",
              "<td>1</td></tr>\n",
              "<tr><td>H2O_cluster_free_memory:</td>\n",
              "<td>3.162 Gb</td></tr>\n",
              "<tr><td>H2O_cluster_total_cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O_cluster_allowed_cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O_cluster_status:</td>\n",
              "<td>locked, healthy</td></tr>\n",
              "<tr><td>H2O_connection_url:</td>\n",
              "<td>http://localhost:54321</td></tr>\n",
              "<tr><td>H2O_connection_proxy:</td>\n",
              "<td>{\"http\": null, \"https\": null}</td></tr>\n",
              "<tr><td>H2O_internal_security:</td>\n",
              "<td>False</td></tr>\n",
              "<tr><td>Python_version:</td>\n",
              "<td>3.7.15 final</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from h2o.automl import H2OAutoML"
      ],
      "metadata": {
        "id": "EF_E4OCpr9Ta"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = h2o.import_file('https://raw.githubusercontent.com/Venkata-Bhargavi/AutoML/main/predictive_maintenance%205.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYBVG9VZr-Ci",
        "outputId": "7aaef1df-ab4d-4779-8548-ecacec876421"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset is placed in github and importing it as a raw file"
      ],
      "metadata": {
        "id": "C6VUYsZltVm7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Description\n",
        "\n",
        "`UID`: unique identifier ranging from 1 to 10000\n",
        "\n",
        "`productID`: consisting of a letter L, M, or H for low (50% of all products), medium (30%), and high (20%) as product quality variants and a variant-specific serial number\n",
        "\n",
        "`Air temperature [K]`: generated using a random walk process later normalized to a standard deviation of 2 K around 300 K\n",
        "`Process temperature [K]: generated using a random walk process normalized to a standard deviation of 1 K, added to the air temperature plus 10 K.\n",
        "\n",
        "`Rotational speed [rpm]`: calculated from powepower of 2860 W, overlaid with a normally distributed noise\n",
        "\n",
        "`Torque [Nm]`: torque values are normally distributed around 40 Nm with an Ïƒ = 10 Nm and no negative values.\n",
        "\n",
        "`Tool wear [min]`: The quality variants H/M/L add 5/3/2 minutes of tool wear to the used tool in the process. and a\n",
        "'machine failure' label that indicates, whether the machine has failed in this particular data point for any of the following failure modes are true.\n",
        "Important : There are two Targets - Do not make the mistake of using one of them as feature, as it will lead to leakage.\n",
        "\n",
        "`Target` : Failure or Not\n",
        "\n",
        "`Failure Type` : Type of Failure\n",
        "\n",
        "Acknowledgements\n",
        "\n",
        "UCI : https://archive.ics.uci.edu/ml/datasets/AI4I+2020+Predictive+Maintenance+Dataset"
      ],
      "metadata": {
        "id": "P9KPzaokD8mQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.types # checking the data types of all the features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYrvtVRitaZU",
        "outputId": "d0b96201-9496-4d27-a3f3-c9703b336c3d"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\ufeffUDI': 'int',\n",
              " 'Product ID': 'string',\n",
              " 'Type': 'enum',\n",
              " 'Air temperature [K]': 'real',\n",
              " 'Process temperature [K]': 'real',\n",
              " 'Rotational speed [rpm]': 'int',\n",
              " 'Torque [Nm]': 'real',\n",
              " 'Tool wear [min]': 'int',\n",
              " 'Target': 'enum',\n",
              " 'Failure Type': 'enum'}"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, in this data Target is a categorical feature but represented as integer and should be converted to categorical feature."
      ],
      "metadata": {
        "id": "new3j97wtlbg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "id": "do82F2i4umv4",
        "outputId": "13549a0b-0f34-4540-cfa0-7ff634c3279b"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Rows:10000\n",
              "Cols:10\n"
            ],
            "text/html": [
              "<pre style='margin: 1em 0 1em 0;'>Rows:10000\n",
              "Cols:10\n",
              "</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "         ﻿UDI                Product ID    Type    Air temperature [K]    Process temperature [K]    Rotational speed [rpm]    Torque [Nm]        Tool wear [min]     Target                Failure Type\n",
              "-------  ------------------  ------------  ------  ---------------------  -------------------------  ------------------------  -----------------  ------------------  --------------------  --------------\n",
              "type     int                 string        enum    real                   real                       int                       real               int                 int                   enum\n",
              "mins     1.0                 NaN                   295.3                  305.7                      1168.0                    3.8                0.0                 0.0\n",
              "mean     5000.5              NaN                   300.00493              310.00556                  1538.7761000000003        39.98690999999997  107.95100000000005  0.033900000000000007\n",
              "maxs     10000.0             NaN                   304.5                  313.8                      2886.0                    76.6               253.0               1.0\n",
              "sigma    2886.8956799071675  NaN                   2.0002586829158036     1.4837342191657434         179.2840959134266         9.968933725121339  63.654146636636355  0.18098084265065364\n",
              "zeros    0                   0                     0                      0                          0                         0                  120                 9661\n",
              "missing  0                   0             0       0                      0                          0                         0                  0                   0                     0\n",
              "0        1.0                 M14860        M       298.1                  308.6                      1551.0                    42.8               0.0                 0.0                   No Failure\n",
              "1        2.0                 L47181        L       298.2                  308.7                      1408.0                    46.3               3.0                 0.0                   No Failure\n",
              "2        3.0                 L47182        L       298.1                  308.5                      1498.0                    49.4               5.0                 0.0                   No Failure\n",
              "3        4.0                 L47183        L       298.2                  308.6                      1433.0                    39.5               7.0                 0.0                   No Failure\n",
              "4        5.0                 L47184        L       298.2                  308.7                      1408.0                    40.0               9.0                 0.0                   No Failure\n",
              "5        6.0                 M14865        M       298.1                  308.6                      1425.0                    41.9               11.0                0.0                   No Failure\n",
              "6        7.0                 L47186        L       298.1                  308.6                      1558.0                    42.4               14.0                0.0                   No Failure\n",
              "7        8.0                 L47187        L       298.1                  308.6                      1527.0                    40.2               16.0                0.0                   No Failure\n",
              "8        9.0                 M14868        M       298.3                  308.7                      1667.0                    28.6               18.0                0.0                   No Failure\n",
              "9        10.0                M14869        M       298.5                  309.0                      1741.0                    28.0               21.0                0.0                   No Failure\n",
              "[10000 rows x 10 columns]\n"
            ],
            "text/html": [
              "<table class='dataframe'>\n",
              "<thead>\n",
              "<tr><th>       </th><th>﻿UDI              </th><th>Product ID  </th><th>Type  </th><th>Air temperature [K]  </th><th>Process temperature [K]  </th><th>Rotational speed [rpm]  </th><th>Torque [Nm]      </th><th>Tool wear [min]   </th><th>Target              </th><th>Failure Type  </th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>type   </td><td>int               </td><td>string      </td><td>enum  </td><td>real                 </td><td>real                     </td><td>int                     </td><td>real             </td><td>int               </td><td>int                 </td><td>enum          </td></tr>\n",
              "<tr><td>mins   </td><td>1.0               </td><td>NaN         </td><td>      </td><td>295.3                </td><td>305.7                    </td><td>1168.0                  </td><td>3.8              </td><td>0.0               </td><td>0.0                 </td><td>              </td></tr>\n",
              "<tr><td>mean   </td><td>5000.5            </td><td>NaN         </td><td>      </td><td>300.00493            </td><td>310.00556                </td><td>1538.7761000000003      </td><td>39.98690999999997</td><td>107.95100000000005</td><td>0.033900000000000007</td><td>              </td></tr>\n",
              "<tr><td>maxs   </td><td>10000.0           </td><td>NaN         </td><td>      </td><td>304.5                </td><td>313.8                    </td><td>2886.0                  </td><td>76.6             </td><td>253.0             </td><td>1.0                 </td><td>              </td></tr>\n",
              "<tr><td>sigma  </td><td>2886.8956799071675</td><td>NaN         </td><td>      </td><td>2.0002586829158036   </td><td>1.4837342191657434       </td><td>179.2840959134266       </td><td>9.968933725121339</td><td>63.654146636636355</td><td>0.18098084265065364 </td><td>              </td></tr>\n",
              "<tr><td>zeros  </td><td>0                 </td><td>0           </td><td>      </td><td>0                    </td><td>0                        </td><td>0                       </td><td>0                </td><td>120               </td><td>9661                </td><td>              </td></tr>\n",
              "<tr><td>missing</td><td>0                 </td><td>0           </td><td>0     </td><td>0                    </td><td>0                        </td><td>0                       </td><td>0                </td><td>0                 </td><td>0                   </td><td>0             </td></tr>\n",
              "<tr><td>0      </td><td>1.0               </td><td>M14860      </td><td>M     </td><td>298.1                </td><td>308.6                    </td><td>1551.0                  </td><td>42.8             </td><td>0.0               </td><td>0.0                 </td><td>No Failure    </td></tr>\n",
              "<tr><td>1      </td><td>2.0               </td><td>L47181      </td><td>L     </td><td>298.2                </td><td>308.7                    </td><td>1408.0                  </td><td>46.3             </td><td>3.0               </td><td>0.0                 </td><td>No Failure    </td></tr>\n",
              "<tr><td>2      </td><td>3.0               </td><td>L47182      </td><td>L     </td><td>298.1                </td><td>308.5                    </td><td>1498.0                  </td><td>49.4             </td><td>5.0               </td><td>0.0                 </td><td>No Failure    </td></tr>\n",
              "<tr><td>3      </td><td>4.0               </td><td>L47183      </td><td>L     </td><td>298.2                </td><td>308.6                    </td><td>1433.0                  </td><td>39.5             </td><td>7.0               </td><td>0.0                 </td><td>No Failure    </td></tr>\n",
              "<tr><td>4      </td><td>5.0               </td><td>L47184      </td><td>L     </td><td>298.2                </td><td>308.7                    </td><td>1408.0                  </td><td>40.0             </td><td>9.0               </td><td>0.0                 </td><td>No Failure    </td></tr>\n",
              "<tr><td>5      </td><td>6.0               </td><td>M14865      </td><td>M     </td><td>298.1                </td><td>308.6                    </td><td>1425.0                  </td><td>41.9             </td><td>11.0              </td><td>0.0                 </td><td>No Failure    </td></tr>\n",
              "<tr><td>6      </td><td>7.0               </td><td>L47186      </td><td>L     </td><td>298.1                </td><td>308.6                    </td><td>1558.0                  </td><td>42.4             </td><td>14.0              </td><td>0.0                 </td><td>No Failure    </td></tr>\n",
              "<tr><td>7      </td><td>8.0               </td><td>L47187      </td><td>L     </td><td>298.1                </td><td>308.6                    </td><td>1527.0                  </td><td>40.2             </td><td>16.0              </td><td>0.0                 </td><td>No Failure    </td></tr>\n",
              "<tr><td>8      </td><td>9.0               </td><td>M14868      </td><td>M     </td><td>298.3                </td><td>308.7                    </td><td>1667.0                  </td><td>28.6             </td><td>18.0              </td><td>0.0                 </td><td>No Failure    </td></tr>\n",
              "<tr><td>9      </td><td>10.0              </td><td>M14869      </td><td>M     </td><td>298.5                </td><td>309.0                    </td><td>1741.0                  </td><td>28.0             </td><td>21.0              </td><td>0.0                 </td><td>No Failure    </td></tr>\n",
              "</tbody>\n",
              "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[10000 rows x 10 columns]</pre>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations from above description\n",
        "\n",
        "* `Air Temperature` has a mean of 300K and 75% of data is distributed between 295.3K and 301.5K, seems like a good distribution and may not have outliers.\n",
        "* `Process temperature` has a mean of 310K and maximum data is distributed between 305.7K and 311.1K, looks good and may not have possible outliers.\n",
        "* `Rotational speed` has a mean 1538 and 75% of data is distribbuted between 1168 and 1612 but the maximum value is 2886 and it looks like investigation is needed to understand outliers and it will be discussed further in this notebook.\n",
        "* `Torque` has mean 39.9 , maximum value is 76.6, minimum value is 1168 and median is 40.1 which is slightly left skewed from mean.\n",
        "* `Tool wear` has mean 107.9 and a median(2nd quantile) of 108 which is almost a normal distribution.\n",
        "\n",
        "\n",
        "All the quantile information "
      ],
      "metadata": {
        "id": "LNlhcfDluGhF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pdf = pd.read_csv(\"https://raw.githubusercontent.com/Venkata-Bhargavi/AutoML/main/predictive_maintenance%205.csv\")\n",
        "pdf.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "psHnluEzMU3m",
        "outputId": "75a99b05-c88f-48cd-a3a6-671c80153a87"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   UDI Product ID Type  Air temperature [K]  Process temperature [K]  \\\n",
              "0    1     M14860    M                298.1                    308.6   \n",
              "1    2     L47181    L                298.2                    308.7   \n",
              "2    3     L47182    L                298.1                    308.5   \n",
              "3    4     L47183    L                298.2                    308.6   \n",
              "4    5     L47184    L                298.2                    308.7   \n",
              "\n",
              "   Rotational speed [rpm]  Torque [Nm]  Tool wear [min]  Target Failure Type  \n",
              "0                    1551         42.8                0       0   No Failure  \n",
              "1                    1408         46.3                3       0   No Failure  \n",
              "2                    1498         49.4                5       0   No Failure  \n",
              "3                    1433         39.5                7       0   No Failure  \n",
              "4                    1408         40.0                9       0   No Failure  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-35684e9b-0fe1-4b06-908c-9ca0861bba56\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UDI</th>\n",
              "      <th>Product ID</th>\n",
              "      <th>Type</th>\n",
              "      <th>Air temperature [K]</th>\n",
              "      <th>Process temperature [K]</th>\n",
              "      <th>Rotational speed [rpm]</th>\n",
              "      <th>Torque [Nm]</th>\n",
              "      <th>Tool wear [min]</th>\n",
              "      <th>Target</th>\n",
              "      <th>Failure Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>M14860</td>\n",
              "      <td>M</td>\n",
              "      <td>298.1</td>\n",
              "      <td>308.6</td>\n",
              "      <td>1551</td>\n",
              "      <td>42.8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>No Failure</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>L47181</td>\n",
              "      <td>L</td>\n",
              "      <td>298.2</td>\n",
              "      <td>308.7</td>\n",
              "      <td>1408</td>\n",
              "      <td>46.3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>No Failure</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>L47182</td>\n",
              "      <td>L</td>\n",
              "      <td>298.1</td>\n",
              "      <td>308.5</td>\n",
              "      <td>1498</td>\n",
              "      <td>49.4</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>No Failure</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>L47183</td>\n",
              "      <td>L</td>\n",
              "      <td>298.2</td>\n",
              "      <td>308.6</td>\n",
              "      <td>1433</td>\n",
              "      <td>39.5</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>No Failure</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>L47184</td>\n",
              "      <td>L</td>\n",
              "      <td>298.2</td>\n",
              "      <td>308.7</td>\n",
              "      <td>1408</td>\n",
              "      <td>40.0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>No Failure</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-35684e9b-0fe1-4b06-908c-9ca0861bba56')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-35684e9b-0fe1-4b06-908c-9ca0861bba56 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-35684e9b-0fe1-4b06-908c-9ca0861bba56');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For Data Visualization\n",
        "import numpy as np\n",
        "data_corr = pdf.corr()\n",
        "mask = np.triu(np.ones_like(pdf.corr(), dtype=bool))\n",
        "corr_ft = plt.figure(figsize= (19, 10))\n",
        "corr_ft = sns.heatmap(data_corr, mask=mask,vmin= -1, vmax = 1, annot=True, linewidths= 0.3, cmap= \"BrBG\")\n",
        "corr_ft.set_title(\"The Pearson Correlation between Features\",\n",
        "                   fontsize= 15,\n",
        "                   pad= 12)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "id": "ooUcYhskMb3n",
        "outputId": "efa66afb-0e7c-48d1-c459-8e1255ad7fef"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1368x720 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations\n",
        "- Above heapmap shows that `Air teamperature [k]` and `Process temperature [k]` are highly correlated.\n",
        "- `Torque` has high correlation comparing to other feature with Target\n",
        "- `Torque` and `Rotational speed [Nm]` are negatively correlated i.e if Rotational speed increases then Torque decreases and vice versa.\n",
        "- `Type` has slight correlation with `Rotational speed [Nm]` comparing to other features but it doesn't seem like multi colinearity as the value is very low.\n"
      ],
      "metadata": {
        "id": "1ysZcPkOPaqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Target\"] = df[\"Target\"].asfactor()"
      ],
      "metadata": {
        "id": "aF_CSCjzZhzQ"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting `Target` column to enum as it is given integer but need to classify it"
      ],
      "metadata": {
        "id": "hmcU2myeuJ0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train,test,valid = df.split_frame(ratios=[.7, .15])"
      ],
      "metadata": {
        "id": "dFBlg6-rusPv"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting train test and vailidation into 70:15:15 ratio."
      ],
      "metadata": {
        "id": "F2s8HDlq0OwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = \"Target\"\n",
        "x = df.columns\n",
        "x.remove(y)\n",
        "x.remove(\"Product ID\")\n",
        "x.remove(\"Failure Type\")\n",
        "x.remove(\"\\ufeffUDI\")"
      ],
      "metadata": {
        "id": "1UgMm63pvOFH"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Here the target feature is `Target` for binary classification.\n",
        "- Removing `Product ID`, `Failure Type`, `UDI` as product Id and UDI are just unique identifiers and dont contribute for the analysis\n",
        "- Removing `Failure Type` as it has the failure type information which is similar to target feature and may lead to data leakage"
      ],
      "metadata": {
        "id": "uV3giXm-0YWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aml = H2OAutoML(max_models = 10, seed = 10, exclude_algos = [\"StackedEnsemble\", \"DeepLearning\"], verbosity=\"info\", nfolds=0)\n"
      ],
      "metadata": {
        "id": "la2SFHBI2Kpa"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Excluding StackedEnsemble and DeepLearning as it is more complex at this moment and it is also an expensive process"
      ],
      "metadata": {
        "id": "kOqvzS281RXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !nvidia-smi"
      ],
      "metadata": {
        "id": "BA1VG0937LN2"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aml.train(x = x, y = y, training_frame = train, validation_frame=valid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_9lyaBbs7Nzt",
        "outputId": "4a575120-40ad-4e76-e5f7-5ce19c7a50a3"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AutoML progress: |\n",
            "23:59:41.300: Project: AutoML_3_20221107_235941\n",
            "23:59:41.300: Cross-validation disabled by user: no fold column nor nfolds > 1.\n",
            "23:59:41.300: Setting stopping tolerance adaptively based on the training frame: 0.011958266722236254\n",
            "23:59:41.300: Build control seed: 10\n",
            "23:59:41.301: training frame: Frame key: AutoML_3_20221107_235941_training_py_21_sid_a03f    cols: 10    rows: 6993  chunks: 8    size: 176492  checksum: -7511266214878178940\n",
            "23:59:41.304: validation frame: Frame key: py_23_sid_a03f    cols: 10    rows: 1456  chunks: 8    size: 54308  checksum: -1915476153114142194\n",
            "23:59:41.304: leaderboard frame: Frame key: py_23_sid_a03f    cols: 10    rows: 1456  chunks: 8    size: 54308  checksum: -1915476153114142194\n",
            "23:59:41.304: blending frame: NULL\n",
            "23:59:41.304: response column: Target\n",
            "23:59:41.305: fold column: null\n",
            "23:59:41.305: weights column: null\n",
            "23:59:41.305: Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (7g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (7g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (6g, 60w)]}, {StackedEnsemble : [monotonic (9g, 10w), best_of_family_xglm (10g, 10w), all_xglm (10g, 10w)]}]\n",
            "23:59:41.307: Disabling Algo: DeepLearning as requested by the user.\n",
            "23:59:41.307: Disabling Algo: StackedEnsemble as requested by the user.\n",
            "23:59:41.308: AutoML job created: 2022.11.07 23:59:41.300\n",
            "23:59:41.309: AutoML build started: 2022.11.07 23:59:41.308\n",
            "23:59:41.312: AutoML: starting XGBoost_1_AutoML_3_20221107_235941 model training\n",
            "23:59:46.101: New leader: XGBoost_1_AutoML_3_20221107_235941, auc: 0.9541899517861057\n",
            "23:59:46.103: AutoML: starting GLM_1_AutoML_3_20221107_235941 model training\n",
            "23:59:47.243: AutoML: starting GBM_1_AutoML_3_20221107_235941 model training\n",
            "23:59:51.223: New leader: GBM_1_AutoML_3_20221107_235941, auc: 0.9550049309664694\n",
            "23:59:51.225: AutoML: starting XGBoost_2_AutoML_3_20221107_235941 model training\n",
            "23:59:59.661: AutoML: starting DRF_1_AutoML_3_20221107_235941 model training\n",
            "00:00:01.55: AutoML: starting GBM_2_AutoML_3_20221107_235941 model training\n",
            "00:00:03.335: New leader: GBM_2_AutoML_3_20221107_235941, auc: 0.9681678720140259\n",
            "00:00:03.337: AutoML: starting GBM_3_AutoML_3_20221107_235941 model training\n",
            "00:00:06.658: AutoML: starting GBM_4_AutoML_3_20221107_235941 model training\n",
            "00:00:08.881: AutoML: starting XGBoost_3_AutoML_3_20221107_235941 model training\n",
            "00:00:13.627: AutoML: starting XRT_1_AutoML_3_20221107_235941 model training\n",
            "00:00:15.358: Skipping StackedEnsemble 'monotonic' due to the exclude_algos option or it is already trained.\n",
            "00:00:15.358: Skipping StackedEnsemble 'best_of_family_xglm' due to the exclude_algos option or it is already trained.\n",
            "00:00:15.359: Skipping StackedEnsemble 'all_xglm' due to the exclude_algos option or it is already trained.\n",
            "00:00:15.359: Actual modeling steps: [{XGBoost : [def_2 (1g, 10w)]}, {GLM : [def_1 (1g, 10w)]}, {GBM : [def_5 (1g, 10w)]}, {XGBoost : [def_1 (2g, 10w)]}, {DRF : [def_1 (2g, 10w)]}, {GBM : [def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w)]}, {XGBoost : [def_3 (3g, 10w)]}, {DRF : [XRT (3g, 10w)]}]\n",
            "00:00:15.359: AutoML build stopped: 2022.11.08 00:00:15.359\n",
            "00:00:15.359: AutoML build done: built 10 models\n",
            "00:00:15.360: AutoML duration: 34.051 sec\n",
            "01:24:39.885: Project: AutoML_3_20221107_235941\n",
            "01:24:39.885: Cross-validation disabled by user: no fold column nor nfolds > 1.\n",
            "01:24:39.893: Setting stopping tolerance adaptively based on the training frame: 0.011958266722236254\n",
            "01:24:39.893: Build control seed: 10\n",
            "01:24:39.893: training frame: Frame key: AutoML_4_20221108_12439_training_py_21_sid_a03f    cols: 10    rows: 6993  chunks: 8    size: 176492  checksum: -7511266214878178940\n",
            "01:24:39.894: validation frame: Frame key: py_23_sid_a03f    cols: 10    rows: 1456  chunks: 8    size: 54308  checksum: -1915476153114142194\n",
            "01:24:39.894: leaderboard frame: Frame key: py_23_sid_a03f    cols: 10    rows: 1456  chunks: 8    size: 54308  checksum: -1915476153114142194\n",
            "01:24:39.894: blending frame: NULL\n",
            "01:24:39.894: response column: Target\n",
            "01:24:39.894: fold column: null\n",
            "01:24:39.894: weights column: null\n",
            "01:24:39.895: New models will be added to existing leaderboard AutoML_3_20221107_235941@@Target (leaderboard frame=py_23_sid_a03f) with already 10 models.\n",
            "01:24:39.896: Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (7g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (7g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (6g, 60w)]}, {StackedEnsemble : [monotonic (9g, 10w), best_of_family_xglm (10g, 10w), all_xglm (10g, 10w)]}]\n",
            "01:24:39.899: Disabling Algo: DeepLearning as requested by the user.\n",
            "01:24:39.899: Disabling Algo: StackedEnsemble as requested by the user.\n",
            "01:24:39.899: AutoML job created: 2022.11.08 01:24:39.866\n",
            "01:24:39.904: AutoML build started: 2022.11.08 01:24:39.904\n",
            "01:24:39.926: AutoML: starting XGBoost_4_AutoML_4_20221108_12439 model training\n",
            "\n",
            "█\n",
            "01:24:45.826: AutoML: starting GLM_2_AutoML_4_20221108_12439 model training\n",
            "\n",
            "█\n",
            "01:24:46.707: AutoML: starting GBM_5_AutoML_4_20221108_12439 model training\n",
            "\n",
            "█\n",
            "01:24:49.440: AutoML: starting XGBoost_5_AutoML_4_20221108_12439 model training\n",
            "\n",
            "███\n",
            "01:24:53.431: AutoML: starting DRF_2_AutoML_4_20221108_12439 model training\n",
            "01:24:54.486: AutoML: starting GBM_6_AutoML_4_20221108_12439 model training\n",
            "\n",
            "██\n",
            "01:24:56.493: New leader: GBM_6_AutoML_4_20221108_12439, auc: 0.9681678720140259\n",
            "01:24:56.495: AutoML: starting GBM_7_AutoML_4_20221108_12439 model training\n",
            "\n",
            "██\n",
            "01:24:59.124: AutoML: starting GBM_8_AutoML_4_20221108_12439 model training\n",
            "\n",
            "█\n",
            "01:25:00.779: AutoML: starting XGBoost_6_AutoML_4_20221108_12439 model training\n",
            "\n",
            "██\n",
            "01:25:02.230: AutoML: starting XRT_2_AutoML_4_20221108_12439 model training\n",
            "\n",
            "██████████████████████████████████████████████████| (done) 100%\n",
            "\n",
            "01:25:03.320: Skipping StackedEnsemble 'monotonic' due to the exclude_algos option or it is already trained.\n",
            "01:25:03.320: Skipping StackedEnsemble 'best_of_family_xglm' due to the exclude_algos option or it is already trained.\n",
            "01:25:03.321: Skipping StackedEnsemble 'all_xglm' due to the exclude_algos option or it is already trained.\n",
            "01:25:03.321: Actual modeling steps: [{XGBoost : [def_2 (1g, 10w)]}, {GLM : [def_1 (1g, 10w)]}, {GBM : [def_5 (1g, 10w)]}, {XGBoost : [def_1 (2g, 10w)]}, {DRF : [def_1 (2g, 10w)]}, {GBM : [def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w)]}, {XGBoost : [def_3 (3g, 10w)]}, {DRF : [XRT (3g, 10w)]}]\n",
            "01:25:03.321: AutoML build stopped: 2022.11.08 01:25:03.321\n",
            "01:25:03.321: AutoML build done: built 10 models\n",
            "01:25:03.321: AutoML duration: 23.417 sec\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model Details\n",
              "=============\n",
              "H2OGradientBoostingEstimator : Gradient Boosting Machine\n",
              "Model Key: GBM_6_AutoML_4_20221108_12439\n",
              "\n",
              "\n",
              "Model Summary: \n",
              "    number_of_trees    number_of_internal_trees    model_size_in_bytes    min_depth    max_depth    mean_depth    min_leaves    max_leaves    mean_leaves\n",
              "--  -----------------  --------------------------  ---------------------  -----------  -----------  ------------  ------------  ------------  -------------\n",
              "    80                 80                          37616                  7            7            7             12            72            32.675\n",
              "\n",
              "ModelMetricsBinomial: gbm\n",
              "** Reported on train data. **\n",
              "\n",
              "MSE: 0.0030207200528190826\n",
              "RMSE: 0.054961077616974385\n",
              "LogLoss: 0.015464407200018463\n",
              "Mean Per-Class Error: 0.017173670286515126\n",
              "AUC: 0.9993151891239668\n",
              "AUCPR: 0.9919272319930348\n",
              "Gini: 0.9986303782479335\n",
              "\n",
              "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.29666095801752085\n",
              "       0     1    Error    Rate\n",
              "-----  ----  ---  -------  -------------\n",
              "0      6752  4    0.0006   (4.0/6756.0)\n",
              "1      8     229  0.0338   (8.0/237.0)\n",
              "Total  6760  233  0.0017   (12.0/6993.0)\n",
              "\n",
              "Maximum Metrics: Maximum metrics at their respective thresholds\n",
              "metric                       threshold    value     idx\n",
              "---------------------------  -----------  --------  -----\n",
              "max f1                       0.296661     0.974468  164\n",
              "max f2                       0.219575     0.973154  173\n",
              "max f0point5                 0.386869     0.985977  157\n",
              "max accuracy                 0.309309     0.998284  162\n",
              "max precision                0.998696     1         0\n",
              "max recall                   0.0124605    1         333\n",
              "max specificity              0.998696     1         0\n",
              "max absolute_mcc             0.296661     0.973618  164\n",
              "max min_per_class_accuracy   0.117788     0.991561  206\n",
              "max mean_per_class_accuracy  0.117788     0.991784  206\n",
              "max tns                      0.998696     6756      0\n",
              "max fns                      0.998696     236       0\n",
              "max fps                      0.000319197  6756      399\n",
              "max tps                      0.0124605    237       333\n",
              "max tnr                      0.998696     1         0\n",
              "max fnr                      0.998696     0.995781  0\n",
              "max fpr                      0.000319197  1         399\n",
              "max tpr                      0.0124605    1         333\n",
              "\n",
              "Gains/Lift Table: Avg response rate:  3.39 %, avg score:  3.38 %\n",
              "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
              "-------  --------------------------  -----------------  ---------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
              "1        0.01001                     0.940838           29.5063    29.5063            1                0.972743     1                           0.972743            0.295359        0.295359                   2850.63   2850.63            0.295359\n",
              "2        0.02002                     0.862888           29.5063    29.5063            1                0.907889     1                           0.940316            0.295359        0.590717                   2850.63   2850.63            0.590717\n",
              "3        0.03003                     0.52123            29.5063    29.5063            1                0.75389      1                           0.878174            0.295359        0.886076                   2850.63   2850.63            0.886076\n",
              "4        0.04004                     0.126458           10.1165    24.6589            0.342857         0.258928     0.835714                    0.723363            0.101266        0.987342                   911.646   2365.89            0.980533\n",
              "5        0.0500501                   0.0759899          0.421519   19.8114            0.0142857        0.094287     0.671429                    0.597547            0.00421941      0.991561                   -57.8481  1881.14            0.974539\n",
              "6        0.1001                      0.0194506          0.0843038  9.94785            0.00285714       0.0404474    0.337143                    0.318997            0.00421941      0.995781                   -91.5696  894.785            0.927101\n",
              "7        0.150007                    0.00783495         0.0845454  6.66635            0.00286533       0.0121894    0.225929                    0.216923            0.00421941      1                          -91.5455  566.635            0.879811\n",
              "8        0.200057                    0.00387259         0          4.99857            0                0.00556024   0.169407                    0.164045            0               1                          -100      399.857            0.828005\n",
              "9        0.300014                    0.0020429          0          3.33317            0                0.00274488   0.112965                    0.110304            0               1                          -100      233.317            0.724541\n",
              "10       0.399971                    0.00148469         0          2.50018            0                0.00172867   0.0847336                   0.0831696           0               1                          -100      150.018            0.621078\n",
              "11       0.500072                    0.00114842         0          1.99971            0                0.00130966   0.0677724                   0.0667836           0               1                          -100      99.9714            0.517466\n",
              "12       0.600172                    0.000949113        0          1.66619            0                0.00103435   0.0564689                   0.0558175           0               1                          -100      66.619             0.413854\n",
              "13       0.699986                    0.00083529         0          1.4286             0                0.000885091  0.0484168                   0.0479845           0               1                          -100      42.8601            0.310539\n",
              "14       0.800801                    0.000749023        0          1.24875            0                0.000790914  0.0423214                   0.0420431           0               1                          -100      24.875             0.206187\n",
              "15       0.8999                      0.000644007        0          1.11123            0                0.000699275  0.0376609                   0.0374903           0               1                          -100      11.1235            0.103612\n",
              "16       1                           0.000251342        0          1                  0                0.00051489   0.033891                    0.033789            0               1                          -100      0                  0\n",
              "\n",
              "ModelMetricsBinomial: gbm\n",
              "** Reported on validation data. **\n",
              "\n",
              "MSE: 0.012143755017777197\n",
              "RMSE: 0.11019870696962464\n",
              "LogLoss: 0.05076886190242359\n",
              "Mean Per-Class Error: 0.146011396011396\n",
              "AUC: 0.9681678720140259\n",
              "AUCPR: 0.8184057386168719\n",
              "Gini: 0.9363357440280518\n",
              "\n",
              "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.43833384467054226\n",
              "       0     1    Error    Rate\n",
              "-----  ----  ---  -------  -------------\n",
              "0      1399  5    0.0036   (5.0/1404.0)\n",
              "1      15    37   0.2885   (15.0/52.0)\n",
              "Total  1414  42   0.0137   (20.0/1456.0)\n",
              "\n",
              "Maximum Metrics: Maximum metrics at their respective thresholds\n",
              "metric                       threshold    value     idx\n",
              "---------------------------  -----------  --------  -----\n",
              "max f1                       0.438334     0.787234  40\n",
              "max f2                       0.155975     0.797101  66\n",
              "max f0point5                 0.687081     0.869565  32\n",
              "max accuracy                 0.49897      0.986264  37\n",
              "max precision                0.985851     1         0\n",
              "max recall                   0.000980848  1         360\n",
              "max specificity              0.985851     1         0\n",
              "max absolute_mcc             0.438334     0.784974  40\n",
              "max min_per_class_accuracy   0.0298728    0.923077  143\n",
              "max mean_per_class_accuracy  0.0583284    0.932336  99\n",
              "max tns                      0.985851     1404      0\n",
              "max fns                      0.985851     51        0\n",
              "max fps                      0.000260583  1404      399\n",
              "max tps                      0.000980848  52        360\n",
              "max tnr                      0.985851     1         0\n",
              "max fnr                      0.985851     0.980769  0\n",
              "max fpr                      0.000260583  1         399\n",
              "max tpr                      0.000980848  1         360\n",
              "\n",
              "Gains/Lift Table: Avg response rate:  3.57 %, avg score:  3.26 %\n",
              "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
              "-------  --------------------------  -----------------  --------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
              "1        0.0103022                   0.906607           26.1333   26.1333            0.933333         0.941874     0.933333                    0.941874            0.269231        0.269231                   2513.33   2513.33            0.268519\n",
              "2        0.0206044                   0.70814            28        27.0667            1                0.821938     0.966667                    0.881906            0.288462        0.557692                   2700      2606.67            0.55698\n",
              "3        0.0302198                   0.401783           16        23.5455            0.571429         0.54721      0.840909                    0.775412            0.153846        0.711538                   1500      2254.55            0.706553\n",
              "4        0.040522                    0.194102           7.46667   19.4576            0.266667         0.279656     0.694915                    0.649372            0.0769231       0.788462                   646.667   1845.76            0.775641\n",
              "5        0.0501374                   0.109413           6         16.8767            0.214286         0.156318     0.60274                     0.554814            0.0576923       0.846154                   500       1587.67            0.825499\n",
              "6        0.100275                    0.0295479          1.53425   9.20548            0.0547945        0.0534366    0.328767                    0.304125            0.0769231       0.923077                   53.4247   820.548            0.853276\n",
              "7        0.150412                    0.00880222         0.383562  6.26484            0.0136986        0.0159302    0.223744                    0.20806             0.0192308       0.942308                   -61.6438  526.484            0.821225\n",
              "8        0.200549                    0.00433098         0         4.69863            0                0.00637191   0.167808                    0.157638            0               0.942308                   -100      369.863            0.769231\n",
              "9        0.300137                    0.00215517         0.193103  3.20366            0.00689655       0.0029295    0.114416                    0.106305            0.0192308       0.961538                   -80.6897  220.366            0.685897\n",
              "10       0.400412                    0.00154344         0         2.40137            0                0.00182138   0.0857633                   0.080139            0               0.961538                   -100      140.137            0.581909\n",
              "11       0.5                         0.0011701          0.193103  1.96154            0.00689655       0.0013422    0.0700549                   0.0644446           0.0192308       0.980769                   -80.6897  96.1538            0.498575\n",
              "12       0.600275                    0.00097206         0.191781  1.6659             0.00684932       0.00106262   0.0594966                   0.0538567           0.0192308       1                          -80.8219  66.5904            0.41453\n",
              "13       0.699863                    0.000836412        0         1.42885            0                0.000897474  0.0510304                   0.0463208           0               1                          -100      42.8852            0.311254\n",
              "14       0.800137                    0.000749022        0         1.24979            0                0.000792182  0.0446352                   0.0406151           0               1                          -100      24.9785            0.207265\n",
              "15       0.899725                    0.000667155        0         1.11145            0                0.000708039  0.0396947                   0.0361979           0               1                          -100      11.145             0.103989\n",
              "16       1                           0.000247547        0         1                  0                0.000554079  0.0357143                   0.0326237           0               1                          -100      0                  0\n",
              "\n",
              "Scoring History: \n",
              "    timestamp            duration    number_of_trees    training_rmse    training_logloss    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_auc    validation_pr_auc    validation_lift    validation_classification_error\n",
              "--  -------------------  ----------  -----------------  ---------------  ------------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ----------------  -------------------  -----------------  ---------------------------------\n",
              "    2022-11-08 01:24:54  0.003 sec   0                  0.180949         0.148018            0.5             0.033891           1                0.966109                         0.185586           0.154126              0.5               0.0357143            1                  0.964286\n",
              "    2022-11-08 01:24:54  0.098 sec   5                  0.139306         0.078639            0.982192        0.839207           28.3715          0.014872                         0.154986           0.0943287             0.953019          0.675375             24.2667            0.0206044\n",
              "    2022-11-08 01:24:54  0.216 sec   10                 0.119629         0.0596727           0.989669        0.895956           29.0848          0.010296                         0.141306           0.0785943             0.957395          0.744593             26.1333            0.018544\n",
              "    2022-11-08 01:24:54  0.340 sec   15                 0.104879         0.0475412           0.991948        0.921171           29.5063          0.00843701                       0.129362           0.0673861             0.959402          0.781276             26.1333            0.0151099\n",
              "    2022-11-08 01:24:54  0.468 sec   20                 0.0961483        0.0407277           0.992914        0.931446           29.5063          0.00772201                       0.124021           0.0620597             0.958292          0.790209             26.1333            0.0164835\n",
              "    2022-11-08 01:24:55  0.586 sec   25                 0.0881069        0.0352555           0.993327        0.947863           29.5063          0.00686401                       0.119697           0.0581635             0.960299          0.802045             26.1333            0.0164835\n",
              "    2022-11-08 01:24:55  0.698 sec   30                 0.0827489        0.0315937           0.994437        0.956807           29.5063          0.00614901                       0.117551           0.0563102             0.958443          0.796632             26.1333            0.0137363\n",
              "    2022-11-08 01:24:55  0.858 sec   35                 0.0784556        0.0287119           0.995547        0.96399            29.5063          0.00529101                       0.115416           0.0545359             0.956197          0.800756             26.1333            0.0137363\n",
              "    2022-11-08 01:24:55  0.983 sec   40                 0.074317         0.0260227           0.996192        0.970832           29.5063          0.004719                         0.114301           0.0536017             0.956327          0.816309             26.1333            0.0137363\n",
              "    2022-11-08 01:24:55  1.088 sec   45                 0.0706416        0.0239411           0.996428        0.973215           29.5063          0.004147                         0.112185           0.0521488             0.955875          0.825124             26.1333            0.0151099\n",
              "    2022-11-08 01:24:55  1.226 sec   50                 0.0685663        0.0226603           0.997118        0.975755           29.5063          0.003861                         0.112093           0.0521302             0.955779          0.813266             26.1333            0.0151099\n",
              "    2022-11-08 01:24:55  1.311 sec   55                 0.0659316        0.0213575           0.997267        0.978837           29.5063          0.003432                         0.110894           0.0515135             0.956347          0.807698             26.1333            0.0157967\n",
              "    2022-11-08 01:24:55  1.428 sec   60                 0.0635476        0.0201857           0.997316        0.980354           29.5063          0.003003                         0.110417           0.0509809             0.957313          0.81881              26.1333            0.0151099\n",
              "    2022-11-08 01:24:56  1.555 sec   65                 0.0618342        0.0193495           0.997404        0.981389           29.5063          0.00286                          0.109729           0.0505648             0.958847          0.821877             26.1333            0.0130495\n",
              "    2022-11-08 01:24:56  1.689 sec   70                 0.0597051        0.0180078           0.998007        0.98622            29.5063          0.002574                         0.110027           0.0508048             0.960792          0.819833             26.1333            0.0130495\n",
              "    2022-11-08 01:24:56  1.806 sec   75                 0.0575338        0.0166085           0.999159        0.989882           29.5063          0.002002                         0.109764           0.0507182             0.96475           0.821985             26.1333            0.0137363\n",
              "    2022-11-08 01:24:56  1.918 sec   80                 0.0549611        0.0154644           0.999315        0.991927           29.5063          0.001716                         0.110199           0.0507689             0.968168          0.818406             26.1333            0.0137363\n",
              "\n",
              "Variable Importances: \n",
              "variable                 relative_importance    scaled_importance    percentage\n",
              "-----------------------  ---------------------  -------------------  ------------\n",
              "Torque [Nm]              264.416                1                    0.410175\n",
              "Tool wear [min]          117.481                0.444301             0.182241\n",
              "Air temperature [K]      90.9836                0.344092             0.141138\n",
              "Rotational speed [rpm]   83.9354                0.317437             0.130205\n",
              "Process temperature [K]  77.4207                0.292799             0.120099\n",
              "Type                     10.4059                0.0393544            0.0161422\n",
              "\n",
              "[tips]\n",
              "Use `model.explain()` to inspect the model.\n",
              "--\n",
              "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
            ],
            "text/html": [
              "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
              "=============\n",
              "H2OGradientBoostingEstimator : Gradient Boosting Machine\n",
              "Model Key: GBM_6_AutoML_4_20221108_12439\n",
              "</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-134.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-134 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-134 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-134 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-134 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-134 .h2o-table th,\n",
              "#h2o-table-134 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-134 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-134\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Model Summary: </caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>number_of_trees</th>\n",
              "<th>number_of_internal_trees</th>\n",
              "<th>model_size_in_bytes</th>\n",
              "<th>min_depth</th>\n",
              "<th>max_depth</th>\n",
              "<th>mean_depth</th>\n",
              "<th>min_leaves</th>\n",
              "<th>max_leaves</th>\n",
              "<th>mean_leaves</th></tr></thead>\n",
              "    <tbody><tr><td></td>\n",
              "<td>80.0</td>\n",
              "<td>80.0</td>\n",
              "<td>37616.0</td>\n",
              "<td>7.0</td>\n",
              "<td>7.0</td>\n",
              "<td>7.0</td>\n",
              "<td>12.0</td>\n",
              "<td>72.0</td>\n",
              "<td>32.675</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: gbm\n",
              "** Reported on train data. **\n",
              "\n",
              "MSE: 0.0030207200528190826\n",
              "RMSE: 0.054961077616974385\n",
              "LogLoss: 0.015464407200018463\n",
              "Mean Per-Class Error: 0.017173670286515126\n",
              "AUC: 0.9993151891239668\n",
              "AUCPR: 0.9919272319930348\n",
              "Gini: 0.9986303782479335</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-135.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-135 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-135 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-135 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-135 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-135 .h2o-table th,\n",
              "#h2o-table-135 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-135 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-135\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.29666095801752085</caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>0</th>\n",
              "<th>1</th>\n",
              "<th>Error</th>\n",
              "<th>Rate</th></tr></thead>\n",
              "    <tbody><tr><td>0</td>\n",
              "<td>6752.0</td>\n",
              "<td>4.0</td>\n",
              "<td>0.0006</td>\n",
              "<td> (4.0/6756.0)</td></tr>\n",
              "<tr><td>1</td>\n",
              "<td>8.0</td>\n",
              "<td>229.0</td>\n",
              "<td>0.0338</td>\n",
              "<td> (8.0/237.0)</td></tr>\n",
              "<tr><td>Total</td>\n",
              "<td>6760.0</td>\n",
              "<td>233.0</td>\n",
              "<td>0.0017</td>\n",
              "<td> (12.0/6993.0)</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-136.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-136 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-136 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-136 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-136 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-136 .h2o-table th,\n",
              "#h2o-table-136 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-136 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-136\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
              "    <thead><tr><th>metric</th>\n",
              "<th>threshold</th>\n",
              "<th>value</th>\n",
              "<th>idx</th></tr></thead>\n",
              "    <tbody><tr><td>max f1</td>\n",
              "<td>0.2966610</td>\n",
              "<td>0.9744681</td>\n",
              "<td>164.0</td></tr>\n",
              "<tr><td>max f2</td>\n",
              "<td>0.2195754</td>\n",
              "<td>0.9731544</td>\n",
              "<td>173.0</td></tr>\n",
              "<tr><td>max f0point5</td>\n",
              "<td>0.3868691</td>\n",
              "<td>0.9859772</td>\n",
              "<td>157.0</td></tr>\n",
              "<tr><td>max accuracy</td>\n",
              "<td>0.3093085</td>\n",
              "<td>0.9982840</td>\n",
              "<td>162.0</td></tr>\n",
              "<tr><td>max precision</td>\n",
              "<td>0.9986962</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max recall</td>\n",
              "<td>0.0124605</td>\n",
              "<td>1.0</td>\n",
              "<td>333.0</td></tr>\n",
              "<tr><td>max specificity</td>\n",
              "<td>0.9986962</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max absolute_mcc</td>\n",
              "<td>0.2966610</td>\n",
              "<td>0.9736181</td>\n",
              "<td>164.0</td></tr>\n",
              "<tr><td>max min_per_class_accuracy</td>\n",
              "<td>0.1177878</td>\n",
              "<td>0.9915612</td>\n",
              "<td>206.0</td></tr>\n",
              "<tr><td>max mean_per_class_accuracy</td>\n",
              "<td>0.1177878</td>\n",
              "<td>0.9917841</td>\n",
              "<td>206.0</td></tr>\n",
              "<tr><td>max tns</td>\n",
              "<td>0.9986962</td>\n",
              "<td>6756.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fns</td>\n",
              "<td>0.9986962</td>\n",
              "<td>236.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fps</td>\n",
              "<td>0.0003192</td>\n",
              "<td>6756.0</td>\n",
              "<td>399.0</td></tr>\n",
              "<tr><td>max tps</td>\n",
              "<td>0.0124605</td>\n",
              "<td>237.0</td>\n",
              "<td>333.0</td></tr>\n",
              "<tr><td>max tnr</td>\n",
              "<td>0.9986962</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fnr</td>\n",
              "<td>0.9986962</td>\n",
              "<td>0.9957806</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fpr</td>\n",
              "<td>0.0003192</td>\n",
              "<td>1.0</td>\n",
              "<td>399.0</td></tr>\n",
              "<tr><td>max tpr</td>\n",
              "<td>0.0124605</td>\n",
              "<td>1.0</td>\n",
              "<td>333.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-137.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-137 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-137 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-137 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-137 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-137 .h2o-table th,\n",
              "#h2o-table-137 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-137 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-137\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Gains/Lift Table: Avg response rate:  3.39 %, avg score:  3.38 %</caption>\n",
              "    <thead><tr><th>group</th>\n",
              "<th>cumulative_data_fraction</th>\n",
              "<th>lower_threshold</th>\n",
              "<th>lift</th>\n",
              "<th>cumulative_lift</th>\n",
              "<th>response_rate</th>\n",
              "<th>score</th>\n",
              "<th>cumulative_response_rate</th>\n",
              "<th>cumulative_score</th>\n",
              "<th>capture_rate</th>\n",
              "<th>cumulative_capture_rate</th>\n",
              "<th>gain</th>\n",
              "<th>cumulative_gain</th>\n",
              "<th>kolmogorov_smirnov</th></tr></thead>\n",
              "    <tbody><tr><td>1</td>\n",
              "<td>0.0100100</td>\n",
              "<td>0.9408383</td>\n",
              "<td>29.5063291</td>\n",
              "<td>29.5063291</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9727429</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9727429</td>\n",
              "<td>0.2953586</td>\n",
              "<td>0.2953586</td>\n",
              "<td>2850.6329114</td>\n",
              "<td>2850.6329114</td>\n",
              "<td>0.2953586</td></tr>\n",
              "<tr><td>2</td>\n",
              "<td>0.0200200</td>\n",
              "<td>0.8628880</td>\n",
              "<td>29.5063291</td>\n",
              "<td>29.5063291</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9078892</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9403161</td>\n",
              "<td>0.2953586</td>\n",
              "<td>0.5907173</td>\n",
              "<td>2850.6329114</td>\n",
              "<td>2850.6329114</td>\n",
              "<td>0.5907173</td></tr>\n",
              "<tr><td>3</td>\n",
              "<td>0.0300300</td>\n",
              "<td>0.5212295</td>\n",
              "<td>29.5063291</td>\n",
              "<td>29.5063291</td>\n",
              "<td>1.0</td>\n",
              "<td>0.7538898</td>\n",
              "<td>1.0</td>\n",
              "<td>0.8781740</td>\n",
              "<td>0.2953586</td>\n",
              "<td>0.8860759</td>\n",
              "<td>2850.6329114</td>\n",
              "<td>2850.6329114</td>\n",
              "<td>0.8860759</td></tr>\n",
              "<tr><td>4</td>\n",
              "<td>0.0400400</td>\n",
              "<td>0.1264582</td>\n",
              "<td>10.1164557</td>\n",
              "<td>24.6588608</td>\n",
              "<td>0.3428571</td>\n",
              "<td>0.2589282</td>\n",
              "<td>0.8357143</td>\n",
              "<td>0.7233625</td>\n",
              "<td>0.1012658</td>\n",
              "<td>0.9873418</td>\n",
              "<td>911.6455696</td>\n",
              "<td>2365.8860759</td>\n",
              "<td>0.9805330</td></tr>\n",
              "<tr><td>5</td>\n",
              "<td>0.0500501</td>\n",
              "<td>0.0759899</td>\n",
              "<td>0.4215190</td>\n",
              "<td>19.8113924</td>\n",
              "<td>0.0142857</td>\n",
              "<td>0.0942870</td>\n",
              "<td>0.6714286</td>\n",
              "<td>0.5975474</td>\n",
              "<td>0.0042194</td>\n",
              "<td>0.9915612</td>\n",
              "<td>-57.8481013</td>\n",
              "<td>1881.1392405</td>\n",
              "<td>0.9745393</td></tr>\n",
              "<tr><td>6</td>\n",
              "<td>0.1001001</td>\n",
              "<td>0.0194506</td>\n",
              "<td>0.0843038</td>\n",
              "<td>9.9478481</td>\n",
              "<td>0.0028571</td>\n",
              "<td>0.0404474</td>\n",
              "<td>0.3371429</td>\n",
              "<td>0.3189974</td>\n",
              "<td>0.0042194</td>\n",
              "<td>0.9957806</td>\n",
              "<td>-91.5696203</td>\n",
              "<td>894.7848101</td>\n",
              "<td>0.9271009</td></tr>\n",
              "<tr><td>7</td>\n",
              "<td>0.1500072</td>\n",
              "<td>0.0078349</td>\n",
              "<td>0.0845454</td>\n",
              "<td>6.6663489</td>\n",
              "<td>0.0028653</td>\n",
              "<td>0.0121894</td>\n",
              "<td>0.2259295</td>\n",
              "<td>0.2169231</td>\n",
              "<td>0.0042194</td>\n",
              "<td>1.0</td>\n",
              "<td>-91.5454644</td>\n",
              "<td>566.6348904</td>\n",
              "<td>0.8798105</td></tr>\n",
              "<tr><td>8</td>\n",
              "<td>0.2000572</td>\n",
              "<td>0.0038726</td>\n",
              "<td>0.0</td>\n",
              "<td>4.9985704</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0055602</td>\n",
              "<td>0.1694067</td>\n",
              "<td>0.1640446</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>399.8570407</td>\n",
              "<td>0.8280047</td></tr>\n",
              "<tr><td>9</td>\n",
              "<td>0.3000143</td>\n",
              "<td>0.0020429</td>\n",
              "<td>0.0</td>\n",
              "<td>3.3331745</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0027449</td>\n",
              "<td>0.1129647</td>\n",
              "<td>0.1103036</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>233.3174452</td>\n",
              "<td>0.7245411</td></tr>\n",
              "<tr><td>10</td>\n",
              "<td>0.3999714</td>\n",
              "<td>0.0014847</td>\n",
              "<td>0.0</td>\n",
              "<td>2.5001788</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0017287</td>\n",
              "<td>0.0847336</td>\n",
              "<td>0.0831696</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>150.0178763</td>\n",
              "<td>0.6210776</td></tr>\n",
              "<tr><td>11</td>\n",
              "<td>0.5000715</td>\n",
              "<td>0.0011484</td>\n",
              "<td>0.0</td>\n",
              "<td>1.9997140</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0013097</td>\n",
              "<td>0.0677724</td>\n",
              "<td>0.0667836</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>99.9714041</td>\n",
              "<td>0.5174660</td></tr>\n",
              "<tr><td>12</td>\n",
              "<td>0.6001716</td>\n",
              "<td>0.0009491</td>\n",
              "<td>0.0</td>\n",
              "<td>1.6661901</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0010343</td>\n",
              "<td>0.0564689</td>\n",
              "<td>0.0558175</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>66.6190136</td>\n",
              "<td>0.4138544</td></tr>\n",
              "<tr><td>13</td>\n",
              "<td>0.6999857</td>\n",
              "<td>0.0008353</td>\n",
              "<td>0.0</td>\n",
              "<td>1.4286006</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0008851</td>\n",
              "<td>0.0484168</td>\n",
              "<td>0.0479845</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>42.8600613</td>\n",
              "<td>0.3105388</td></tr>\n",
              "<tr><td>14</td>\n",
              "<td>0.8008008</td>\n",
              "<td>0.0007490</td>\n",
              "<td>0.0</td>\n",
              "<td>1.24875</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0007909</td>\n",
              "<td>0.0423214</td>\n",
              "<td>0.0420431</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>24.8750000</td>\n",
              "<td>0.2061871</td></tr>\n",
              "<tr><td>15</td>\n",
              "<td>0.8998999</td>\n",
              "<td>0.0006440</td>\n",
              "<td>0.0</td>\n",
              "<td>1.1112347</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0006993</td>\n",
              "<td>0.0376609</td>\n",
              "<td>0.0374903</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>11.1234705</td>\n",
              "<td>0.1036116</td></tr>\n",
              "<tr><td>16</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0002513</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0005149</td>\n",
              "<td>0.0338910</td>\n",
              "<td>0.0337890</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div></div>\n",
              "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: gbm\n",
              "** Reported on validation data. **\n",
              "\n",
              "MSE: 0.012143755017777197\n",
              "RMSE: 0.11019870696962464\n",
              "LogLoss: 0.05076886190242359\n",
              "Mean Per-Class Error: 0.146011396011396\n",
              "AUC: 0.9681678720140259\n",
              "AUCPR: 0.8184057386168719\n",
              "Gini: 0.9363357440280518</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-138.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-138 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-138 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-138 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-138 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-138 .h2o-table th,\n",
              "#h2o-table-138 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-138 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-138\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.43833384467054226</caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>0</th>\n",
              "<th>1</th>\n",
              "<th>Error</th>\n",
              "<th>Rate</th></tr></thead>\n",
              "    <tbody><tr><td>0</td>\n",
              "<td>1399.0</td>\n",
              "<td>5.0</td>\n",
              "<td>0.0036</td>\n",
              "<td> (5.0/1404.0)</td></tr>\n",
              "<tr><td>1</td>\n",
              "<td>15.0</td>\n",
              "<td>37.0</td>\n",
              "<td>0.2885</td>\n",
              "<td> (15.0/52.0)</td></tr>\n",
              "<tr><td>Total</td>\n",
              "<td>1414.0</td>\n",
              "<td>42.0</td>\n",
              "<td>0.0137</td>\n",
              "<td> (20.0/1456.0)</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-139.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-139 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-139 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-139 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-139 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-139 .h2o-table th,\n",
              "#h2o-table-139 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-139 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-139\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
              "    <thead><tr><th>metric</th>\n",
              "<th>threshold</th>\n",
              "<th>value</th>\n",
              "<th>idx</th></tr></thead>\n",
              "    <tbody><tr><td>max f1</td>\n",
              "<td>0.4383338</td>\n",
              "<td>0.7872340</td>\n",
              "<td>40.0</td></tr>\n",
              "<tr><td>max f2</td>\n",
              "<td>0.1559755</td>\n",
              "<td>0.7971014</td>\n",
              "<td>66.0</td></tr>\n",
              "<tr><td>max f0point5</td>\n",
              "<td>0.6870812</td>\n",
              "<td>0.8695652</td>\n",
              "<td>32.0</td></tr>\n",
              "<tr><td>max accuracy</td>\n",
              "<td>0.4989703</td>\n",
              "<td>0.9862637</td>\n",
              "<td>37.0</td></tr>\n",
              "<tr><td>max precision</td>\n",
              "<td>0.9858514</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max recall</td>\n",
              "<td>0.0009808</td>\n",
              "<td>1.0</td>\n",
              "<td>360.0</td></tr>\n",
              "<tr><td>max specificity</td>\n",
              "<td>0.9858514</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max absolute_mcc</td>\n",
              "<td>0.4383338</td>\n",
              "<td>0.7849738</td>\n",
              "<td>40.0</td></tr>\n",
              "<tr><td>max min_per_class_accuracy</td>\n",
              "<td>0.0298728</td>\n",
              "<td>0.9230769</td>\n",
              "<td>143.0</td></tr>\n",
              "<tr><td>max mean_per_class_accuracy</td>\n",
              "<td>0.0583284</td>\n",
              "<td>0.9323362</td>\n",
              "<td>99.0</td></tr>\n",
              "<tr><td>max tns</td>\n",
              "<td>0.9858514</td>\n",
              "<td>1404.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fns</td>\n",
              "<td>0.9858514</td>\n",
              "<td>51.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fps</td>\n",
              "<td>0.0002606</td>\n",
              "<td>1404.0</td>\n",
              "<td>399.0</td></tr>\n",
              "<tr><td>max tps</td>\n",
              "<td>0.0009808</td>\n",
              "<td>52.0</td>\n",
              "<td>360.0</td></tr>\n",
              "<tr><td>max tnr</td>\n",
              "<td>0.9858514</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fnr</td>\n",
              "<td>0.9858514</td>\n",
              "<td>0.9807692</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fpr</td>\n",
              "<td>0.0002606</td>\n",
              "<td>1.0</td>\n",
              "<td>399.0</td></tr>\n",
              "<tr><td>max tpr</td>\n",
              "<td>0.0009808</td>\n",
              "<td>1.0</td>\n",
              "<td>360.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-140.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-140 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-140 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-140 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-140 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-140 .h2o-table th,\n",
              "#h2o-table-140 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-140 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-140\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Gains/Lift Table: Avg response rate:  3.57 %, avg score:  3.26 %</caption>\n",
              "    <thead><tr><th>group</th>\n",
              "<th>cumulative_data_fraction</th>\n",
              "<th>lower_threshold</th>\n",
              "<th>lift</th>\n",
              "<th>cumulative_lift</th>\n",
              "<th>response_rate</th>\n",
              "<th>score</th>\n",
              "<th>cumulative_response_rate</th>\n",
              "<th>cumulative_score</th>\n",
              "<th>capture_rate</th>\n",
              "<th>cumulative_capture_rate</th>\n",
              "<th>gain</th>\n",
              "<th>cumulative_gain</th>\n",
              "<th>kolmogorov_smirnov</th></tr></thead>\n",
              "    <tbody><tr><td>1</td>\n",
              "<td>0.0103022</td>\n",
              "<td>0.9066070</td>\n",
              "<td>26.1333333</td>\n",
              "<td>26.1333333</td>\n",
              "<td>0.9333333</td>\n",
              "<td>0.9418743</td>\n",
              "<td>0.9333333</td>\n",
              "<td>0.9418743</td>\n",
              "<td>0.2692308</td>\n",
              "<td>0.2692308</td>\n",
              "<td>2513.3333333</td>\n",
              "<td>2513.3333333</td>\n",
              "<td>0.2685185</td></tr>\n",
              "<tr><td>2</td>\n",
              "<td>0.0206044</td>\n",
              "<td>0.7081395</td>\n",
              "<td>28.0</td>\n",
              "<td>27.0666667</td>\n",
              "<td>1.0</td>\n",
              "<td>0.8219382</td>\n",
              "<td>0.9666667</td>\n",
              "<td>0.8819062</td>\n",
              "<td>0.2884615</td>\n",
              "<td>0.5576923</td>\n",
              "<td>2700.0</td>\n",
              "<td>2606.6666667</td>\n",
              "<td>0.5569801</td></tr>\n",
              "<tr><td>3</td>\n",
              "<td>0.0302198</td>\n",
              "<td>0.4017825</td>\n",
              "<td>16.0</td>\n",
              "<td>23.5454545</td>\n",
              "<td>0.5714286</td>\n",
              "<td>0.5472096</td>\n",
              "<td>0.8409091</td>\n",
              "<td>0.7754119</td>\n",
              "<td>0.1538462</td>\n",
              "<td>0.7115385</td>\n",
              "<td>1500.0</td>\n",
              "<td>2254.5454545</td>\n",
              "<td>0.7065527</td></tr>\n",
              "<tr><td>4</td>\n",
              "<td>0.0405220</td>\n",
              "<td>0.1941016</td>\n",
              "<td>7.4666667</td>\n",
              "<td>19.4576271</td>\n",
              "<td>0.2666667</td>\n",
              "<td>0.2796559</td>\n",
              "<td>0.6949153</td>\n",
              "<td>0.6493722</td>\n",
              "<td>0.0769231</td>\n",
              "<td>0.7884615</td>\n",
              "<td>646.6666667</td>\n",
              "<td>1845.7627119</td>\n",
              "<td>0.7756410</td></tr>\n",
              "<tr><td>5</td>\n",
              "<td>0.0501374</td>\n",
              "<td>0.1094129</td>\n",
              "<td>6.0</td>\n",
              "<td>16.8767123</td>\n",
              "<td>0.2142857</td>\n",
              "<td>0.1563179</td>\n",
              "<td>0.6027397</td>\n",
              "<td>0.5548138</td>\n",
              "<td>0.0576923</td>\n",
              "<td>0.8461538</td>\n",
              "<td>500.0</td>\n",
              "<td>1587.6712329</td>\n",
              "<td>0.8254986</td></tr>\n",
              "<tr><td>6</td>\n",
              "<td>0.1002747</td>\n",
              "<td>0.0295479</td>\n",
              "<td>1.5342466</td>\n",
              "<td>9.2054795</td>\n",
              "<td>0.0547945</td>\n",
              "<td>0.0534366</td>\n",
              "<td>0.3287671</td>\n",
              "<td>0.3041252</td>\n",
              "<td>0.0769231</td>\n",
              "<td>0.9230769</td>\n",
              "<td>53.4246575</td>\n",
              "<td>820.5479452</td>\n",
              "<td>0.8532764</td></tr>\n",
              "<tr><td>7</td>\n",
              "<td>0.1504121</td>\n",
              "<td>0.0088022</td>\n",
              "<td>0.3835616</td>\n",
              "<td>6.2648402</td>\n",
              "<td>0.0136986</td>\n",
              "<td>0.0159302</td>\n",
              "<td>0.2237443</td>\n",
              "<td>0.2080602</td>\n",
              "<td>0.0192308</td>\n",
              "<td>0.9423077</td>\n",
              "<td>-61.6438356</td>\n",
              "<td>526.4840183</td>\n",
              "<td>0.8212251</td></tr>\n",
              "<tr><td>8</td>\n",
              "<td>0.2005495</td>\n",
              "<td>0.0043310</td>\n",
              "<td>0.0</td>\n",
              "<td>4.6986301</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0063719</td>\n",
              "<td>0.1678082</td>\n",
              "<td>0.1576381</td>\n",
              "<td>0.0</td>\n",
              "<td>0.9423077</td>\n",
              "<td>-100.0</td>\n",
              "<td>369.8630137</td>\n",
              "<td>0.7692308</td></tr>\n",
              "<tr><td>9</td>\n",
              "<td>0.3001374</td>\n",
              "<td>0.0021552</td>\n",
              "<td>0.1931034</td>\n",
              "<td>3.2036613</td>\n",
              "<td>0.0068966</td>\n",
              "<td>0.0029295</td>\n",
              "<td>0.1144165</td>\n",
              "<td>0.1063046</td>\n",
              "<td>0.0192308</td>\n",
              "<td>0.9615385</td>\n",
              "<td>-80.6896552</td>\n",
              "<td>220.3661327</td>\n",
              "<td>0.6858974</td></tr>\n",
              "<tr><td>10</td>\n",
              "<td>0.4004121</td>\n",
              "<td>0.0015434</td>\n",
              "<td>0.0</td>\n",
              "<td>2.4013722</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0018214</td>\n",
              "<td>0.0857633</td>\n",
              "<td>0.0801390</td>\n",
              "<td>0.0</td>\n",
              "<td>0.9615385</td>\n",
              "<td>-100.0</td>\n",
              "<td>140.1372213</td>\n",
              "<td>0.5819088</td></tr>\n",
              "<tr><td>11</td>\n",
              "<td>0.5</td>\n",
              "<td>0.0011701</td>\n",
              "<td>0.1931034</td>\n",
              "<td>1.9615385</td>\n",
              "<td>0.0068966</td>\n",
              "<td>0.0013422</td>\n",
              "<td>0.0700549</td>\n",
              "<td>0.0644446</td>\n",
              "<td>0.0192308</td>\n",
              "<td>0.9807692</td>\n",
              "<td>-80.6896552</td>\n",
              "<td>96.1538462</td>\n",
              "<td>0.4985755</td></tr>\n",
              "<tr><td>12</td>\n",
              "<td>0.6002747</td>\n",
              "<td>0.0009721</td>\n",
              "<td>0.1917808</td>\n",
              "<td>1.6659039</td>\n",
              "<td>0.0068493</td>\n",
              "<td>0.0010626</td>\n",
              "<td>0.0594966</td>\n",
              "<td>0.0538567</td>\n",
              "<td>0.0192308</td>\n",
              "<td>1.0</td>\n",
              "<td>-80.8219178</td>\n",
              "<td>66.5903890</td>\n",
              "<td>0.4145299</td></tr>\n",
              "<tr><td>13</td>\n",
              "<td>0.6998626</td>\n",
              "<td>0.0008364</td>\n",
              "<td>0.0</td>\n",
              "<td>1.4288518</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0008975</td>\n",
              "<td>0.0510304</td>\n",
              "<td>0.0463208</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>42.8851816</td>\n",
              "<td>0.3112536</td></tr>\n",
              "<tr><td>14</td>\n",
              "<td>0.8001374</td>\n",
              "<td>0.0007490</td>\n",
              "<td>0.0</td>\n",
              "<td>1.2497854</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0007922</td>\n",
              "<td>0.0446352</td>\n",
              "<td>0.0406151</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>24.9785408</td>\n",
              "<td>0.2072650</td></tr>\n",
              "<tr><td>15</td>\n",
              "<td>0.8997253</td>\n",
              "<td>0.0006672</td>\n",
              "<td>0.0</td>\n",
              "<td>1.1114504</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0007080</td>\n",
              "<td>0.0396947</td>\n",
              "<td>0.0361979</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>11.1450382</td>\n",
              "<td>0.1039886</td></tr>\n",
              "<tr><td>16</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0002475</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0005541</td>\n",
              "<td>0.0357143</td>\n",
              "<td>0.0326237</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div></div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-141.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-141 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-141 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-141 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-141 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-141 .h2o-table th,\n",
              "#h2o-table-141 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-141 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-141\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Scoring History: </caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>timestamp</th>\n",
              "<th>duration</th>\n",
              "<th>number_of_trees</th>\n",
              "<th>training_rmse</th>\n",
              "<th>training_logloss</th>\n",
              "<th>training_auc</th>\n",
              "<th>training_pr_auc</th>\n",
              "<th>training_lift</th>\n",
              "<th>training_classification_error</th>\n",
              "<th>validation_rmse</th>\n",
              "<th>validation_logloss</th>\n",
              "<th>validation_auc</th>\n",
              "<th>validation_pr_auc</th>\n",
              "<th>validation_lift</th>\n",
              "<th>validation_classification_error</th></tr></thead>\n",
              "    <tbody><tr><td></td>\n",
              "<td>2022-11-08 01:24:54</td>\n",
              "<td> 0.003 sec</td>\n",
              "<td>0.0</td>\n",
              "<td>0.1809487</td>\n",
              "<td>0.1480179</td>\n",
              "<td>0.5</td>\n",
              "<td>0.0338910</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9661090</td>\n",
              "<td>0.1855858</td>\n",
              "<td>0.1541260</td>\n",
              "<td>0.5</td>\n",
              "<td>0.0357143</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9642857</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2022-11-08 01:24:54</td>\n",
              "<td> 0.098 sec</td>\n",
              "<td>5.0</td>\n",
              "<td>0.1393057</td>\n",
              "<td>0.0786390</td>\n",
              "<td>0.9821918</td>\n",
              "<td>0.8392068</td>\n",
              "<td>28.3714703</td>\n",
              "<td>0.0148720</td>\n",
              "<td>0.1549860</td>\n",
              "<td>0.0943287</td>\n",
              "<td>0.9530188</td>\n",
              "<td>0.6753752</td>\n",
              "<td>24.2666667</td>\n",
              "<td>0.0206044</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2022-11-08 01:24:54</td>\n",
              "<td> 0.216 sec</td>\n",
              "<td>10.0</td>\n",
              "<td>0.1196289</td>\n",
              "<td>0.0596727</td>\n",
              "<td>0.9896694</td>\n",
              "<td>0.8959561</td>\n",
              "<td>29.0848101</td>\n",
              "<td>0.0102960</td>\n",
              "<td>0.1413058</td>\n",
              "<td>0.0785943</td>\n",
              "<td>0.9573951</td>\n",
              "<td>0.7445927</td>\n",
              "<td>26.1333333</td>\n",
              "<td>0.0185440</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2022-11-08 01:24:54</td>\n",
              "<td> 0.340 sec</td>\n",
              "<td>15.0</td>\n",
              "<td>0.1048791</td>\n",
              "<td>0.0475412</td>\n",
              "<td>0.9919481</td>\n",
              "<td>0.9211711</td>\n",
              "<td>29.5063291</td>\n",
              "<td>0.0084370</td>\n",
              "<td>0.1293617</td>\n",
              "<td>0.0673861</td>\n",
              "<td>0.9594017</td>\n",
              "<td>0.7812764</td>\n",
              "<td>26.1333333</td>\n",
              "<td>0.0151099</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2022-11-08 01:24:54</td>\n",
              "<td> 0.468 sec</td>\n",
              "<td>20.0</td>\n",
              "<td>0.0961483</td>\n",
              "<td>0.0407277</td>\n",
              "<td>0.9929139</td>\n",
              "<td>0.9314462</td>\n",
              "<td>29.5063291</td>\n",
              "<td>0.0077220</td>\n",
              "<td>0.1240209</td>\n",
              "<td>0.0620597</td>\n",
              "<td>0.9582922</td>\n",
              "<td>0.7902095</td>\n",
              "<td>26.1333333</td>\n",
              "<td>0.0164835</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2022-11-08 01:24:55</td>\n",
              "<td> 0.586 sec</td>\n",
              "<td>25.0</td>\n",
              "<td>0.0881069</td>\n",
              "<td>0.0352555</td>\n",
              "<td>0.9933271</td>\n",
              "<td>0.9478629</td>\n",
              "<td>29.5063291</td>\n",
              "<td>0.0068640</td>\n",
              "<td>0.1196968</td>\n",
              "<td>0.0581635</td>\n",
              "<td>0.9602989</td>\n",
              "<td>0.8020453</td>\n",
              "<td>26.1333333</td>\n",
              "<td>0.0164835</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2022-11-08 01:24:55</td>\n",
              "<td> 0.698 sec</td>\n",
              "<td>30.0</td>\n",
              "<td>0.0827489</td>\n",
              "<td>0.0315937</td>\n",
              "<td>0.9944372</td>\n",
              "<td>0.9568070</td>\n",
              "<td>29.5063291</td>\n",
              "<td>0.0061490</td>\n",
              "<td>0.1175510</td>\n",
              "<td>0.0563102</td>\n",
              "<td>0.9584429</td>\n",
              "<td>0.7966322</td>\n",
              "<td>26.1333333</td>\n",
              "<td>0.0137363</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2022-11-08 01:24:55</td>\n",
              "<td> 0.858 sec</td>\n",
              "<td>35.0</td>\n",
              "<td>0.0784556</td>\n",
              "<td>0.0287119</td>\n",
              "<td>0.9955470</td>\n",
              "<td>0.9639897</td>\n",
              "<td>29.5063291</td>\n",
              "<td>0.0052910</td>\n",
              "<td>0.1154158</td>\n",
              "<td>0.0545359</td>\n",
              "<td>0.9561966</td>\n",
              "<td>0.8007562</td>\n",
              "<td>26.1333333</td>\n",
              "<td>0.0137363</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2022-11-08 01:24:55</td>\n",
              "<td> 0.983 sec</td>\n",
              "<td>40.0</td>\n",
              "<td>0.0743170</td>\n",
              "<td>0.0260227</td>\n",
              "<td>0.9961922</td>\n",
              "<td>0.9708320</td>\n",
              "<td>29.5063291</td>\n",
              "<td>0.0047190</td>\n",
              "<td>0.1143014</td>\n",
              "<td>0.0536017</td>\n",
              "<td>0.9563267</td>\n",
              "<td>0.8163090</td>\n",
              "<td>26.1333333</td>\n",
              "<td>0.0137363</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2022-11-08 01:24:55</td>\n",
              "<td> 1.088 sec</td>\n",
              "<td>45.0</td>\n",
              "<td>0.0706416</td>\n",
              "<td>0.0239411</td>\n",
              "<td>0.9964276</td>\n",
              "<td>0.9732147</td>\n",
              "<td>29.5063291</td>\n",
              "<td>0.0041470</td>\n",
              "<td>0.1121851</td>\n",
              "<td>0.0521488</td>\n",
              "<td>0.9558747</td>\n",
              "<td>0.8251245</td>\n",
              "<td>26.1333333</td>\n",
              "<td>0.0151099</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2022-11-08 01:24:55</td>\n",
              "<td> 1.226 sec</td>\n",
              "<td>50.0</td>\n",
              "<td>0.0685663</td>\n",
              "<td>0.0226603</td>\n",
              "<td>0.9971177</td>\n",
              "<td>0.9757550</td>\n",
              "<td>29.5063291</td>\n",
              "<td>0.0038610</td>\n",
              "<td>0.1120929</td>\n",
              "<td>0.0521302</td>\n",
              "<td>0.9557788</td>\n",
              "<td>0.8132657</td>\n",
              "<td>26.1333333</td>\n",
              "<td>0.0151099</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2022-11-08 01:24:55</td>\n",
              "<td> 1.311 sec</td>\n",
              "<td>55.0</td>\n",
              "<td>0.0659316</td>\n",
              "<td>0.0213575</td>\n",
              "<td>0.9972667</td>\n",
              "<td>0.9788367</td>\n",
              "<td>29.5063291</td>\n",
              "<td>0.0034320</td>\n",
              "<td>0.1108939</td>\n",
              "<td>0.0515135</td>\n",
              "<td>0.9563472</td>\n",
              "<td>0.8076984</td>\n",
              "<td>26.1333333</td>\n",
              "<td>0.0157967</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2022-11-08 01:24:55</td>\n",
              "<td> 1.428 sec</td>\n",
              "<td>60.0</td>\n",
              "<td>0.0635476</td>\n",
              "<td>0.0201857</td>\n",
              "<td>0.9973160</td>\n",
              "<td>0.9803536</td>\n",
              "<td>29.5063291</td>\n",
              "<td>0.0030030</td>\n",
              "<td>0.1104173</td>\n",
              "<td>0.0509809</td>\n",
              "<td>0.9573129</td>\n",
              "<td>0.8188104</td>\n",
              "<td>26.1333333</td>\n",
              "<td>0.0151099</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2022-11-08 01:24:56</td>\n",
              "<td> 1.555 sec</td>\n",
              "<td>65.0</td>\n",
              "<td>0.0618342</td>\n",
              "<td>0.0193495</td>\n",
              "<td>0.9974038</td>\n",
              "<td>0.9813891</td>\n",
              "<td>29.5063291</td>\n",
              "<td>0.0028600</td>\n",
              "<td>0.1097291</td>\n",
              "<td>0.0505648</td>\n",
              "<td>0.9588470</td>\n",
              "<td>0.8218767</td>\n",
              "<td>26.1333333</td>\n",
              "<td>0.0130495</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2022-11-08 01:24:56</td>\n",
              "<td> 1.689 sec</td>\n",
              "<td>70.0</td>\n",
              "<td>0.0597051</td>\n",
              "<td>0.0180078</td>\n",
              "<td>0.9980074</td>\n",
              "<td>0.9862195</td>\n",
              "<td>29.5063291</td>\n",
              "<td>0.0025740</td>\n",
              "<td>0.1100270</td>\n",
              "<td>0.0508048</td>\n",
              "<td>0.9607920</td>\n",
              "<td>0.8198325</td>\n",
              "<td>26.1333333</td>\n",
              "<td>0.0130495</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2022-11-08 01:24:56</td>\n",
              "<td> 1.806 sec</td>\n",
              "<td>75.0</td>\n",
              "<td>0.0575338</td>\n",
              "<td>0.0166085</td>\n",
              "<td>0.9991591</td>\n",
              "<td>0.9898823</td>\n",
              "<td>29.5063291</td>\n",
              "<td>0.0020020</td>\n",
              "<td>0.1097642</td>\n",
              "<td>0.0507182</td>\n",
              "<td>0.9647504</td>\n",
              "<td>0.8219852</td>\n",
              "<td>26.1333333</td>\n",
              "<td>0.0137363</td></tr>\n",
              "<tr><td></td>\n",
              "<td>2022-11-08 01:24:56</td>\n",
              "<td> 1.918 sec</td>\n",
              "<td>80.0</td>\n",
              "<td>0.0549611</td>\n",
              "<td>0.0154644</td>\n",
              "<td>0.9993152</td>\n",
              "<td>0.9919272</td>\n",
              "<td>29.5063291</td>\n",
              "<td>0.0017160</td>\n",
              "<td>0.1101987</td>\n",
              "<td>0.0507689</td>\n",
              "<td>0.9681679</td>\n",
              "<td>0.8184057</td>\n",
              "<td>26.1333333</td>\n",
              "<td>0.0137363</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-142.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-142 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-142 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-142 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-142 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-142 .h2o-table th,\n",
              "#h2o-table-142 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-142 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-142\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Variable Importances: </caption>\n",
              "    <thead><tr><th>variable</th>\n",
              "<th>relative_importance</th>\n",
              "<th>scaled_importance</th>\n",
              "<th>percentage</th></tr></thead>\n",
              "    <tbody><tr><td>Torque [Nm]</td>\n",
              "<td>264.4163818</td>\n",
              "<td>1.0</td>\n",
              "<td>0.4101751</td></tr>\n",
              "<tr><td>Tool wear [min]</td>\n",
              "<td>117.4805450</td>\n",
              "<td>0.4443013</td>\n",
              "<td>0.1822414</td></tr>\n",
              "<tr><td>Air temperature [K]</td>\n",
              "<td>90.9836121</td>\n",
              "<td>0.3440922</td>\n",
              "<td>0.1411381</td></tr>\n",
              "<tr><td>Rotational speed [rpm]</td>\n",
              "<td>83.9354248</td>\n",
              "<td>0.3174366</td>\n",
              "<td>0.1302046</td></tr>\n",
              "<tr><td>Process temperature [K]</td>\n",
              "<td>77.4207230</td>\n",
              "<td>0.2927985</td>\n",
              "<td>0.1200987</td></tr>\n",
              "<tr><td>Type</td>\n",
              "<td>10.4059420</td>\n",
              "<td>0.0393544</td>\n",
              "<td>0.0161422</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
              "\n",
              "[tips]\n",
              "Use `model.explain()` to inspect the model.\n",
              "--\n",
              "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the AutoML with training data "
      ],
      "metadata": {
        "id": "fvnjzAUouoM2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "below, gives the leaderboard which has performance of models after training\n"
      ],
      "metadata": {
        "id": "1cP8jJgVu5Uf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lb = aml.leaderboard"
      ],
      "metadata": {
        "id": "3sqFyFc-7T0T"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = aml.get_best_model()"
      ],
      "metadata": {
        "id": "O7qtgkuAvRtJ"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Storing the best model after training on the dataset"
      ],
      "metadata": {
        "id": "-y_8l3kjvZ5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(best_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1OpUq6qvW-n",
        "outputId": "4707c52d-ea87-4cf6-f51e-1cc7ec7d1d7d"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Details\n",
            "=============\n",
            "H2OGradientBoostingEstimator : Gradient Boosting Machine\n",
            "Model Key: GBM_6_AutoML_4_20221108_12439\n",
            "\n",
            "\n",
            "Model Summary: \n",
            "    number_of_trees    number_of_internal_trees    model_size_in_bytes    min_depth    max_depth    mean_depth    min_leaves    max_leaves    mean_leaves\n",
            "--  -----------------  --------------------------  ---------------------  -----------  -----------  ------------  ------------  ------------  -------------\n",
            "    80                 80                          37616                  7            7            7             12            72            32.675\n",
            "\n",
            "ModelMetricsBinomial: gbm\n",
            "** Reported on train data. **\n",
            "\n",
            "MSE: 0.0030207200528190826\n",
            "RMSE: 0.054961077616974385\n",
            "LogLoss: 0.015464407200018463\n",
            "Mean Per-Class Error: 0.017173670286515126\n",
            "AUC: 0.9993151891239668\n",
            "AUCPR: 0.9919272319930348\n",
            "Gini: 0.9986303782479335\n",
            "\n",
            "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.29666095801752085\n",
            "       0     1    Error    Rate\n",
            "-----  ----  ---  -------  -------------\n",
            "0      6752  4    0.0006   (4.0/6756.0)\n",
            "1      8     229  0.0338   (8.0/237.0)\n",
            "Total  6760  233  0.0017   (12.0/6993.0)\n",
            "\n",
            "Maximum Metrics: Maximum metrics at their respective thresholds\n",
            "metric                       threshold    value     idx\n",
            "---------------------------  -----------  --------  -----\n",
            "max f1                       0.296661     0.974468  164\n",
            "max f2                       0.219575     0.973154  173\n",
            "max f0point5                 0.386869     0.985977  157\n",
            "max accuracy                 0.309309     0.998284  162\n",
            "max precision                0.998696     1         0\n",
            "max recall                   0.0124605    1         333\n",
            "max specificity              0.998696     1         0\n",
            "max absolute_mcc             0.296661     0.973618  164\n",
            "max min_per_class_accuracy   0.117788     0.991561  206\n",
            "max mean_per_class_accuracy  0.117788     0.991784  206\n",
            "max tns                      0.998696     6756      0\n",
            "max fns                      0.998696     236       0\n",
            "max fps                      0.000319197  6756      399\n",
            "max tps                      0.0124605    237       333\n",
            "max tnr                      0.998696     1         0\n",
            "max fnr                      0.998696     0.995781  0\n",
            "max fpr                      0.000319197  1         399\n",
            "max tpr                      0.0124605    1         333\n",
            "\n",
            "Gains/Lift Table: Avg response rate:  3.39 %, avg score:  3.38 %\n",
            "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
            "-------  --------------------------  -----------------  ---------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
            "1        0.01001                     0.940838           29.5063    29.5063            1                0.972743     1                           0.972743            0.295359        0.295359                   2850.63   2850.63            0.295359\n",
            "2        0.02002                     0.862888           29.5063    29.5063            1                0.907889     1                           0.940316            0.295359        0.590717                   2850.63   2850.63            0.590717\n",
            "3        0.03003                     0.52123            29.5063    29.5063            1                0.75389      1                           0.878174            0.295359        0.886076                   2850.63   2850.63            0.886076\n",
            "4        0.04004                     0.126458           10.1165    24.6589            0.342857         0.258928     0.835714                    0.723363            0.101266        0.987342                   911.646   2365.89            0.980533\n",
            "5        0.0500501                   0.0759899          0.421519   19.8114            0.0142857        0.094287     0.671429                    0.597547            0.00421941      0.991561                   -57.8481  1881.14            0.974539\n",
            "6        0.1001                      0.0194506          0.0843038  9.94785            0.00285714       0.0404474    0.337143                    0.318997            0.00421941      0.995781                   -91.5696  894.785            0.927101\n",
            "7        0.150007                    0.00783495         0.0845454  6.66635            0.00286533       0.0121894    0.225929                    0.216923            0.00421941      1                          -91.5455  566.635            0.879811\n",
            "8        0.200057                    0.00387259         0          4.99857            0                0.00556024   0.169407                    0.164045            0               1                          -100      399.857            0.828005\n",
            "9        0.300014                    0.0020429          0          3.33317            0                0.00274488   0.112965                    0.110304            0               1                          -100      233.317            0.724541\n",
            "10       0.399971                    0.00148469         0          2.50018            0                0.00172867   0.0847336                   0.0831696           0               1                          -100      150.018            0.621078\n",
            "11       0.500072                    0.00114842         0          1.99971            0                0.00130966   0.0677724                   0.0667836           0               1                          -100      99.9714            0.517466\n",
            "12       0.600172                    0.000949113        0          1.66619            0                0.00103435   0.0564689                   0.0558175           0               1                          -100      66.619             0.413854\n",
            "13       0.699986                    0.00083529         0          1.4286             0                0.000885091  0.0484168                   0.0479845           0               1                          -100      42.8601            0.310539\n",
            "14       0.800801                    0.000749023        0          1.24875            0                0.000790914  0.0423214                   0.0420431           0               1                          -100      24.875             0.206187\n",
            "15       0.8999                      0.000644007        0          1.11123            0                0.000699275  0.0376609                   0.0374903           0               1                          -100      11.1235            0.103612\n",
            "16       1                           0.000251342        0          1                  0                0.00051489   0.033891                    0.033789            0               1                          -100      0                  0\n",
            "\n",
            "ModelMetricsBinomial: gbm\n",
            "** Reported on validation data. **\n",
            "\n",
            "MSE: 0.012143755017777197\n",
            "RMSE: 0.11019870696962464\n",
            "LogLoss: 0.05076886190242359\n",
            "Mean Per-Class Error: 0.146011396011396\n",
            "AUC: 0.9681678720140259\n",
            "AUCPR: 0.8184057386168719\n",
            "Gini: 0.9363357440280518\n",
            "\n",
            "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.43833384467054226\n",
            "       0     1    Error    Rate\n",
            "-----  ----  ---  -------  -------------\n",
            "0      1399  5    0.0036   (5.0/1404.0)\n",
            "1      15    37   0.2885   (15.0/52.0)\n",
            "Total  1414  42   0.0137   (20.0/1456.0)\n",
            "\n",
            "Maximum Metrics: Maximum metrics at their respective thresholds\n",
            "metric                       threshold    value     idx\n",
            "---------------------------  -----------  --------  -----\n",
            "max f1                       0.438334     0.787234  40\n",
            "max f2                       0.155975     0.797101  66\n",
            "max f0point5                 0.687081     0.869565  32\n",
            "max accuracy                 0.49897      0.986264  37\n",
            "max precision                0.985851     1         0\n",
            "max recall                   0.000980848  1         360\n",
            "max specificity              0.985851     1         0\n",
            "max absolute_mcc             0.438334     0.784974  40\n",
            "max min_per_class_accuracy   0.0298728    0.923077  143\n",
            "max mean_per_class_accuracy  0.0583284    0.932336  99\n",
            "max tns                      0.985851     1404      0\n",
            "max fns                      0.985851     51        0\n",
            "max fps                      0.000260583  1404      399\n",
            "max tps                      0.000980848  52        360\n",
            "max tnr                      0.985851     1         0\n",
            "max fnr                      0.985851     0.980769  0\n",
            "max fpr                      0.000260583  1         399\n",
            "max tpr                      0.000980848  1         360\n",
            "\n",
            "Gains/Lift Table: Avg response rate:  3.57 %, avg score:  3.26 %\n",
            "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
            "-------  --------------------------  -----------------  --------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
            "1        0.0103022                   0.906607           26.1333   26.1333            0.933333         0.941874     0.933333                    0.941874            0.269231        0.269231                   2513.33   2513.33            0.268519\n",
            "2        0.0206044                   0.70814            28        27.0667            1                0.821938     0.966667                    0.881906            0.288462        0.557692                   2700      2606.67            0.55698\n",
            "3        0.0302198                   0.401783           16        23.5455            0.571429         0.54721      0.840909                    0.775412            0.153846        0.711538                   1500      2254.55            0.706553\n",
            "4        0.040522                    0.194102           7.46667   19.4576            0.266667         0.279656     0.694915                    0.649372            0.0769231       0.788462                   646.667   1845.76            0.775641\n",
            "5        0.0501374                   0.109413           6         16.8767            0.214286         0.156318     0.60274                     0.554814            0.0576923       0.846154                   500       1587.67            0.825499\n",
            "6        0.100275                    0.0295479          1.53425   9.20548            0.0547945        0.0534366    0.328767                    0.304125            0.0769231       0.923077                   53.4247   820.548            0.853276\n",
            "7        0.150412                    0.00880222         0.383562  6.26484            0.0136986        0.0159302    0.223744                    0.20806             0.0192308       0.942308                   -61.6438  526.484            0.821225\n",
            "8        0.200549                    0.00433098         0         4.69863            0                0.00637191   0.167808                    0.157638            0               0.942308                   -100      369.863            0.769231\n",
            "9        0.300137                    0.00215517         0.193103  3.20366            0.00689655       0.0029295    0.114416                    0.106305            0.0192308       0.961538                   -80.6897  220.366            0.685897\n",
            "10       0.400412                    0.00154344         0         2.40137            0                0.00182138   0.0857633                   0.080139            0               0.961538                   -100      140.137            0.581909\n",
            "11       0.5                         0.0011701          0.193103  1.96154            0.00689655       0.0013422    0.0700549                   0.0644446           0.0192308       0.980769                   -80.6897  96.1538            0.498575\n",
            "12       0.600275                    0.00097206         0.191781  1.6659             0.00684932       0.00106262   0.0594966                   0.0538567           0.0192308       1                          -80.8219  66.5904            0.41453\n",
            "13       0.699863                    0.000836412        0         1.42885            0                0.000897474  0.0510304                   0.0463208           0               1                          -100      42.8852            0.311254\n",
            "14       0.800137                    0.000749022        0         1.24979            0                0.000792182  0.0446352                   0.0406151           0               1                          -100      24.9785            0.207265\n",
            "15       0.899725                    0.000667155        0         1.11145            0                0.000708039  0.0396947                   0.0361979           0               1                          -100      11.145             0.103989\n",
            "16       1                           0.000247547        0         1                  0                0.000554079  0.0357143                   0.0326237           0               1                          -100      0                  0\n",
            "\n",
            "Scoring History: \n",
            "    timestamp            duration    number_of_trees    training_rmse    training_logloss    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_auc    validation_pr_auc    validation_lift    validation_classification_error\n",
            "--  -------------------  ----------  -----------------  ---------------  ------------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ----------------  -------------------  -----------------  ---------------------------------\n",
            "    2022-11-08 01:24:54  0.003 sec   0                  0.180949         0.148018            0.5             0.033891           1                0.966109                         0.185586           0.154126              0.5               0.0357143            1                  0.964286\n",
            "    2022-11-08 01:24:54  0.098 sec   5                  0.139306         0.078639            0.982192        0.839207           28.3715          0.014872                         0.154986           0.0943287             0.953019          0.675375             24.2667            0.0206044\n",
            "    2022-11-08 01:24:54  0.216 sec   10                 0.119629         0.0596727           0.989669        0.895956           29.0848          0.010296                         0.141306           0.0785943             0.957395          0.744593             26.1333            0.018544\n",
            "    2022-11-08 01:24:54  0.340 sec   15                 0.104879         0.0475412           0.991948        0.921171           29.5063          0.00843701                       0.129362           0.0673861             0.959402          0.781276             26.1333            0.0151099\n",
            "    2022-11-08 01:24:54  0.468 sec   20                 0.0961483        0.0407277           0.992914        0.931446           29.5063          0.00772201                       0.124021           0.0620597             0.958292          0.790209             26.1333            0.0164835\n",
            "    2022-11-08 01:24:55  0.586 sec   25                 0.0881069        0.0352555           0.993327        0.947863           29.5063          0.00686401                       0.119697           0.0581635             0.960299          0.802045             26.1333            0.0164835\n",
            "    2022-11-08 01:24:55  0.698 sec   30                 0.0827489        0.0315937           0.994437        0.956807           29.5063          0.00614901                       0.117551           0.0563102             0.958443          0.796632             26.1333            0.0137363\n",
            "    2022-11-08 01:24:55  0.858 sec   35                 0.0784556        0.0287119           0.995547        0.96399            29.5063          0.00529101                       0.115416           0.0545359             0.956197          0.800756             26.1333            0.0137363\n",
            "    2022-11-08 01:24:55  0.983 sec   40                 0.074317         0.0260227           0.996192        0.970832           29.5063          0.004719                         0.114301           0.0536017             0.956327          0.816309             26.1333            0.0137363\n",
            "    2022-11-08 01:24:55  1.088 sec   45                 0.0706416        0.0239411           0.996428        0.973215           29.5063          0.004147                         0.112185           0.0521488             0.955875          0.825124             26.1333            0.0151099\n",
            "    2022-11-08 01:24:55  1.226 sec   50                 0.0685663        0.0226603           0.997118        0.975755           29.5063          0.003861                         0.112093           0.0521302             0.955779          0.813266             26.1333            0.0151099\n",
            "    2022-11-08 01:24:55  1.311 sec   55                 0.0659316        0.0213575           0.997267        0.978837           29.5063          0.003432                         0.110894           0.0515135             0.956347          0.807698             26.1333            0.0157967\n",
            "    2022-11-08 01:24:55  1.428 sec   60                 0.0635476        0.0201857           0.997316        0.980354           29.5063          0.003003                         0.110417           0.0509809             0.957313          0.81881              26.1333            0.0151099\n",
            "    2022-11-08 01:24:56  1.555 sec   65                 0.0618342        0.0193495           0.997404        0.981389           29.5063          0.00286                          0.109729           0.0505648             0.958847          0.821877             26.1333            0.0130495\n",
            "    2022-11-08 01:24:56  1.689 sec   70                 0.0597051        0.0180078           0.998007        0.98622            29.5063          0.002574                         0.110027           0.0508048             0.960792          0.819833             26.1333            0.0130495\n",
            "    2022-11-08 01:24:56  1.806 sec   75                 0.0575338        0.0166085           0.999159        0.989882           29.5063          0.002002                         0.109764           0.0507182             0.96475           0.821985             26.1333            0.0137363\n",
            "    2022-11-08 01:24:56  1.918 sec   80                 0.0549611        0.0154644           0.999315        0.991927           29.5063          0.001716                         0.110199           0.0507689             0.968168          0.818406             26.1333            0.0137363\n",
            "\n",
            "Variable Importances: \n",
            "variable                 relative_importance    scaled_importance    percentage\n",
            "-----------------------  ---------------------  -------------------  ------------\n",
            "Torque [Nm]              264.416                1                    0.410175\n",
            "Tool wear [min]          117.481                0.444301             0.182241\n",
            "Air temperature [K]      90.9836                0.344092             0.141138\n",
            "Rotational speed [rpm]   83.9354                0.317437             0.130205\n",
            "Process temperature [K]  77.4207                0.292799             0.120099\n",
            "Type                     10.4059                0.0393544            0.0161422\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lb.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "SB0i8ERO7ai-",
        "outputId": "9aad0d5b-7ff5-43a3-bc65-dc61e37eecc8"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model_id                                 auc    logloss     aucpr    mean_per_class_error      rmse        mse\n",
              "----------------------------------  --------  ---------  --------  ----------------------  --------  ---------\n",
              "GBM_6_AutoML_4_20221108_12439       0.968168  0.0507689  0.818406               0.146011   0.110199  0.0121438\n",
              "GBM_2_AutoML_3_20221107_235941      0.968168  0.0507689  0.818406               0.146011   0.110199  0.0121438\n",
              "GBM_7_AutoML_4_20221108_12439       0.964963  0.0486406  0.859322               0.117521   0.102848  0.0105777\n",
              "GBM_3_AutoML_3_20221107_235941      0.964963  0.0486406  0.859322               0.117521   0.102848  0.0105777\n",
              "XGBoost_3_AutoML_3_20221107_235941  0.963031  0.0499266  0.828576               0.107906   0.105204  0.0110679\n",
              "XGBoost_6_AutoML_4_20221108_12439   0.963031  0.0499266  0.828576               0.107906   0.105204  0.0110679\n",
              "GBM_8_AutoML_4_20221108_12439       0.958374  0.0501386  0.845997               0.0990028  0.105769  0.011187\n",
              "GBM_4_AutoML_3_20221107_235941      0.958374  0.0501386  0.845997               0.0990028  0.105769  0.011187\n",
              "GBM_5_AutoML_4_20221108_12439       0.955005  0.0680771  0.744404               0.132835   0.130225  0.0169585\n",
              "GBM_1_AutoML_3_20221107_235941      0.955005  0.0680771  0.744404               0.132835   0.130225  0.0169585\n",
              "[10 rows x 7 columns]\n"
            ],
            "text/html": [
              "<table class='dataframe'>\n",
              "<thead>\n",
              "<tr><th>model_id                          </th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">   aucpr</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">      mse</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>GBM_6_AutoML_4_20221108_12439     </td><td style=\"text-align: right;\">0.968168</td><td style=\"text-align: right;\">0.0507689</td><td style=\"text-align: right;\">0.818406</td><td style=\"text-align: right;\">             0.146011 </td><td style=\"text-align: right;\">0.110199</td><td style=\"text-align: right;\">0.0121438</td></tr>\n",
              "<tr><td>GBM_2_AutoML_3_20221107_235941    </td><td style=\"text-align: right;\">0.968168</td><td style=\"text-align: right;\">0.0507689</td><td style=\"text-align: right;\">0.818406</td><td style=\"text-align: right;\">             0.146011 </td><td style=\"text-align: right;\">0.110199</td><td style=\"text-align: right;\">0.0121438</td></tr>\n",
              "<tr><td>GBM_7_AutoML_4_20221108_12439     </td><td style=\"text-align: right;\">0.964963</td><td style=\"text-align: right;\">0.0486406</td><td style=\"text-align: right;\">0.859322</td><td style=\"text-align: right;\">             0.117521 </td><td style=\"text-align: right;\">0.102848</td><td style=\"text-align: right;\">0.0105777</td></tr>\n",
              "<tr><td>GBM_3_AutoML_3_20221107_235941    </td><td style=\"text-align: right;\">0.964963</td><td style=\"text-align: right;\">0.0486406</td><td style=\"text-align: right;\">0.859322</td><td style=\"text-align: right;\">             0.117521 </td><td style=\"text-align: right;\">0.102848</td><td style=\"text-align: right;\">0.0105777</td></tr>\n",
              "<tr><td>XGBoost_3_AutoML_3_20221107_235941</td><td style=\"text-align: right;\">0.963031</td><td style=\"text-align: right;\">0.0499266</td><td style=\"text-align: right;\">0.828576</td><td style=\"text-align: right;\">             0.107906 </td><td style=\"text-align: right;\">0.105204</td><td style=\"text-align: right;\">0.0110679</td></tr>\n",
              "<tr><td>XGBoost_6_AutoML_4_20221108_12439 </td><td style=\"text-align: right;\">0.963031</td><td style=\"text-align: right;\">0.0499266</td><td style=\"text-align: right;\">0.828576</td><td style=\"text-align: right;\">             0.107906 </td><td style=\"text-align: right;\">0.105204</td><td style=\"text-align: right;\">0.0110679</td></tr>\n",
              "<tr><td>GBM_8_AutoML_4_20221108_12439     </td><td style=\"text-align: right;\">0.958374</td><td style=\"text-align: right;\">0.0501386</td><td style=\"text-align: right;\">0.845997</td><td style=\"text-align: right;\">             0.0990028</td><td style=\"text-align: right;\">0.105769</td><td style=\"text-align: right;\">0.011187 </td></tr>\n",
              "<tr><td>GBM_4_AutoML_3_20221107_235941    </td><td style=\"text-align: right;\">0.958374</td><td style=\"text-align: right;\">0.0501386</td><td style=\"text-align: right;\">0.845997</td><td style=\"text-align: right;\">             0.0990028</td><td style=\"text-align: right;\">0.105769</td><td style=\"text-align: right;\">0.011187 </td></tr>\n",
              "<tr><td>GBM_5_AutoML_4_20221108_12439     </td><td style=\"text-align: right;\">0.955005</td><td style=\"text-align: right;\">0.0680771</td><td style=\"text-align: right;\">0.744404</td><td style=\"text-align: right;\">             0.132835 </td><td style=\"text-align: right;\">0.130225</td><td style=\"text-align: right;\">0.0169585</td></tr>\n",
              "<tr><td>GBM_1_AutoML_3_20221107_235941    </td><td style=\"text-align: right;\">0.955005</td><td style=\"text-align: right;\">0.0680771</td><td style=\"text-align: right;\">0.744404</td><td style=\"text-align: right;\">             0.132835 </td><td style=\"text-align: right;\">0.130225</td><td style=\"text-align: right;\">0.0169585</td></tr>\n",
              "</tbody>\n",
              "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[10 rows x 7 columns]</pre>"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Displaying top models in leaderboard"
      ],
      "metadata": {
        "id": "LaUUX9Pb2Lg7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using best model from leader board to predict on test data"
      ],
      "metadata": {
        "id": "12wp4oZ-27TQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred=aml.leader.predict(test)"
      ],
      "metadata": {
        "id": "4Eh0fVph7fVD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e27f68c-0043-4c46-a105-41be794fa430"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aml.leader.model_performance(test)  #Checking the best model performance on test data , this is same as using best model above"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ilfeS31RQT9k",
        "outputId": "bba2a92b-de12-47a5-c5e6-aab3a39f3907"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModelMetricsBinomial: gbm\n",
              "** Reported on test data. **\n",
              "\n",
              "MSE: 0.01165769989083747\n",
              "RMSE: 0.10797082888835054\n",
              "LogLoss: 0.045557837874566465\n",
              "Mean Per-Class Error: 0.11299800133244503\n",
              "AUC: 0.9819786808794138\n",
              "AUCPR: 0.8117885826525254\n",
              "Gini: 0.9639573617588275\n",
              "\n",
              "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.2715401530036246\n",
              "       0     1    Error    Rate\n",
              "-----  ----  ---  -------  -------------\n",
              "0      1492  9    0.006    (9.0/1501.0)\n",
              "1      11    39   0.22     (11.0/50.0)\n",
              "Total  1503  48   0.0129   (20.0/1551.0)\n",
              "\n",
              "Maximum Metrics: Maximum metrics at their respective thresholds\n",
              "metric                       threshold    value     idx\n",
              "---------------------------  -----------  --------  -----\n",
              "max f1                       0.27154      0.795918  47\n",
              "max f2                       0.27154      0.78629   47\n",
              "max f0point5                 0.397276     0.817757  40\n",
              "max accuracy                 0.301956     0.987105  45\n",
              "max precision                0.993987     1         0\n",
              "max recall                   0.0016769    1         320\n",
              "max specificity              0.993987     1         0\n",
              "max absolute_mcc             0.27154      0.789439  47\n",
              "max min_per_class_accuracy   0.0262825    0.936709  136\n",
              "max mean_per_class_accuracy  0.025215     0.946356  141\n",
              "max tns                      0.993987     1501      0\n",
              "max fns                      0.993987     49        0\n",
              "max fps                      0.000251808  1501      399\n",
              "max tps                      0.0016769    50        320\n",
              "max tnr                      0.993987     1         0\n",
              "max fnr                      0.993987     0.98      0\n",
              "max fpr                      0.000251808  1         399\n",
              "max tpr                      0.0016769    1         320\n",
              "\n",
              "Gains/Lift Table: Avg response rate:  3.22 %, avg score:  3.00 %\n",
              "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
              "-------  --------------------------  -----------------  --------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
              "1        0.0103159                   0.932043           31.02     31.02              1                0.958699     1                           0.958699            0.32            0.32                       3002      3002               0.32\n",
              "2        0.0206319                   0.649858           25.2037   28.1119            0.8125           0.784699     0.90625                     0.871699            0.26            0.58                       2420.38   2711.19            0.578001\n",
              "3        0.030303                    0.274349           18.612    25.08              0.6              0.477177     0.808511                    0.745788            0.18            0.76                       1761.2    2408               0.754004\n",
              "4        0.040619                    0.129783           3.8775    19.6952            0.125            0.198939     0.634921                    0.606906            0.04            0.8                        287.75    1869.52            0.784677\n",
              "5        0.0502901                   0.0908703          0         15.9077            0                0.105646     0.512821                    0.510509            0               0.8                        -100      1490.77            0.774684\n",
              "6        0.10058                     0.0235395          3.18154   9.54462            0.102564         0.0477265    0.307692                    0.279118            0.16            0.96                       218.154   854.462            0.888048\n",
              "7        0.150226                    0.00843778         0.402857  6.52352            0.012987         0.0137764    0.2103                      0.19143             0.02            0.98                       -59.7143  552.352            0.857415\n",
              "8        0.200516                    0.00400775         0         4.8874             0                0.00590212   0.157556                    0.144899            0               0.98                       -100      388.74             0.80545\n",
              "9        0.300451                    0.00199678         0         3.26176            0                0.00268486   0.10515                     0.0975959           0               0.98                       -100      226.176            0.702185\n",
              "10       0.400387                    0.00150079         0.200129  2.49758            0.00645161       0.00169483   0.0805153                   0.0736593           0.02            1                          -79.9871  149.758            0.619587\n",
              "11       0.500322                    0.00112107         0         1.99871            0                0.00128965   0.064433                    0.059204            0               1                          -100      99.8711            0.516322\n",
              "12       0.600258                    0.00091938         0         1.66595            0                0.00101279   0.0537057                   0.0495159           0               1                          -100      66.5951            0.413058\n",
              "13       0.700193                    0.000824148        0         1.42818            0                0.000871765  0.0460405                   0.0425731           0               1                          -100      42.8177            0.309793\n",
              "14       0.800129                    0.000736556        0         1.2498             0                0.000775038  0.0402901                   0.0373526           0               1                          -100      24.9799            0.206529\n",
              "15       0.900064                    0.000653987        0         1.11103            0                0.000694365  0.0358166                   0.0332824           0               1                          -100      11.1032            0.103264\n",
              "16       1                           0.000251808        0         1                  0                0.000526547  0.0322373                   0.0300089           0               1                          -100      0                  0"
            ],
            "text/html": [
              "<pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: gbm\n",
              "** Reported on test data. **\n",
              "\n",
              "MSE: 0.01165769989083747\n",
              "RMSE: 0.10797082888835054\n",
              "LogLoss: 0.045557837874566465\n",
              "Mean Per-Class Error: 0.11299800133244503\n",
              "AUC: 0.9819786808794138\n",
              "AUCPR: 0.8117885826525254\n",
              "Gini: 0.9639573617588275</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-152.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-152 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-152 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-152 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-152 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-152 .h2o-table th,\n",
              "#h2o-table-152 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-152 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-152\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.2715401530036246</caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>0</th>\n",
              "<th>1</th>\n",
              "<th>Error</th>\n",
              "<th>Rate</th></tr></thead>\n",
              "    <tbody><tr><td>0</td>\n",
              "<td>1492.0</td>\n",
              "<td>9.0</td>\n",
              "<td>0.006</td>\n",
              "<td> (9.0/1501.0)</td></tr>\n",
              "<tr><td>1</td>\n",
              "<td>11.0</td>\n",
              "<td>39.0</td>\n",
              "<td>0.22</td>\n",
              "<td> (11.0/50.0)</td></tr>\n",
              "<tr><td>Total</td>\n",
              "<td>1503.0</td>\n",
              "<td>48.0</td>\n",
              "<td>0.0129</td>\n",
              "<td> (20.0/1551.0)</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-153.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-153 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-153 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-153 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-153 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-153 .h2o-table th,\n",
              "#h2o-table-153 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-153 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-153\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
              "    <thead><tr><th>metric</th>\n",
              "<th>threshold</th>\n",
              "<th>value</th>\n",
              "<th>idx</th></tr></thead>\n",
              "    <tbody><tr><td>max f1</td>\n",
              "<td>0.2715402</td>\n",
              "<td>0.7959184</td>\n",
              "<td>47.0</td></tr>\n",
              "<tr><td>max f2</td>\n",
              "<td>0.2715402</td>\n",
              "<td>0.7862903</td>\n",
              "<td>47.0</td></tr>\n",
              "<tr><td>max f0point5</td>\n",
              "<td>0.3972761</td>\n",
              "<td>0.8177570</td>\n",
              "<td>40.0</td></tr>\n",
              "<tr><td>max accuracy</td>\n",
              "<td>0.3019565</td>\n",
              "<td>0.9871051</td>\n",
              "<td>45.0</td></tr>\n",
              "<tr><td>max precision</td>\n",
              "<td>0.9939875</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max recall</td>\n",
              "<td>0.0016769</td>\n",
              "<td>1.0</td>\n",
              "<td>320.0</td></tr>\n",
              "<tr><td>max specificity</td>\n",
              "<td>0.9939875</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max absolute_mcc</td>\n",
              "<td>0.2715402</td>\n",
              "<td>0.7894388</td>\n",
              "<td>47.0</td></tr>\n",
              "<tr><td>max min_per_class_accuracy</td>\n",
              "<td>0.0262825</td>\n",
              "<td>0.9367089</td>\n",
              "<td>136.0</td></tr>\n",
              "<tr><td>max mean_per_class_accuracy</td>\n",
              "<td>0.0252150</td>\n",
              "<td>0.9463558</td>\n",
              "<td>141.0</td></tr>\n",
              "<tr><td>max tns</td>\n",
              "<td>0.9939875</td>\n",
              "<td>1501.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fns</td>\n",
              "<td>0.9939875</td>\n",
              "<td>49.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fps</td>\n",
              "<td>0.0002518</td>\n",
              "<td>1501.0</td>\n",
              "<td>399.0</td></tr>\n",
              "<tr><td>max tps</td>\n",
              "<td>0.0016769</td>\n",
              "<td>50.0</td>\n",
              "<td>320.0</td></tr>\n",
              "<tr><td>max tnr</td>\n",
              "<td>0.9939875</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fnr</td>\n",
              "<td>0.9939875</td>\n",
              "<td>0.98</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fpr</td>\n",
              "<td>0.0002518</td>\n",
              "<td>1.0</td>\n",
              "<td>399.0</td></tr>\n",
              "<tr><td>max tpr</td>\n",
              "<td>0.0016769</td>\n",
              "<td>1.0</td>\n",
              "<td>320.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-154.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-154 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-154 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-154 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-154 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-154 .h2o-table th,\n",
              "#h2o-table-154 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-154 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-154\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Gains/Lift Table: Avg response rate:  3.22 %, avg score:  3.00 %</caption>\n",
              "    <thead><tr><th>group</th>\n",
              "<th>cumulative_data_fraction</th>\n",
              "<th>lower_threshold</th>\n",
              "<th>lift</th>\n",
              "<th>cumulative_lift</th>\n",
              "<th>response_rate</th>\n",
              "<th>score</th>\n",
              "<th>cumulative_response_rate</th>\n",
              "<th>cumulative_score</th>\n",
              "<th>capture_rate</th>\n",
              "<th>cumulative_capture_rate</th>\n",
              "<th>gain</th>\n",
              "<th>cumulative_gain</th>\n",
              "<th>kolmogorov_smirnov</th></tr></thead>\n",
              "    <tbody><tr><td>1</td>\n",
              "<td>0.0103159</td>\n",
              "<td>0.9320431</td>\n",
              "<td>31.0200000</td>\n",
              "<td>31.0200000</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9586990</td>\n",
              "<td>1.0</td>\n",
              "<td>0.9586990</td>\n",
              "<td>0.32</td>\n",
              "<td>0.32</td>\n",
              "<td>3002.0000000</td>\n",
              "<td>3002.0000000</td>\n",
              "<td>0.32</td></tr>\n",
              "<tr><td>2</td>\n",
              "<td>0.0206319</td>\n",
              "<td>0.6498575</td>\n",
              "<td>25.20375</td>\n",
              "<td>28.1118750</td>\n",
              "<td>0.8125</td>\n",
              "<td>0.7846993</td>\n",
              "<td>0.90625</td>\n",
              "<td>0.8716992</td>\n",
              "<td>0.26</td>\n",
              "<td>0.58</td>\n",
              "<td>2420.375</td>\n",
              "<td>2711.1875</td>\n",
              "<td>0.5780013</td></tr>\n",
              "<tr><td>3</td>\n",
              "<td>0.0303030</td>\n",
              "<td>0.2743490</td>\n",
              "<td>18.612</td>\n",
              "<td>25.0800000</td>\n",
              "<td>0.6</td>\n",
              "<td>0.4771771</td>\n",
              "<td>0.8085106</td>\n",
              "<td>0.7457878</td>\n",
              "<td>0.18</td>\n",
              "<td>0.76</td>\n",
              "<td>1761.2000000</td>\n",
              "<td>2408.0000000</td>\n",
              "<td>0.7540040</td></tr>\n",
              "<tr><td>4</td>\n",
              "<td>0.0406190</td>\n",
              "<td>0.1297826</td>\n",
              "<td>3.8775000</td>\n",
              "<td>19.6952381</td>\n",
              "<td>0.125</td>\n",
              "<td>0.1989390</td>\n",
              "<td>0.6349206</td>\n",
              "<td>0.6069056</td>\n",
              "<td>0.04</td>\n",
              "<td>0.8</td>\n",
              "<td>287.7500000</td>\n",
              "<td>1869.5238095</td>\n",
              "<td>0.7846769</td></tr>\n",
              "<tr><td>5</td>\n",
              "<td>0.0502901</td>\n",
              "<td>0.0908703</td>\n",
              "<td>0.0</td>\n",
              "<td>15.9076923</td>\n",
              "<td>0.0</td>\n",
              "<td>0.1056456</td>\n",
              "<td>0.5128205</td>\n",
              "<td>0.5105095</td>\n",
              "<td>0.0</td>\n",
              "<td>0.8</td>\n",
              "<td>-100.0</td>\n",
              "<td>1490.7692308</td>\n",
              "<td>0.7746835</td></tr>\n",
              "<tr><td>6</td>\n",
              "<td>0.1005803</td>\n",
              "<td>0.0235395</td>\n",
              "<td>3.1815385</td>\n",
              "<td>9.5446154</td>\n",
              "<td>0.1025641</td>\n",
              "<td>0.0477265</td>\n",
              "<td>0.3076923</td>\n",
              "<td>0.2791180</td>\n",
              "<td>0.16</td>\n",
              "<td>0.96</td>\n",
              "<td>218.1538462</td>\n",
              "<td>854.4615385</td>\n",
              "<td>0.8880480</td></tr>\n",
              "<tr><td>7</td>\n",
              "<td>0.1502257</td>\n",
              "<td>0.0084378</td>\n",
              "<td>0.4028571</td>\n",
              "<td>6.5235193</td>\n",
              "<td>0.0129870</td>\n",
              "<td>0.0137764</td>\n",
              "<td>0.2103004</td>\n",
              "<td>0.1914300</td>\n",
              "<td>0.02</td>\n",
              "<td>0.98</td>\n",
              "<td>-59.7142857</td>\n",
              "<td>552.3519313</td>\n",
              "<td>0.8574151</td></tr>\n",
              "<tr><td>8</td>\n",
              "<td>0.2005158</td>\n",
              "<td>0.0040078</td>\n",
              "<td>0.0</td>\n",
              "<td>4.8873955</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0059021</td>\n",
              "<td>0.1575563</td>\n",
              "<td>0.1448989</td>\n",
              "<td>0.0</td>\n",
              "<td>0.98</td>\n",
              "<td>-100.0</td>\n",
              "<td>388.7395498</td>\n",
              "<td>0.8054497</td></tr>\n",
              "<tr><td>9</td>\n",
              "<td>0.3004513</td>\n",
              "<td>0.0019968</td>\n",
              "<td>0.0</td>\n",
              "<td>3.2617597</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0026849</td>\n",
              "<td>0.1051502</td>\n",
              "<td>0.0975959</td>\n",
              "<td>0.0</td>\n",
              "<td>0.98</td>\n",
              "<td>-100.0</td>\n",
              "<td>226.1759657</td>\n",
              "<td>0.7021852</td></tr>\n",
              "<tr><td>10</td>\n",
              "<td>0.4003868</td>\n",
              "<td>0.0015008</td>\n",
              "<td>0.2001290</td>\n",
              "<td>2.4975845</td>\n",
              "<td>0.0064516</td>\n",
              "<td>0.0016948</td>\n",
              "<td>0.0805153</td>\n",
              "<td>0.0736593</td>\n",
              "<td>0.02</td>\n",
              "<td>1.0</td>\n",
              "<td>-79.9870968</td>\n",
              "<td>149.7584541</td>\n",
              "<td>0.6195869</td></tr>\n",
              "<tr><td>11</td>\n",
              "<td>0.5003224</td>\n",
              "<td>0.0011211</td>\n",
              "<td>0.0</td>\n",
              "<td>1.9987113</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0012897</td>\n",
              "<td>0.0644330</td>\n",
              "<td>0.0592040</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>99.8711340</td>\n",
              "<td>0.5163225</td></tr>\n",
              "<tr><td>12</td>\n",
              "<td>0.6002579</td>\n",
              "<td>0.0009194</td>\n",
              "<td>0.0</td>\n",
              "<td>1.6659506</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0010128</td>\n",
              "<td>0.0537057</td>\n",
              "<td>0.0495159</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>66.5950591</td>\n",
              "<td>0.4130580</td></tr>\n",
              "<tr><td>13</td>\n",
              "<td>0.7001934</td>\n",
              "<td>0.0008241</td>\n",
              "<td>0.0</td>\n",
              "<td>1.4281768</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0008718</td>\n",
              "<td>0.0460405</td>\n",
              "<td>0.0425731</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>42.8176796</td>\n",
              "<td>0.3097935</td></tr>\n",
              "<tr><td>14</td>\n",
              "<td>0.8001289</td>\n",
              "<td>0.0007366</td>\n",
              "<td>0.0</td>\n",
              "<td>1.2497985</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0007750</td>\n",
              "<td>0.0402901</td>\n",
              "<td>0.0373526</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>24.9798550</td>\n",
              "<td>0.2065290</td></tr>\n",
              "<tr><td>15</td>\n",
              "<td>0.9000645</td>\n",
              "<td>0.0006540</td>\n",
              "<td>0.0</td>\n",
              "<td>1.1110315</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0006944</td>\n",
              "<td>0.0358166</td>\n",
              "<td>0.0332824</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>11.1031519</td>\n",
              "<td>0.1032645</td></tr>\n",
              "<tr><td>16</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0002518</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0005265</td>\n",
              "<td>0.0322373</td>\n",
              "<td>0.0300089</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MSE: 0.01165769989083747\n",
        "\n",
        "RMSE: 0.10797082888835054\n",
        "\n",
        "LogLoss: 0.045557837874566465\n",
        "\n",
        "Mean Per-Class Error: 0.11299800133244503\n",
        "\n",
        "AUC: 0.9819786808794138\n",
        "\n",
        "AUCPR: 0.8117885826525254\n",
        "\n",
        "Gini: 0.9639573617588275\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Here AUC score is close to '1'. This means it is able to separate classes well.**"
      ],
      "metadata": {
        "id": "1J04Z3tF67Wh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aml.leader.model_performance(valid) # model performance on validation data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5xKHMbhdShcb",
        "outputId": "91733652-ca69-4f11-e52b-cc4e44a8b090"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModelMetricsBinomial: gbm\n",
              "** Reported on test data. **\n",
              "\n",
              "MSE: 0.012143755017777197\n",
              "RMSE: 0.11019870696962464\n",
              "LogLoss: 0.05076886190242359\n",
              "Mean Per-Class Error: 0.146011396011396\n",
              "AUC: 0.9681678720140259\n",
              "AUCPR: 0.8184057386168719\n",
              "Gini: 0.9363357440280518\n",
              "\n",
              "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.43833384467054226\n",
              "       0     1    Error    Rate\n",
              "-----  ----  ---  -------  -------------\n",
              "0      1399  5    0.0036   (5.0/1404.0)\n",
              "1      15    37   0.2885   (15.0/52.0)\n",
              "Total  1414  42   0.0137   (20.0/1456.0)\n",
              "\n",
              "Maximum Metrics: Maximum metrics at their respective thresholds\n",
              "metric                       threshold    value     idx\n",
              "---------------------------  -----------  --------  -----\n",
              "max f1                       0.438334     0.787234  40\n",
              "max f2                       0.155975     0.797101  66\n",
              "max f0point5                 0.687081     0.869565  32\n",
              "max accuracy                 0.49897      0.986264  37\n",
              "max precision                0.985851     1         0\n",
              "max recall                   0.000980848  1         360\n",
              "max specificity              0.985851     1         0\n",
              "max absolute_mcc             0.438334     0.784974  40\n",
              "max min_per_class_accuracy   0.0298728    0.923077  143\n",
              "max mean_per_class_accuracy  0.0583284    0.932336  99\n",
              "max tns                      0.985851     1404      0\n",
              "max fns                      0.985851     51        0\n",
              "max fps                      0.000260583  1404      399\n",
              "max tps                      0.000980848  52        360\n",
              "max tnr                      0.985851     1         0\n",
              "max fnr                      0.985851     0.980769  0\n",
              "max fpr                      0.000260583  1         399\n",
              "max tpr                      0.000980848  1         360\n",
              "\n",
              "Gains/Lift Table: Avg response rate:  3.57 %, avg score:  3.26 %\n",
              "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
              "-------  --------------------------  -----------------  --------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
              "1        0.0103022                   0.906607           26.1333   26.1333            0.933333         0.941874     0.933333                    0.941874            0.269231        0.269231                   2513.33   2513.33            0.268519\n",
              "2        0.0206044                   0.70814            28        27.0667            1                0.821938     0.966667                    0.881906            0.288462        0.557692                   2700      2606.67            0.55698\n",
              "3        0.0302198                   0.401783           16        23.5455            0.571429         0.54721      0.840909                    0.775412            0.153846        0.711538                   1500      2254.55            0.706553\n",
              "4        0.040522                    0.194102           7.46667   19.4576            0.266667         0.279656     0.694915                    0.649372            0.0769231       0.788462                   646.667   1845.76            0.775641\n",
              "5        0.0501374                   0.109413           6         16.8767            0.214286         0.156318     0.60274                     0.554814            0.0576923       0.846154                   500       1587.67            0.825499\n",
              "6        0.100275                    0.0295479          1.53425   9.20548            0.0547945        0.0534366    0.328767                    0.304125            0.0769231       0.923077                   53.4247   820.548            0.853276\n",
              "7        0.150412                    0.00880222         0.383562  6.26484            0.0136986        0.0159302    0.223744                    0.20806             0.0192308       0.942308                   -61.6438  526.484            0.821225\n",
              "8        0.200549                    0.00433098         0         4.69863            0                0.00637191   0.167808                    0.157638            0               0.942308                   -100      369.863            0.769231\n",
              "9        0.300137                    0.00215517         0.193103  3.20366            0.00689655       0.0029295    0.114416                    0.106305            0.0192308       0.961538                   -80.6897  220.366            0.685897\n",
              "10       0.400412                    0.00154344         0         2.40137            0                0.00182138   0.0857633                   0.080139            0               0.961538                   -100      140.137            0.581909\n",
              "11       0.5                         0.0011701          0.193103  1.96154            0.00689655       0.0013422    0.0700549                   0.0644446           0.0192308       0.980769                   -80.6897  96.1538            0.498575\n",
              "12       0.600275                    0.00097206         0.191781  1.6659             0.00684932       0.00106262   0.0594966                   0.0538567           0.0192308       1                          -80.8219  66.5904            0.41453\n",
              "13       0.699863                    0.000836412        0         1.42885            0                0.000897474  0.0510304                   0.0463208           0               1                          -100      42.8852            0.311254\n",
              "14       0.800137                    0.000749022        0         1.24979            0                0.000792182  0.0446352                   0.0406151           0               1                          -100      24.9785            0.207265\n",
              "15       0.899725                    0.000667155        0         1.11145            0                0.000708039  0.0396947                   0.0361979           0               1                          -100      11.145             0.103989\n",
              "16       1                           0.000247547        0         1                  0                0.000554079  0.0357143                   0.0326237           0               1                          -100      0                  0"
            ],
            "text/html": [
              "<pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: gbm\n",
              "** Reported on test data. **\n",
              "\n",
              "MSE: 0.012143755017777197\n",
              "RMSE: 0.11019870696962464\n",
              "LogLoss: 0.05076886190242359\n",
              "Mean Per-Class Error: 0.146011396011396\n",
              "AUC: 0.9681678720140259\n",
              "AUCPR: 0.8184057386168719\n",
              "Gini: 0.9363357440280518</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-158.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-158 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-158 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-158 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-158 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-158 .h2o-table th,\n",
              "#h2o-table-158 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-158 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-158\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.43833384467054226</caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>0</th>\n",
              "<th>1</th>\n",
              "<th>Error</th>\n",
              "<th>Rate</th></tr></thead>\n",
              "    <tbody><tr><td>0</td>\n",
              "<td>1399.0</td>\n",
              "<td>5.0</td>\n",
              "<td>0.0036</td>\n",
              "<td> (5.0/1404.0)</td></tr>\n",
              "<tr><td>1</td>\n",
              "<td>15.0</td>\n",
              "<td>37.0</td>\n",
              "<td>0.2885</td>\n",
              "<td> (15.0/52.0)</td></tr>\n",
              "<tr><td>Total</td>\n",
              "<td>1414.0</td>\n",
              "<td>42.0</td>\n",
              "<td>0.0137</td>\n",
              "<td> (20.0/1456.0)</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-159.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-159 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-159 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-159 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-159 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-159 .h2o-table th,\n",
              "#h2o-table-159 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-159 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-159\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
              "    <thead><tr><th>metric</th>\n",
              "<th>threshold</th>\n",
              "<th>value</th>\n",
              "<th>idx</th></tr></thead>\n",
              "    <tbody><tr><td>max f1</td>\n",
              "<td>0.4383338</td>\n",
              "<td>0.7872340</td>\n",
              "<td>40.0</td></tr>\n",
              "<tr><td>max f2</td>\n",
              "<td>0.1559755</td>\n",
              "<td>0.7971014</td>\n",
              "<td>66.0</td></tr>\n",
              "<tr><td>max f0point5</td>\n",
              "<td>0.6870812</td>\n",
              "<td>0.8695652</td>\n",
              "<td>32.0</td></tr>\n",
              "<tr><td>max accuracy</td>\n",
              "<td>0.4989703</td>\n",
              "<td>0.9862637</td>\n",
              "<td>37.0</td></tr>\n",
              "<tr><td>max precision</td>\n",
              "<td>0.9858514</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max recall</td>\n",
              "<td>0.0009808</td>\n",
              "<td>1.0</td>\n",
              "<td>360.0</td></tr>\n",
              "<tr><td>max specificity</td>\n",
              "<td>0.9858514</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max absolute_mcc</td>\n",
              "<td>0.4383338</td>\n",
              "<td>0.7849738</td>\n",
              "<td>40.0</td></tr>\n",
              "<tr><td>max min_per_class_accuracy</td>\n",
              "<td>0.0298728</td>\n",
              "<td>0.9230769</td>\n",
              "<td>143.0</td></tr>\n",
              "<tr><td>max mean_per_class_accuracy</td>\n",
              "<td>0.0583284</td>\n",
              "<td>0.9323362</td>\n",
              "<td>99.0</td></tr>\n",
              "<tr><td>max tns</td>\n",
              "<td>0.9858514</td>\n",
              "<td>1404.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fns</td>\n",
              "<td>0.9858514</td>\n",
              "<td>51.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fps</td>\n",
              "<td>0.0002606</td>\n",
              "<td>1404.0</td>\n",
              "<td>399.0</td></tr>\n",
              "<tr><td>max tps</td>\n",
              "<td>0.0009808</td>\n",
              "<td>52.0</td>\n",
              "<td>360.0</td></tr>\n",
              "<tr><td>max tnr</td>\n",
              "<td>0.9858514</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fnr</td>\n",
              "<td>0.9858514</td>\n",
              "<td>0.9807692</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>max fpr</td>\n",
              "<td>0.0002606</td>\n",
              "<td>1.0</td>\n",
              "<td>399.0</td></tr>\n",
              "<tr><td>max tpr</td>\n",
              "<td>0.0009808</td>\n",
              "<td>1.0</td>\n",
              "<td>360.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-160.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-160 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-160 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-160 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-160 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-160 .h2o-table th,\n",
              "#h2o-table-160 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-160 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-160\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Gains/Lift Table: Avg response rate:  3.57 %, avg score:  3.26 %</caption>\n",
              "    <thead><tr><th>group</th>\n",
              "<th>cumulative_data_fraction</th>\n",
              "<th>lower_threshold</th>\n",
              "<th>lift</th>\n",
              "<th>cumulative_lift</th>\n",
              "<th>response_rate</th>\n",
              "<th>score</th>\n",
              "<th>cumulative_response_rate</th>\n",
              "<th>cumulative_score</th>\n",
              "<th>capture_rate</th>\n",
              "<th>cumulative_capture_rate</th>\n",
              "<th>gain</th>\n",
              "<th>cumulative_gain</th>\n",
              "<th>kolmogorov_smirnov</th></tr></thead>\n",
              "    <tbody><tr><td>1</td>\n",
              "<td>0.0103022</td>\n",
              "<td>0.9066070</td>\n",
              "<td>26.1333333</td>\n",
              "<td>26.1333333</td>\n",
              "<td>0.9333333</td>\n",
              "<td>0.9418743</td>\n",
              "<td>0.9333333</td>\n",
              "<td>0.9418743</td>\n",
              "<td>0.2692308</td>\n",
              "<td>0.2692308</td>\n",
              "<td>2513.3333333</td>\n",
              "<td>2513.3333333</td>\n",
              "<td>0.2685185</td></tr>\n",
              "<tr><td>2</td>\n",
              "<td>0.0206044</td>\n",
              "<td>0.7081395</td>\n",
              "<td>28.0</td>\n",
              "<td>27.0666667</td>\n",
              "<td>1.0</td>\n",
              "<td>0.8219382</td>\n",
              "<td>0.9666667</td>\n",
              "<td>0.8819062</td>\n",
              "<td>0.2884615</td>\n",
              "<td>0.5576923</td>\n",
              "<td>2700.0</td>\n",
              "<td>2606.6666667</td>\n",
              "<td>0.5569801</td></tr>\n",
              "<tr><td>3</td>\n",
              "<td>0.0302198</td>\n",
              "<td>0.4017825</td>\n",
              "<td>16.0</td>\n",
              "<td>23.5454545</td>\n",
              "<td>0.5714286</td>\n",
              "<td>0.5472096</td>\n",
              "<td>0.8409091</td>\n",
              "<td>0.7754119</td>\n",
              "<td>0.1538462</td>\n",
              "<td>0.7115385</td>\n",
              "<td>1500.0</td>\n",
              "<td>2254.5454545</td>\n",
              "<td>0.7065527</td></tr>\n",
              "<tr><td>4</td>\n",
              "<td>0.0405220</td>\n",
              "<td>0.1941016</td>\n",
              "<td>7.4666667</td>\n",
              "<td>19.4576271</td>\n",
              "<td>0.2666667</td>\n",
              "<td>0.2796559</td>\n",
              "<td>0.6949153</td>\n",
              "<td>0.6493722</td>\n",
              "<td>0.0769231</td>\n",
              "<td>0.7884615</td>\n",
              "<td>646.6666667</td>\n",
              "<td>1845.7627119</td>\n",
              "<td>0.7756410</td></tr>\n",
              "<tr><td>5</td>\n",
              "<td>0.0501374</td>\n",
              "<td>0.1094129</td>\n",
              "<td>6.0</td>\n",
              "<td>16.8767123</td>\n",
              "<td>0.2142857</td>\n",
              "<td>0.1563179</td>\n",
              "<td>0.6027397</td>\n",
              "<td>0.5548138</td>\n",
              "<td>0.0576923</td>\n",
              "<td>0.8461538</td>\n",
              "<td>500.0</td>\n",
              "<td>1587.6712329</td>\n",
              "<td>0.8254986</td></tr>\n",
              "<tr><td>6</td>\n",
              "<td>0.1002747</td>\n",
              "<td>0.0295479</td>\n",
              "<td>1.5342466</td>\n",
              "<td>9.2054795</td>\n",
              "<td>0.0547945</td>\n",
              "<td>0.0534366</td>\n",
              "<td>0.3287671</td>\n",
              "<td>0.3041252</td>\n",
              "<td>0.0769231</td>\n",
              "<td>0.9230769</td>\n",
              "<td>53.4246575</td>\n",
              "<td>820.5479452</td>\n",
              "<td>0.8532764</td></tr>\n",
              "<tr><td>7</td>\n",
              "<td>0.1504121</td>\n",
              "<td>0.0088022</td>\n",
              "<td>0.3835616</td>\n",
              "<td>6.2648402</td>\n",
              "<td>0.0136986</td>\n",
              "<td>0.0159302</td>\n",
              "<td>0.2237443</td>\n",
              "<td>0.2080602</td>\n",
              "<td>0.0192308</td>\n",
              "<td>0.9423077</td>\n",
              "<td>-61.6438356</td>\n",
              "<td>526.4840183</td>\n",
              "<td>0.8212251</td></tr>\n",
              "<tr><td>8</td>\n",
              "<td>0.2005495</td>\n",
              "<td>0.0043310</td>\n",
              "<td>0.0</td>\n",
              "<td>4.6986301</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0063719</td>\n",
              "<td>0.1678082</td>\n",
              "<td>0.1576381</td>\n",
              "<td>0.0</td>\n",
              "<td>0.9423077</td>\n",
              "<td>-100.0</td>\n",
              "<td>369.8630137</td>\n",
              "<td>0.7692308</td></tr>\n",
              "<tr><td>9</td>\n",
              "<td>0.3001374</td>\n",
              "<td>0.0021552</td>\n",
              "<td>0.1931034</td>\n",
              "<td>3.2036613</td>\n",
              "<td>0.0068966</td>\n",
              "<td>0.0029295</td>\n",
              "<td>0.1144165</td>\n",
              "<td>0.1063046</td>\n",
              "<td>0.0192308</td>\n",
              "<td>0.9615385</td>\n",
              "<td>-80.6896552</td>\n",
              "<td>220.3661327</td>\n",
              "<td>0.6858974</td></tr>\n",
              "<tr><td>10</td>\n",
              "<td>0.4004121</td>\n",
              "<td>0.0015434</td>\n",
              "<td>0.0</td>\n",
              "<td>2.4013722</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0018214</td>\n",
              "<td>0.0857633</td>\n",
              "<td>0.0801390</td>\n",
              "<td>0.0</td>\n",
              "<td>0.9615385</td>\n",
              "<td>-100.0</td>\n",
              "<td>140.1372213</td>\n",
              "<td>0.5819088</td></tr>\n",
              "<tr><td>11</td>\n",
              "<td>0.5</td>\n",
              "<td>0.0011701</td>\n",
              "<td>0.1931034</td>\n",
              "<td>1.9615385</td>\n",
              "<td>0.0068966</td>\n",
              "<td>0.0013422</td>\n",
              "<td>0.0700549</td>\n",
              "<td>0.0644446</td>\n",
              "<td>0.0192308</td>\n",
              "<td>0.9807692</td>\n",
              "<td>-80.6896552</td>\n",
              "<td>96.1538462</td>\n",
              "<td>0.4985755</td></tr>\n",
              "<tr><td>12</td>\n",
              "<td>0.6002747</td>\n",
              "<td>0.0009721</td>\n",
              "<td>0.1917808</td>\n",
              "<td>1.6659039</td>\n",
              "<td>0.0068493</td>\n",
              "<td>0.0010626</td>\n",
              "<td>0.0594966</td>\n",
              "<td>0.0538567</td>\n",
              "<td>0.0192308</td>\n",
              "<td>1.0</td>\n",
              "<td>-80.8219178</td>\n",
              "<td>66.5903890</td>\n",
              "<td>0.4145299</td></tr>\n",
              "<tr><td>13</td>\n",
              "<td>0.6998626</td>\n",
              "<td>0.0008364</td>\n",
              "<td>0.0</td>\n",
              "<td>1.4288518</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0008975</td>\n",
              "<td>0.0510304</td>\n",
              "<td>0.0463208</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>42.8851816</td>\n",
              "<td>0.3112536</td></tr>\n",
              "<tr><td>14</td>\n",
              "<td>0.8001374</td>\n",
              "<td>0.0007490</td>\n",
              "<td>0.0</td>\n",
              "<td>1.2497854</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0007922</td>\n",
              "<td>0.0446352</td>\n",
              "<td>0.0406151</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>24.9785408</td>\n",
              "<td>0.2072650</td></tr>\n",
              "<tr><td>15</td>\n",
              "<td>0.8997253</td>\n",
              "<td>0.0006672</td>\n",
              "<td>0.0</td>\n",
              "<td>1.1114504</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0007080</td>\n",
              "<td>0.0396947</td>\n",
              "<td>0.0361979</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>11.1450382</td>\n",
              "<td>0.1039886</td></tr>\n",
              "<tr><td>16</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0002475</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0005541</td>\n",
              "<td>0.0357143</td>\n",
              "<td>0.0326237</td>\n",
              "<td>0.0</td>\n",
              "<td>1.0</td>\n",
              "<td>-100.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perf = aml.leader.model_performance(test)\n",
        "perf.accuracy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITNG1lJwKiEb",
        "outputId": "6d82f29b-8ffe-4cf9-eb9c-6228b6b95bbc"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.3019564616010904, 0.9871050934880722]]"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy from confusion metrics\n",
        "\n",
        "# total correct predicted observations divided by total observations\n",
        "\n",
        "acc = (1492 + 39) / (1503+48)\n",
        "acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFOVPYxnLBOc",
        "outputId": "902f8da7-da81-47c1-8153-c9694b5d9a91"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9871050934880722"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_ids = list(aml.leaderboard['model_id'].as_data_frame().iloc[:,0])\n"
      ],
      "metadata": {
        "id": "e9LHBkavRBI6"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkE5tDllRUaj",
        "outputId": "0f8f1516-ced6-42fa-f636-21cc442ea4bf"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['GBM_2_AutoML_3_20221107_235941',\n",
              " 'GBM_3_AutoML_3_20221107_235941',\n",
              " 'XGBoost_3_AutoML_3_20221107_235941',\n",
              " 'GBM_4_AutoML_3_20221107_235941',\n",
              " 'GBM_1_AutoML_3_20221107_235941',\n",
              " 'XGBoost_2_AutoML_3_20221107_235941',\n",
              " 'XGBoost_1_AutoML_3_20221107_235941',\n",
              " 'DRF_1_AutoML_3_20221107_235941',\n",
              " 'XRT_1_AutoML_3_20221107_235941',\n",
              " 'GLM_1_AutoML_3_20221107_235941']"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# h2o.get_model([mid for mid in model_ids if \"GBM\" in mid][0])"
      ],
      "metadata": {
        "id": "xZnK4umzRXKZ"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# out = h2o.get_model([mid for mid in model_ids if \"XGBoost\" in mid][0])"
      ],
      "metadata": {
        "id": "ZexSncfDRaEM"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "me5daGgDRgxU",
        "outputId": "57f9bff1-408a-4205-ec7d-ca340bff7b38"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model_id': {'default': None,\n",
              "  'actual': {'__meta': {'schema_version': 3,\n",
              "    'schema_name': 'ModelKeyV3',\n",
              "    'schema_type': 'Key<Model>'},\n",
              "   'name': 'GBM_2_AutoML_3_20221107_235941',\n",
              "   'type': 'Key<Model>',\n",
              "   'URL': '/3/Models/GBM_2_AutoML_3_20221107_235941'},\n",
              "  'input': None},\n",
              " 'training_frame': {'default': None,\n",
              "  'actual': {'__meta': {'schema_version': 3,\n",
              "    'schema_name': 'FrameKeyV3',\n",
              "    'schema_type': 'Key<Frame>'},\n",
              "   'name': 'AutoML_3_20221107_235941_training_py_21_sid_a03f',\n",
              "   'type': 'Key<Frame>',\n",
              "   'URL': '/3/Frames/AutoML_3_20221107_235941_training_py_21_sid_a03f'},\n",
              "  'input': {'__meta': {'schema_version': 3,\n",
              "    'schema_name': 'FrameKeyV3',\n",
              "    'schema_type': 'Key<Frame>'},\n",
              "   'name': 'AutoML_3_20221107_235941_training_py_21_sid_a03f',\n",
              "   'type': 'Key<Frame>',\n",
              "   'URL': '/3/Frames/AutoML_3_20221107_235941_training_py_21_sid_a03f'}},\n",
              " 'validation_frame': {'default': None,\n",
              "  'actual': {'__meta': {'schema_version': 3,\n",
              "    'schema_name': 'FrameKeyV3',\n",
              "    'schema_type': 'Key<Frame>'},\n",
              "   'name': 'py_23_sid_a03f',\n",
              "   'type': 'Key<Frame>',\n",
              "   'URL': '/3/Frames/py_23_sid_a03f'},\n",
              "  'input': {'__meta': {'schema_version': 3,\n",
              "    'schema_name': 'FrameKeyV3',\n",
              "    'schema_type': 'Key<Frame>'},\n",
              "   'name': 'py_23_sid_a03f',\n",
              "   'type': 'Key<Frame>',\n",
              "   'URL': '/3/Frames/py_23_sid_a03f'}},\n",
              " 'nfolds': {'default': 0, 'actual': 0, 'input': 0},\n",
              " 'keep_cross_validation_models': {'default': True,\n",
              "  'actual': False,\n",
              "  'input': False},\n",
              " 'keep_cross_validation_predictions': {'default': False,\n",
              "  'actual': True,\n",
              "  'input': True},\n",
              " 'keep_cross_validation_fold_assignment': {'default': False,\n",
              "  'actual': False,\n",
              "  'input': False},\n",
              " 'score_each_iteration': {'default': False, 'actual': False, 'input': False},\n",
              " 'score_tree_interval': {'default': 0, 'actual': 5, 'input': 5},\n",
              " 'fold_assignment': {'default': 'AUTO', 'actual': None, 'input': 'AUTO'},\n",
              " 'fold_column': {'default': None, 'actual': None, 'input': None},\n",
              " 'response_column': {'default': None,\n",
              "  'actual': {'__meta': {'schema_version': 3,\n",
              "    'schema_name': 'ColSpecifierV3',\n",
              "    'schema_type': 'VecSpecifier'},\n",
              "   'column_name': 'Target',\n",
              "   'is_member_of_frames': None},\n",
              "  'input': {'__meta': {'schema_version': 3,\n",
              "    'schema_name': 'ColSpecifierV3',\n",
              "    'schema_type': 'VecSpecifier'},\n",
              "   'column_name': 'Target',\n",
              "   'is_member_of_frames': None}},\n",
              " 'ignored_columns': {'default': None,\n",
              "  'actual': ['Product ID', '\\ufeffUDI', 'Failure Type'],\n",
              "  'input': ['Product ID', '\\ufeffUDI', 'Failure Type']},\n",
              " 'ignore_const_cols': {'default': True, 'actual': True, 'input': True},\n",
              " 'offset_column': {'default': None, 'actual': None, 'input': None},\n",
              " 'weights_column': {'default': None, 'actual': None, 'input': None},\n",
              " 'balance_classes': {'default': False, 'actual': False, 'input': False},\n",
              " 'class_sampling_factors': {'default': None, 'actual': None, 'input': None},\n",
              " 'max_after_balance_size': {'default': 5.0, 'actual': 5.0, 'input': 5.0},\n",
              " 'max_confusion_matrix_size': {'default': 20, 'actual': 20, 'input': 20},\n",
              " 'ntrees': {'default': 50, 'actual': 10000, 'input': 10000},\n",
              " 'max_depth': {'default': 5, 'actual': 7, 'input': 7},\n",
              " 'min_rows': {'default': 10.0, 'actual': 10.0, 'input': 10.0},\n",
              " 'nbins': {'default': 20, 'actual': 20, 'input': 20},\n",
              " 'nbins_top_level': {'default': 1024, 'actual': 1024, 'input': 1024},\n",
              " 'nbins_cats': {'default': 1024, 'actual': 1024, 'input': 1024},\n",
              " 'r2_stopping': {'default': 1.7976931348623157e+308,\n",
              "  'actual': 1.7976931348623157e+308,\n",
              "  'input': 1.7976931348623157e+308},\n",
              " 'stopping_rounds': {'default': 0, 'actual': 3, 'input': 3},\n",
              " 'stopping_metric': {'default': 'AUTO',\n",
              "  'actual': 'logloss',\n",
              "  'input': 'logloss'},\n",
              " 'stopping_tolerance': {'default': 0.001,\n",
              "  'actual': 0.011958266722236254,\n",
              "  'input': 0.011958266722236254},\n",
              " 'max_runtime_secs': {'default': 0.0, 'actual': 0.0, 'input': 0.0},\n",
              " 'seed': {'default': -1, 'actual': 15, 'input': 15},\n",
              " 'build_tree_one_node': {'default': False, 'actual': False, 'input': False},\n",
              " 'learn_rate': {'default': 0.1, 'actual': 0.1, 'input': 0.1},\n",
              " 'learn_rate_annealing': {'default': 1.0, 'actual': 1.0, 'input': 1.0},\n",
              " 'distribution': {'default': 'AUTO',\n",
              "  'actual': 'bernoulli',\n",
              "  'input': 'bernoulli'},\n",
              " 'quantile_alpha': {'default': 0.5, 'actual': 0.5, 'input': 0.5},\n",
              " 'tweedie_power': {'default': 1.5, 'actual': 1.5, 'input': 1.5},\n",
              " 'huber_alpha': {'default': 0.9, 'actual': 0.9, 'input': 0.9},\n",
              " 'checkpoint': {'default': None, 'actual': None, 'input': None},\n",
              " 'sample_rate': {'default': 1.0, 'actual': 0.8, 'input': 0.8},\n",
              " 'sample_rate_per_class': {'default': None, 'actual': None, 'input': None},\n",
              " 'col_sample_rate': {'default': 1.0, 'actual': 0.8, 'input': 0.8},\n",
              " 'col_sample_rate_change_per_level': {'default': 1.0,\n",
              "  'actual': 1.0,\n",
              "  'input': 1.0},\n",
              " 'col_sample_rate_per_tree': {'default': 1.0, 'actual': 0.8, 'input': 0.8},\n",
              " 'min_split_improvement': {'default': 1e-05, 'actual': 1e-05, 'input': 1e-05},\n",
              " 'histogram_type': {'default': 'AUTO',\n",
              "  'actual': 'UniformAdaptive',\n",
              "  'input': 'AUTO'},\n",
              " 'max_abs_leafnode_pred': {'default': 1.7976931348623157e+308,\n",
              "  'actual': 1.7976931348623157e+308,\n",
              "  'input': 1.7976931348623157e+308},\n",
              " 'pred_noise_bandwidth': {'default': 0.0, 'actual': 0.0, 'input': 0.0},\n",
              " 'categorical_encoding': {'default': 'AUTO',\n",
              "  'actual': 'Enum',\n",
              "  'input': 'AUTO'},\n",
              " 'calibrate_model': {'default': False, 'actual': False, 'input': False},\n",
              " 'calibration_frame': {'default': None, 'actual': None, 'input': None},\n",
              " 'calibration_method': {'default': 'AUTO',\n",
              "  'actual': 'PlattScaling',\n",
              "  'input': 'AUTO'},\n",
              " 'custom_metric_func': {'default': None, 'actual': None, 'input': None},\n",
              " 'custom_distribution_func': {'default': None, 'actual': None, 'input': None},\n",
              " 'export_checkpoints_dir': {'default': None, 'actual': None, 'input': None},\n",
              " 'in_training_checkpoints_dir': {'default': None,\n",
              "  'actual': None,\n",
              "  'input': None},\n",
              " 'in_training_checkpoints_tree_interval': {'default': 1,\n",
              "  'actual': 1,\n",
              "  'input': 1},\n",
              " 'monotone_constraints': {'default': None, 'actual': None, 'input': None},\n",
              " 'check_constant_response': {'default': True, 'actual': True, 'input': True},\n",
              " 'gainslift_bins': {'default': -1, 'actual': -1, 'input': -1},\n",
              " 'auc_type': {'default': 'AUTO', 'actual': 'AUTO', 'input': 'AUTO'},\n",
              " 'interaction_constraints': {'default': None, 'actual': None, 'input': None}}"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# out.convert_H2OXGBoostParams_2_XGBoostParams()"
      ],
      "metadata": {
        "id": "12ZeOOLBRjp0"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# out_gbm = h2o.get_model([mid for mid in model_ids if \"GBM\" in mid][0])"
      ],
      "metadata": {
        "id": "6Yr-Hk0LRqK5"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.confusion_matrix()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "id": "Du99wV70Rwp1",
        "outputId": "2e663823-5982-4809-c9f7-9a694de53cf6"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.29666095801752085\n",
              "       0     1    Error    Rate\n",
              "-----  ----  ---  -------  -------------\n",
              "0      6752  4    0.0006   (4.0/6756.0)\n",
              "1      8     229  0.0338   (8.0/237.0)\n",
              "Total  6760  233  0.0017   (12.0/6993.0)"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "\n",
              "#h2o-table-124.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-124 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-124 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-124 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-124 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-124 .h2o-table th,\n",
              "#h2o-table-124 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-124 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-124\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.29666095801752085</caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>0</th>\n",
              "<th>1</th>\n",
              "<th>Error</th>\n",
              "<th>Rate</th></tr></thead>\n",
              "    <tbody><tr><td>0</td>\n",
              "<td>6752.0</td>\n",
              "<td>4.0</td>\n",
              "<td>0.0006</td>\n",
              "<td> (4.0/6756.0)</td></tr>\n",
              "<tr><td>1</td>\n",
              "<td>8.0</td>\n",
              "<td>229.0</td>\n",
              "<td>0.0338</td>\n",
              "<td> (8.0/237.0)</td></tr>\n",
              "<tr><td>Total</td>\n",
              "<td>6760.0</td>\n",
              "<td>233.0</td>\n",
              "<td>0.0017</td>\n",
              "<td> (12.0/6993.0)</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the above confusion metrics, our positive class is \"Failure\" i.e \"1\" and negative class is \"Not a Failure\" i.e \"0\" \n",
        "\n",
        "- False negative (FN) is less, it means recall is more\n",
        "- We can be a little lineant in saying that a machine would fail, but cannot cannot falsely inform that machine wouldn't fail, this is why recall is important\n"
      ],
      "metadata": {
        "id": "9H8bR9URAcxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.varimp_plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "fVjeoMdSR0mu",
        "outputId": "5f190cec-920f-4516-96ab-b7b0934c87e2"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1008x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<h2o.plot._plot_result._MObject at 0x7fc105bc6290>"
            ]
          },
          "metadata": {},
          "execution_count": 97
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EUyCRqVAaf96"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Questions and Answers \n",
        "\n",
        "1. **Is the relationship significant?**\n",
        "\n",
        "As mentioned in the Assignment description I didnot perform feature engineering but visualised a pearson correlation heatmap for correlation before one hot encoding\n",
        "- `Air teamperature [k]` and `Process temperature [k]` are highly correlated.\n",
        "- `Torque` has high correlation comparing to other feature with Target\n",
        "- `Torque` and `Rotational speed [Nm]` are negatively correlated i.e if Rotational speed increases then Torque decreases and vice versa.\n",
        "- `Type` has slight correlation with `Rotational speed [Nm]` comparing to other features but it doesn't seem like multi colinearity as the value is very low.\n",
        "\n",
        "2. **Are any model assumptions violated?**\n",
        "\n",
        "As AutoML aims to give best model and tunes hyper parameters for gaining best accuracy. Used H2O.ai to build a maximum of 10 models excluding StackedEnsemble and DeepLearning models with no crossvalidation as validation data is taken from the raw dataset, so automl by default tunes the parameters to get the best model. So, its hard to comment if the AutoML assumptions are violated.\n",
        "\n",
        "3. **Is there any multicollinearity in the model?**\n",
        "\n",
        "- `Air teamperature [k]` and `Process temperature [k]` are highly correlated.\n",
        "- `Torque` and `Rotational speed [Nm]` are negatively correlated i.e if Rotational speed increases then Torque decreases and vice versa.\n",
        "- `Type` has slight correlation with `Rotational speed [Nm]` comparing to other features but it doesn't seem like multi colinearity as the value is very low.\n",
        "\n",
        "4. **In the multivariate models are predictor variables independent of all the other predictor variables?**\n",
        "\n",
        "Few features are independent and some features are dependent on others based on heatmap shown. For examples `Air teamperature [k]` and `Process temperature [k]` are highly colinear.\n",
        "Moving forward with feature engineering one of this can. be removed but before that , its a best practice to check which has high significance on the model performance through OLS regression. The same can be checked for `Torque` and `Rotational speed [Nm]`\n",
        "\n",
        "5. **In in multivariate models rank the most significant predictor variables and exclude insignificant ones from the model?**\n",
        "\n",
        "The `varimp_plot()` a H2O.ai function that shows us the most significant predictor variable in a hierarchical manner and `Torque [Nm]` is the most significant in this case\n",
        "\n",
        "6. **Does the model make sense?**\n",
        "\n",
        "Yes, the model makes sense. The test and validation error scores are significant with train set scores and Here the accuracy is 98%. \n",
        "\n",
        "**ModelMetricsBinomial: gbm**\n",
        "\n",
        "**Report on Validation set.**\n",
        "\n",
        "MSE: 0.012143755017777197\n",
        "\n",
        "RMSE: 0.11019870696962464\n",
        "\n",
        "LogLoss: 0.05076886190242359\n",
        "\n",
        "Mean Per-Class Error: 0.146011396011396\n",
        "\n",
        "AUC: 0.9681678720140259\n",
        "\n",
        "AUCPR: 0.8184057386168719\n",
        "\n",
        "Gini: 0.9363357440280518\n",
        "\n",
        "**ModelMetricsBinomial: gbm**\n",
        "\n",
        "**Reported on test data.**\n",
        "\n",
        "MSE: 0.01165769989083747\n",
        "RMSE: 0.10797082888835054\n",
        "LogLoss: 0.045557837874566465\n",
        "Mean Per-Class Error: 0.11299800133244503\n",
        "AUC: 0.9819786808794138\n",
        "AUCPR: 0.8117885826525254\n",
        "Gini: 0.9639573617588275\n",
        "\n",
        "7. **Does regularization help?**\n",
        "\n",
        "Here model is not overfitted on test or validation data and it may not require regularization in this case.\n",
        "\n",
        "8. **Which independent variables are significant?**\n",
        "\n",
        "All the features shows significant importance in prediction. As mentioned in the description of the assignment encoding is not performed on categorical features, doing this would help us get the significant features through permutation importance.\n",
        "\n",
        "9. **Which hyperparameters are important?**\n",
        "\n",
        "max_models will let us see the number of models to be trained and display on the dataset , nfolds helps in mentioning the number of parts the dataset to be divided, exclude_algos are important by helping us not considering deep learning models if the data is not too complex, "
      ],
      "metadata": {
        "id": "zLCX5pdZLhx9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusion :\n",
        "\n",
        "- The dataset has a categorical target feature that has \"Failure\" and \"not a Failure\" classes and predicting \"not a Failure\" case is more sensitive as it may mislead and not warn the user for potential machinary failures\n",
        "- `Failure Type` is removed as it has the information about target variable and may lead to data leakage\n",
        "- H2O AutoML showed good performance in many models and the top one is GBM for classifiation for  our current dataset\n",
        "- Confusion metrics shows that there is low False negatives which is a good sign by giving high recall\n",
        "- `Torque [Nm]` shows high importance over other features and the least important feature is shown as `Type` a categorical feature\n",
        "- Accuracy is 98% based on the calculation mentioned in below confusion metrics"
      ],
      "metadata": {
        "id": "EJyaZ-TiIVpA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Refrences:\n",
        "\n",
        "1. H2O.ai documentation https://docs.h2o.ai/h2o/latest-stable/h2o-docs/performance-and-prediction.html\n",
        "2. H2O.ai notebook reference on a different dataset for classification https://colab.research.google.com/github/srivatsan88/YouTubeLI/blob/master/H2O_AutoML.ipynb#scrollTo=vOxeivTyUCeq\n",
        "3. H2O.ai model explainability https://docs.h2o.ai/h2o/latest-stable/h2o-docs/explain.html\n",
        "4. Confusion metrics https://en.wikipedia.org/wiki/Confusion_matrix\n",
        "\n",
        "**All other code and function implementation are independently written.**\n",
        "\n",
        "\n",
        "Copyright \n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
      ],
      "metadata": {
        "id": "DShZqqCtHjcf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RZMhp7ejISCe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}